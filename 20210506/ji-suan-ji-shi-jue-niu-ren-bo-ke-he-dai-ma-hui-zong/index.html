<!DOCTYPE html><html lang="en"><head><link href="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/css/index.css" rel="stylesheet"><link href="/css/hexo-widget-tree.css" rel="stylesheet"><!--[if lt IE 9]>
    <script src="http://cdn.static.runoob.com/libs/html5shiv/3.7/html5shiv.min.js"></script>
<![endif]--><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="shortcut icon" href="favicon-fish.ico"><link rel="alternate" type="application/rss+xml" title="LordYao" href="/atom.xml"><meta name="keywords" content="LordYao,scholar,要庆生,yaoqs,FUTURE &amp; CIVILIZATION，Natural/Social Philosophy &amp; Infomation Sciences,计算机视觉,博客,代码,计算机视觉牛人博客和代码汇总"><meta name="description" content="A scholar magazine/journal like blog，FUTURE &amp; CIVILIZATION，Natural/Social Philosophy &amp; Infomation Sciences,A scholar magazine/journal-like blog,要庆生的blog"><script>(()=>{var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)})()</script><title>计算机视觉牛人博客和代码汇总 | LordYao</title><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js" integrity="sha256-3gQJhtmj7YnV1fmtbVcnAV6eI4ws0Tr48bVZCThtCGQ=" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" integrity="sha256-PI8n5gCcz9cQqQXm3PEtDuPG8qx9oFsFctPg0S5zb8g=" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/js/all.min.js"></script><link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/fontawesome.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/future.css"><link rel="stylesheet" href="/css/main.css"><script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/jquery.qrcode@1.0.3/jquery.qrcode.min.js"></script><script src="https://d3js.org/d3.v7.min.js"></script><script src="/js/ax.js"></script><script src="/js/main.js"></script><link rel="canonical" href="https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/"><meta name="generator" content="Hexo 7.3.0"></head><body><aside id="aside"><header><style>div#fork_me_on_github{margin-top:-2em;margin-left:-2em;margin-bottom:-5em}.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><div id="fork_me_on_github"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/" class="github-corner" aria-label="View source on GitHub"><svg width="8em" height="8em" viewBox="0 0 250 250" style="fill:#151515;color:#fff;position:absolute;top:0;border:0;left:0;transform:scale(-1,1)" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></div><a id="avatar" href="/"><img id="avatar_img" src="/images/avatar_sx_lite.png" alt="LordYao"></a><h1><a id="author" href="/">LordYao</a></h1><div id="github-iframe"><iframe src="https://ghbtns.com/github-btn.html?user=yaoqs&type=follow&count=true" scrolling="no" frameborder="0" width="150px" height="20px"></iframe></div><div id="weibo"></div><script src="https://tjs.sjs.sinajs.cn/open/api/js/wb.js"></script><iframe src="https://widget.weibo.com/relationship/followbutton.php?btn=red&amp;style=2&amp;uid=1262655355&amp;width=86&amp;height=24&amp;language=zh_cn" scrolling="no" marginheight="0" width="86" height="24" frameborder="0"></iframe><div id="follow-icons"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://space.bilibili.com/19354848" title="哔哩哔哩/bilibili"><i class="fab fa-twitch fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/yaokingson" title="csdn"><i class="fab fa-blogger fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hub.docker.com/u/lordyao" title="dockerhub"><i class="fab fa-docker fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://gitee.com/yaoqs" title="gitee"><i class="fab fa-git fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://ghbtns.com/github-btn.html?user=yaoqs&type=follow&count=true"><i></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/yaoqs" title="github"><i class="fab fa-github fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://stackexchange.com/users/5986345/francisco" title="StackOverflow"><i class="fab fa-stack-overflow fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="http://twitter.com/Lord_Honor_Yao" title="twitter/推特"><i class="fab fa-twitter fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="http://weibo.com/lordyao" title="weibo/微博"><i class="fab fa-weibo fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://widget.weibo.com/relationship/followbutton.php?btn=red&amp;style=2&amp;uid=1262655355&amp;width=86&amp;height=24&amp;language=zh_cn" title="加关注"><i></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/people/yaoqs" title="知乎"><i class="fab fa-zhihu fa-2x"></i></a> <a id="rss" href="/atom.xml" title="RSS"><i class="fa fa-rss fa-2x"></i></a></div><span id="slogan">Slogan:<ul><li style="display:none">解放思想，发展生产力</li><li style="display:none">为天地立心，<br>为生民立命，<br>为往圣继绝学，<br>为万世开太平。</li><li style="display:none">知行合一</li><li style="display:none">凡事预则立，不预则废</li><li style="display:none">茍日新，日日新，又日新</li><li style="display:none">天之道，利而不害；<br>圣人之道，为而不争</li><li style="display:none">吾尝终日而思矣，不如须臾之所学也。<br>吾尝跂而望矣，不如登高之博见也。<br>君子生非异也，善假于物也。</li><li style="display:none">练得身形似鹤形，千株松下两函经。<br>我来问道无馀说，云在青霄水在瓶。</li><li style="display:none">寇可往，我亦可往</li><li style="display:none">我的思想是全人类的财富</li></ul><script>var sel=$("#slogan > ul > li");function lunbo(){arguments.callee.pre=arguments.callee.pre||0,sel[arguments.callee.pre].style.display="none",arguments.callee.pre=Math.floor(Math.random()*sel.length),sel[arguments.callee.pre].style.display="inline-block",setTimeout(lunbo,3e4)}lunbo()</script></span><span id="donate"><a href="/Donate" title="大吉大利 今晚吃鸡">Donate & Reward</a></span></header><footer id="footer-message">Copyright &copy; 2019 - <span id="year">2021</span> <a href="https://yaoqs.github.io" target="_blank">LordYao</a>. BY-NC-SA . All Rights Reserved.<br>Powered by <a href="http://hexo.io/" rel="external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://pages.github.com/" target="_blank">Github Pages</a>. Theme <a href="https://github.com/yaoqs/hexo-theme-scholar-future" rel="external nofollow noreferrer" target="_blank">scholar-future </a>designed by <a href="https://yaoqs.github.io" target="_blank">LordYao </a>.<script>var year=new Date(Date.now()).getFullYear();document.getElementById("year").innerText=year</script><div id="Statistics"><script>var _hmt=_hmt||[];(()=>{var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?2023f967cb85513ede1b6a3d58177776",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)})()</script>&nbsp;<script>var cnzz_protocol="https:"==document.location.protocol?"https://":"http://";document.write(unescape("%3Cspan id='cnzz_stat_icon_1278269244'%3E%3C/span%3E%3Cscript src='"+cnzz_protocol+"s4.cnzz.com/z_stat.php%3Fid%3D1278269244%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"))</script>&nbsp;<script>var cnzz_protocol="https:"==document.location.protocol?"https://":"http://";document.write(unescape("%3Cspan id='cnzz_stat_icon_1278269244'%3E%3C/span%3E%3Cscript src='"+cnzz_protocol+"s4.cnzz.com/z_stat.php%3Fid%3D1278269244%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"))</script>&nbsp;<script src="https://tajs.qq.com/stats?sId=66496804" charset="UTF-8" async></script>&nbsp; <a target="_blank" rel="noopener external nofollow noreferrer" href="https://info.flagcounter.com/tQfY"><img src="https://s11.flagcounter.com/mini/tQfY/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" alt="Flag Counter" border="0"></a>&nbsp;<script>((e,n,c,s,t,r)=>{e[s]=e[s]||function(){(e[s].c=e[s].c||[]).push(arguments)},e[s].s=!1,t=n.getElementsByTagName(c)[0],(r=n.createElement(c)).src="//s.union.360.cn/332983.js",r.defer=!0,r.async=!0,t.parentNode.insertBefore(r,t)})(window,document,"script","_qha")</script>&nbsp;<script src="//js.users.51.la/21341261.js"></script>&nbsp;<script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js?id=JhwXbvPO5Ijy6W6x&ck=JhwXbvPO5Ijy6W6x"></script><script id="LA-DATA-WIDGET" crossorigin="anonymous" charset="UTF-8" src="https://v6-widget.51.la/v6/JhwXbvPO5Ijy6W6x/quote.js?theme=0&f=12&display=0,0,0,1,0,0,0,1"></script><a target="_blank" title="51la网站统计" href="https://v6.51.la/land/JhwXbvPO5Ijy6W6x" rel="external nofollow noreferrer"><img src="https://sdk.51.la/icon/4-5.png"></a>&nbsp;<script src="https://sdk.51.la/perf/js-sdk-perf.min.js" crossorigin="anonymous"></script><script>(new LingQue.Monitor).init({id:"JhwYVlJAdB7w0kYc",sendSpaPv:!0})</script>&nbsp;<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://busuanzi.ibruce.info/" title="不蒜子">总访问量:<span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></a>. </span>&nbsp;<br><span class="post-count">site total word count:475.6k</span></div></footer></aside><nav class="navbar"><h6><span id="custom_html_list"></span> &middot; <a href="/About">About </a>&middot; <a href="/Lab">Lab </a>&middot; <a href="/Navigator">Navigator </a>&middot; <a href="/Feature">Feature </a>&middot; <a href="/Donate">Donate </a>&middot; <a href="/Game">Game </a>&middot; <a href="/Music">Music </a><a href="#searchModal" class="modal-trigger waves-effect waves-light"><span id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></span></a><div id="repos"><div class="dropdown" onmouseenter='showList("dropdown-a")' onmouseleave='showList("dropdown-a")'><a id="a" href="javascript:void(0)" rel="external nofollow noreferrer" class="dropbtn">&#9776; Repositories Pages</a><div class="dropdown-content" id="dropdown-a"><script>$(async function(){jax("https://api.github.com/users/yaoqs/repos",await function(t){d3.select("body").select("#dropdown-a").selectAll("a").data(t).enter().append("a").attr("target","_blank").style("padding-left","1em").text(t=>"§ "+t.full_name).attr("href",t=>"https://yaoqs.github.io/"+t.name)},function(){$("<div style='color:red;width: 9em;height: 2em;text-align: center;display: table-cell;vertical-align: middle;'>当前无网络</div>").appendTo($("#dropdown-a"))})})</script></div></div>&middot;<div class="dropdown" onmouseenter='showList("dropdown-b")' onmouseleave='showList("dropdown-b")'><a href="/" class="dropbtn">Home</a><div class="dropdown-content" id="dropdown-b"><a href="/"><i class="fas fa-home" aria-hidden="true"></i><span style="text-align:center">&#x0009;首页/Index</span></a> <a href="/tags"><i class="fas fa-tags" aria-hidden="true"></i><span style="text-align:center">&#x0009;标签/Tags</span></a> <a href="/categories"><i class="fas fa-bookmark" aria-hidden="true"></i><span style="text-align:center">&#x0009;归类/Categories</span></a> <a href="/archives"><i class="fas fa-archive" aria-hidden="true"></i><span style="text-align:center">&#x0009;文档/Archives</span></a></div></div></div></h6></nav><div id="journal"><div id="journal-name">FUTURE & CIVILIZATION<br>Natural/Social Philosophy & Infomation Sciences</div><div id="post"><main id="content"><hr id="topline"><div id="DOI">05/06, 2021<br>https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/<br><span class="post-count">post word count: 10.2k words.&nbsp; </span><span class="post-count">post estimate read time: 52 min</span></div><article class="post"><h1 class="post-title">计算机视觉牛人博客和代码汇总</h1><div id="post-author">Yao Qingsheng<br>Department of Natural/Social Philosophy & Infomation Sciences, CHINA</div><section class="post-content article-entry"><section id="Abstract"><hr class="AbstractLine"><span class="Abstract">Abstract</span> <span class="Abstract-content"><div id="toc" class="toc-article"><a class="js-toggle-toc" href="javascript:void(0)" rel="external nofollow noreferrer"></a><div class="toc-content"></div></div></span><span class="Abstract">Keywords <span class="keywords-content"><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a>&nbsp; <a href="/tags/Computer-Vision-Resources/">Computer Vision Resources</a>&nbsp;</span></span><hr class="AbstractLine"><span class="Abstract">Citation <span class="keywords-content">Yao Qing-sheng&period;计算机视觉牛人博客和代码汇总&period;FUTURE & CIVILIZATION Natural/Social Philosophy & Infomation Sciences&comma;20210506&period; https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/</span></span><hr class="AbstractLine"></section><section><p>转载自 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/findumars/p/5009003.html">https://www.cnblogs.com/findumars/p/5009003.html</a> 略有删改，未经修正</p><p>1 牛人Homepages（随意排序，不分先后）：</p><p>1.<a href="http://iris.usc.edu/USC-Computer-Vision.html" rel="external nofollow noreferrer" target="_blank">USC Computer Vision Group</a>：南加大，多目标跟踪/检测等；</p><p>2.<a href="http://www.vision.ee.ethz.ch/" rel="external nofollow noreferrer" target="_blank">ETHZ Computer Vision Laboratory</a>：苏黎世联邦理工学院，欧洲最好的几个CV/ML研究机构；</p><p>3.<a href="http://www.vision.ee.ethz.ch/~hegrabne/" rel="external nofollow noreferrer" target="_blank">Helmut Grabner</a>：Online Boosting and Vision的作者，tracking by online feature selection的早期经典，貌似现在不是很活跃了，跑去创业了；</p><p>4.<a href="http://www.cse.psu.edu/~rcollins/" rel="external nofollow noreferrer" target="_blank">Robert T. Collins</a>：PSU，也是跟踪界的大牛；</p><p>5.<a href="http://users.eecs.northwestern.edu/~yingwu/" rel="external nofollow noreferrer" target="_blank">Ying Wu</a>：美国西北大学，华人学者中的翘楚；</p><p>6.<a href="http://www3.ntu.edu.sg/home/jsyuan/" rel="external nofollow noreferrer" target="_blank">Junsong Yuan</a>：NTU，上面Wu老师的学生；</p><p>7.<a href="http://www.cse.ohio-state.edu/~jwdavis/" rel="external nofollow noreferrer" target="_blank">James W. Davis</a>：俄亥俄州立，视频监控；</p><p>8.&nbsp;<a href="http://www.acvt.com.au/" rel="external nofollow noreferrer" target="_blank">The Australian Centre for Visual Technologies</a>：阿德莱德大学的CV组，最近也是exceedingly active &amp; fruitful；</p><p>9.<a href="http://cs.adelaide.edu.au/~chhshen/" rel="external nofollow noreferrer" target="_blank">Chunhua Shen</a>：属上面的ACVT组，最近非常活跃；</p><p>10.<a href="http://cs.adelaide.edu.au/~xi/Xi_Li.html" rel="external nofollow noreferrer" target="_blank">Xi Li</a>：同属ACVT，之前是中科院的PHD，跟踪方面的论文很多，有理论深度；</p><p>11.<a href="http://www.dabi.temple.edu/~hbling/" rel="external nofollow noreferrer" target="_blank">Haibin Ling</a>：天普大学，L1-Tracker及后续扩展，<strong>源码</strong>分享；</p><p>12.<a href="http://lrs.icg.tugraz.at/index.php" rel="external nofollow noreferrer" target="_blank">Learning, Recognition, and Surveillance</a>：奥地利 TU Graz，在线学习，跟踪/检测等，active！<strong>源码</strong>分享；</p><p>13.<a href="http://www.svcl.ucsd.edu/" rel="external nofollow noreferrer" target="_blank">Statistical Visual Computing Laboratory</a>：UCSD，光听名字就很学术吧，Saliency研究很有名；</p><p>14.<a href="http://www.cs.toronto.edu/~dross/" rel="external nofollow noreferrer" target="_blank">David Ross</a>：多伦多大学，<a href="http://www.cs.toronto.edu/~dross/ivt/" rel="external nofollow noreferrer" target="_blank">IVT</a>的作者，跟踪中Generative表观的经典中的经典，提供<strong>源码</strong>，IVT的代码结构被后来很多人引用，值得一读；</p><p>15.<a href="http://cvlab.epfl.ch/" rel="external nofollow noreferrer" target="_blank">EPFL, Computer Vision Laboratory</a>：洛桑理工的学院，和上面的的ETHZ CV lab同样是欧洲最好的CV研究大组；</p><p>16.<a href="http://research.microsoft.com/en-US/people/jamiesho/default.aspx" rel="external nofollow noreferrer" target="_blank">Jamie Shotton</a>：属微软剑桥研究中心，<strong>Decision/Regression Forests</strong>；</p><p>17.<a href="http://web.engr.oregonstate.edu/~sinisa/" rel="external nofollow noreferrer" target="_blank">Sinisa Todorovic</a>：俄勒冈州立，行为分析等；</p><p>18.<a href="http://www.cis.upenn.edu/~jshi/" rel="external nofollow noreferrer" target="_blank">Shi Jianbo</a>：大名鼎鼎的Good Feature to Track作者，目前方向行为分析和多目标跟踪等；</p><p>19.<a href="http://www.eng.tau.ac.il/~avidan/" rel="external nofollow noreferrer" target="_blank">Shai Avidan</a>：特拉维夫大学，大牛级，可算是Tracking-by-detection的开创者，Ensemble Tracking, SVM Tracking；</p><p>20.<a href="http://vipl.ict.ac.cn/" rel="external nofollow noreferrer" target="_blank">Visual Information Processing and Learning</a>：中科院计算所，山世光老师的研究组，不需介绍了吧；</p><p>21.<a href="http://www.eecs.qmul.ac.uk/~sgg/" rel="external nofollow noreferrer" target="_blank">Shaogang Gong</a>：Queen Mary University of London，各种PAMI，IJCV；</p><p>22.<a href="http://www.patternrecognition.cn/~jian/" rel="external nofollow noreferrer" target="_blank">Yang Jian</a>：南京理工大学，2DPCA，人脸识别；</p><p>23.<a href="http://groups.inf.ed.ac.uk/calvin/index.html" rel="external nofollow noreferrer" target="_blank">CALVIN</a>：weakly supervised learning，objectness；</p><p>24.<a href="http://www.lv-nus.org/" rel="external nofollow noreferrer" target="_blank">Learning &amp; Vision Group</a>：NUS，稀疏表示；</p><p>26.<a href="http://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noreferrer" target="_blank">Xiaogang Wang</a>：CUHK，active &amp; fruitful，行人检测，群体行为分析；</p><p>27.<a href="http://mmlab.ie.cuhk.edu.hk/archive/profile/bolei/" rel="external nofollow noreferrer" target="_blank">Zhou, Bolei</a>：上面Wang老师硕士研究生，群体行为，看看人家的Publications已经轻松甩国内博士好几条街；</p><p>28.<a href="http://vision.ics.uci.edu/index.html" rel="external nofollow noreferrer" target="_blank">Computational Vision Group</a>：Leader--<a href="http://www.ics.uci.edu/~dramanan/" rel="external nofollow noreferrer" target="_blank">Deva Ramanan</a>；</p><p>29.<a href="http://www4.comp.polyu.edu.hk/~cslzhang/" rel="external nofollow noreferrer" target="_blank">Zhang Lei</a>：香港理工，稀疏表示，人脸识别，可以算大中华区比较活跃的研究组了，几乎每篇论文都有对应<strong>源码</strong>；</p><p>30.<a href="http://www4.comp.polyu.edu.hk/~cskhzhang/" rel="external nofollow noreferrer" target="_blank">Zhang Kaihua</a>：上面Zhang老师学生，<a href="http://www4.comp.polyu.edu.hk/~cslzhang/CT/CT.htm" rel="external nofollow noreferrer" target="_blank">Compressive Tracking</a>；</p><p>31.<a href="http://iris.usc.edu/people/pksharma/index.html" rel="external nofollow noreferrer" target="_blank">Pramod Sharma</a>：离线训练检测器的在线自适应，貌似是个不错的topic；</p><p>32.<a href="http://www.lorisbazzani.info/#Pubs" rel="external nofollow noreferrer" target="_blank">Loris Bazzani</a>：person re-id，他的SDALF(<a href="http://www.lorisbazzani.info/code-datasets/sdalf-descriptor/" rel="external nofollow noreferrer" target="_blank">code</a>)描述子经常被用来做为比较对象，说明还是有参考价值的；</p><p>33.<a href="http://blog.csdn.net/gxf1027/article/details/Felzenszwalb" rel="external nofollow noreferrer" target="_blank">Pedro Felzenszwalb</a>：布朗大学，目标检测，新新N人一枚；</p><p>34.<a href="http://users.ece.cmu.edu/~kumar/" rel="external nofollow noreferrer" target="_blank">Vijayakumar Bhagavatula</a>：IEEE&nbsp;Fellow，&nbsp;correlation&nbsp;filters；</p><p>35.<a href="http://homepage.tudelft.nl/19j49/Home.html" rel="external nofollow noreferrer" target="_blank">Laurens van der Maaten</a>：MLer.</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p><strong>牛人主页（主页有很多论文代码）</strong></p><div><a href="http://cseweb.ucsd.edu/~sjb/" rel="external nofollow noreferrer" target="_blank">Serge Belongie</a>&nbsp;at UC San Diego</div><div><a href="http://web.mit.edu/torralba/www/" rel="external nofollow noreferrer" target="_blank">Antonio Torralba</a>&nbsp;at MIT</div><div><a href="http://www.cs.cmu.edu/~efros/" rel="external nofollow noreferrer" target="_blank">Alexei Ffros</a>&nbsp;at CMU</div><div><a href="http://people.csail.mit.edu/celiu/" rel="external nofollow noreferrer" target="_blank">Ce Liu</a>&nbsp;at Microsoft Research New England</div><div><a href="http://www.vision.ee.ethz.ch/~calvin/" rel="external nofollow noreferrer" target="_blank">Vittorio Ferrari</a>&nbsp;at Univ.of&nbsp;Edinburgh</div><div><a href="http://www.cs.utexas.edu/~grauman/" rel="external nofollow noreferrer" target="_blank">Kristen Grauman</a>&nbsp;at UT Austin</div><div><a href="http://ttic.uchicago.edu/~dparikh/index.html" rel="external nofollow noreferrer" target="_blank">Devi Parikh</a>&nbsp;at&nbsp;&nbsp;TTI-Chicago&nbsp;(Marr Prize at ICCV2011)</div><div><a href="http://www.columbia.edu/~jw2966/" rel="external nofollow noreferrer" target="_blank">John Wright</a>&nbsp;at Columbia Univ.</div><div><a href="http://vision.ucsd.edu/~pdollar/" rel="external nofollow noreferrer" target="_blank">Piotr Dollar</a>&nbsp;at CalTech</div><div><a href="http://vision.ucsd.edu/~bbabenko/" rel="external nofollow noreferrer" target="_blank">Boris Babenko</a>&nbsp;at UC San Diego</div><div><a href="http://www.cs.toronto.edu/~dross/" rel="external nofollow noreferrer" target="_blank">David Ross</a>&nbsp;at Google/Youtube</div><div><a href="http://www-stat.stanford.edu/~donoho/index.html" rel="external nofollow noreferrer" target="_blank">David Donoho</a>&nbsp;at Stanford Univ.</div><div>&nbsp;</div><div>&nbsp;</div><div><strong>大神们：</strong></div><div><strong>&nbsp;</strong></div><div><a href="http://people.csail.mit.edu/billf/" rel="external nofollow noreferrer" target="_blank">William T. Freeman</a>&nbsp;at MIT</div><div><a href="http://mi.eng.cam.ac.uk/~cipolla/index.htm" rel="external nofollow noreferrer" target="_blank">Roberto Cipolla</a>&nbsp;at Cambridge</div><div><a href="http://www.cs.ubc.ca/~lowe/" rel="external nofollow noreferrer" target="_blank">David Lowe</a>&nbsp;at Univ. of British Columbia</div><div><a href="http://server.cs.ucf.edu/~vision/faculty/shah.html" rel="external nofollow noreferrer" target="_blank">Mubarak Shah</a>&nbsp;at Univ. of Central Florida</div><div><a href="http://yima.csl.illinois.edu/" rel="external nofollow noreferrer" target="_blank">Yi Ma</a>&nbsp;at MSRA</div><div><a href="http://homes.esat.kuleuven.be/~tuytelaa/" rel="external nofollow noreferrer" target="_blank">Tinne Tuytelaars</a>&nbsp;at K.U. Leuven</div><div><a href="http://www.eecs.berkeley.edu/~trevor/" rel="external nofollow noreferrer" target="_blank">Trevor Darrell</a>&nbsp;at U.C. Berkeley</div><div><a href="http://www.cs.brown.edu/~black/" rel="external nofollow noreferrer" target="_blank">Michael J. Black</a>&nbsp;at Brown Univ.</div><div><strong>&nbsp;</strong></div><div><strong>&nbsp;</strong></div><div><strong>&nbsp;</strong></div><div><strong>&nbsp;</strong></div><div><strong>重要研究组：</strong></div><div><strong>&nbsp;</strong></div><div><a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/" rel="external nofollow noreferrer" target="_blank">Computer Vision Group</a>&nbsp;at UC Berkeley</div><div><a href="http://www.robots.ox.ac.uk/" rel="external nofollow noreferrer" target="_blank">Robotics Research Group</a>&nbsp;at Univ. of Oxford</div><div><a href="http://lear.inrialpes.fr/index.php" rel="external nofollow noreferrer" target="_blank">LEAR</a>&nbsp;at INRIA</div><div><a href="http://vision.stanford.edu/index.html" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at Stanford</div><div><a href="http://cvlab.epfl.ch/index.php" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at EPFL</div><div><a href="http://www.vision.ee.ethz.ch/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at ETH Zurich</div><div><a href="http://cv.snu.ac.kr/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at Seoul National Univ.</div><div><a href="http://vision.ucsd.edu/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at UC San Diego</div><div><a href="http://vision.soe.ucsc.edu/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at UC Santa Cruz</div><div><a href="http://iris.usc.edu/USC-Computer-Vision.html" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at Univ. of Southern California</div><div><a href="http://server.cs.ucf.edu/~vision/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at Univ. of Central Florida</div><div><a href="http://www1.cs.columbia.edu/CAVE/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab</a>&nbsp;at Columbia Univ.</div><div><a href="http://www.vision.cs.ucla.edu/index.html" rel="external nofollow noreferrer" target="_blank">UCLA Vision Lab</a></div><div><a href="http://masc.cs.gmu.edu/wiki/Home" rel="external nofollow noreferrer" target="_blank">Motion and Shape Computing Group</a>&nbsp;at George Mason Univ.</div><div><a href="http://coewww.rutgers.edu/riul/" rel="external nofollow noreferrer" target="_blank">Robust Image Understanding Lab</a>&nbsp;at Rutgers Univ.</div><div><a href="http://ivs.informatik.uni-bonn.de/index.html" rel="external nofollow noreferrer" target="_blank">Intelligent Vision Systems Group</a>&nbsp;at Univ. of Bonn</div><div><a href="http://www.icg.tugraz.at/" rel="external nofollow noreferrer" target="_blank">Institute for Computer Graphics and Vision</a>&nbsp;at Graz Univ. of Tech.</div><div><a href="http://www.caa.tuwien.ac.at/cvl/" rel="external nofollow noreferrer" target="_blank">Computer Vision Lab.</a>&nbsp;at Vienna Univ. of Tech.&nbsp;</div><div><a href="http://www.cir.meduniwien.ac.at/" rel="external nofollow noreferrer" target="_blank">Computational Image Analysis and Radiology</a>&nbsp;at Medical Univ. of Vienna</div><div><a href="http://personalrobotics.ri.cmu.edu/index.php" rel="external nofollow noreferrer" target="_blank"><strong>P</strong>ersonal&nbsp;<strong>R</strong>obotics&nbsp;<strong>L</strong>ab</a>&nbsp;at CMU</div><div><a href="http://bigbird.psych.purdue.edu/index.html" rel="external nofollow noreferrer" target="_blank">Visual Perception Lab</a>&nbsp;at Purdue Univ.</div><div><br>&nbsp;</div><div>&nbsp;</div><div><strong>潜力牛人：</strong></div><div><strong>&nbsp;</strong></div><div><a href="http://www.vision.ee.ethz.ch/~gallju/" rel="external nofollow noreferrer" target="_blank">Juergen Gall</a><em>&nbsp;</em>at<em>&nbsp;</em>ETH Zurich</div><div><a href="http://www.cc.gatech.edu/~mflagg/" rel="external nofollow noreferrer" target="_blank">Matt Flagg</a>&nbsp;at Georgia Tech.</div><div><a href="http://ttic.uchicago.edu/~salzmann/" rel="external nofollow noreferrer" target="_blank">Mathieu Salzmann</a>&nbsp;at TTI-Chicago</div><div><a href="http://www.cs.brown.edu/~gregory/" rel="external nofollow noreferrer" target="_blank">Gerg Shakhnarovich</a>&nbsp;at TTI-Chicago</div><div><a href="http://people.csail.mit.edu/taegsang/" rel="external nofollow noreferrer" target="_blank">Taeg Sang Cho</a>&nbsp;at MIT</div><div><a href="http://www.ifp.illinois.edu/~jyang29/index.html" rel="external nofollow noreferrer" target="_blank">Jianchao Yang</a>&nbsp;at UIUC</div><div><a href="http://www.gris.tu-darmstadt.de/~sroth/index.html" rel="external nofollow noreferrer" target="_blank">Stefan Roth</a>&nbsp;at TU Darmstadt</div><div><a href="http://www.student.tugraz.at/peter.kontschieder/index.html" rel="external nofollow noreferrer" target="_blank">Peter Kontschieder</a>&nbsp;at Graz Univ. of Tech.</div><div><a href="http://www.iai.uni-bonn.de/~kleind/" rel="external nofollow noreferrer" target="_blank">Dominik Alexander Klein</a>&nbsp;at Univ. of Bonn</div><div><a href="http://www.cbsr.ia.ac.cn/users/ynyu/" rel="external nofollow noreferrer" target="_blank">Yinan Yu</a>&nbsp;at CASIA (PASCAL VOC 2010 Detection Challenge Winner)</div><div><a href="http://info.ee.surrey.ac.uk/Personal/Z.Kalal/" rel="external nofollow noreferrer" target="_blank">Zdenek Kalal</a>&nbsp;at FPFL</div><div><a href="http://cvlab.epfl.ch/~jpilet/" rel="external nofollow noreferrer" target="_blank">Julien Pilet</a>&nbsp;at FPFL</div><div><a href="http://www.cs.ubc.ca/~okumak/index.html" rel="external nofollow noreferrer" target="_blank">Kenji Okuma</a></div><div>&nbsp;</div><div>2 个人、研究机构链接</div><div><p>（1）googleResearch；&nbsp;<a href="http://research.google.com/index.html" rel="external nofollow noreferrer" target="_blank">http://research.google.com/index.html</a><br>（2）MIT博士，汤晓欧学生林达华；<a href="http://people.csail.mit.edu/dhlin/index.html" rel="external nofollow noreferrer" target="_blank">http://people.csail.mit.edu/dhlin/index.html</a><br>（3）MIT博士后Douglas Lanman；&nbsp;<a href="http://web.media.mit.edu/~dlanman/" rel="external nofollow noreferrer" target="_blank">http://web.media.mit.edu/~dlanman/</a><br>（4）opencv中文网站；<a href="http://www.opencv.org.cn/index.php/%E9%A6%96%E9%A1%B5" rel="external nofollow noreferrer" target="_blank">http://www.opencv.org.cn/index.php/%E9%A6%96%E9%A1%B5</a><br>（5）Stanford大学vision实验室；&nbsp;<a href="http://vision.stanford.edu/research.html" rel="external nofollow noreferrer" target="_blank">http://vision.stanford.edu/research.html</a><br>（6）Stanford大学博士崔靖宇；&nbsp;<a href="http://www.stanford.edu/~jycui/" rel="external nofollow noreferrer" target="_blank">http://www.stanford.edu/~jycui/</a><br>（7）UCLA教授朱松纯；&nbsp;<a href="http://www.stat.ucla.edu/~sczhu/" rel="external nofollow noreferrer" target="_blank">http://www.stat.ucla.edu/~sczhu/</a><br>（8）中国人工智能网；&nbsp;<a href="http://www.chinaai.org/" rel="external nofollow noreferrer" target="_blank">http://www.chinaai.org/</a><br>（9）中国视觉网；&nbsp;<a href="http://www.china-vision.net/" rel="external nofollow noreferrer" target="_blank">http://www.china-vision.net/</a><br>（10）中科院自动化所；&nbsp;<a href="http://www.ia.cas.cn/" rel="external nofollow noreferrer" target="_blank">http://www.ia.cas.cn/</a><br>（11）中科院自动化所李子青研究员；&nbsp;<a href="http://www.cbsr.ia.ac.cn/users/szli/" rel="external nofollow noreferrer" target="_blank">http://www.cbsr.ia.ac.cn/users/szli/</a><br>（12）中科院计算所山世光研究员；&nbsp;<a href="http://www.jdl.ac.cn/user/sgshan/" rel="external nofollow noreferrer" target="_blank">http://www.jdl.ac.cn/user/sgshan/</a><br>（13）人脸识别主页；&nbsp;<a href="http://www.face-rec.org/" rel="external nofollow noreferrer" target="_blank">http://www.face-rec.org/</a><br>（14）加州大学伯克利分校CV小组；<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/" rel="external nofollow noreferrer" target="_blank">http://www.eecs.berkeley.edu/Research/Projects/CS/vision/</a></p><p>（15）南加州大学CV实验室；&nbsp;<a href="http://iris.usc.edu/USC-Computer-Vision.html" rel="external nofollow noreferrer" target="_blank">http://iris.usc.edu/USC-Computer-Vision.html</a><br>（16）卡内基梅隆大学CV主页；</p><p><a href="http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/vision.html" rel="external nofollow noreferrer" target="_blank">http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/vision.html</a></p><p>（17）微软CV研究员Richard Szeliski；<a href="http://research.microsoft.com/en-us/um/people/szeliski/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/um/people/szeliski/</a><br>（18）微软亚洲研究院计算机视觉研究组；&nbsp;<a href="http://research.microsoft.com/en-us/groups/vc/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/groups/vc/</a><br>（19）微软剑桥研究院ML与CV研究组；&nbsp;<a href="http://research.microsoft.com/en-us/groups/mlp/default.aspx" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/groups/mlp/default.aspx</a></p><p>（20）研学论坛；&nbsp;<a href="http://bbs.matwav.com/" rel="external nofollow noreferrer" target="_blank">http://bbs.matwav.com/</a><br>（21）美国Rutgers大学助理教授刘青山；<a href="http://www.research.rutgers.edu/~qsliu/" rel="external nofollow noreferrer" target="_blank">http://www.research.rutgers.edu/~qsliu/</a><br>（22）计算机视觉最新资讯网；&nbsp;<a href="http://www.cvchina.info/" rel="external nofollow noreferrer" target="_blank">http://www.cvchina.info/</a><br>（23）运动检测、阴影、跟踪的测试视频下载；<a href="http://apps.hi.baidu.com/share/detail/18903287" rel="external nofollow noreferrer" target="_blank">http://apps.hi.baidu.com/share/detail/18903287</a><br>（24）香港中文大学助理教授王晓刚；&nbsp;<a href="http://www.ee.cuhk.edu.hk/~xgwang/" rel="external nofollow noreferrer" target="_blank">http://www.ee.cuhk.edu.hk/~xgwang/</a><br>(25)香港中文大学多媒体实验室（汤晓鸥）;&nbsp;<a href="http://mmlab.ie.cuhk.edu.hk/" rel="external nofollow noreferrer" target="_blank">http://mmlab.ie.cuhk.edu.hk/</a><br>(26)U.C. San Diego. computer vision;<a href="http://vision.ucsd.edu/content/home" rel="external nofollow noreferrer" target="_blank">http://vision.ucsd.edu/content/home</a><br>(27)CVonline;&nbsp;<a href="http://homepages.inf.ed.ac.uk/rbf/CVonline/" rel="external nofollow noreferrer" target="_blank">http://homepages.inf.ed.ac.uk/rbf/CVonline/</a><br>(28)computer vision software;&nbsp;<a href="http://peipa.essex.ac.uk/info/software.html" rel="external nofollow noreferrer" target="_blank">http://peipa.essex.ac.uk/info/software.html</a><br>(29)Computer Vision Resource;&nbsp;<a href="http://www.cvpapers.com/" rel="external nofollow noreferrer" target="_blank">http://www.cvpapers.com/</a><br>(30)computer vision research groups;<a href="http://peipa.essex.ac.uk/info/groups.html" rel="external nofollow noreferrer" target="_blank">http://peipa.essex.ac.uk/info/groups.html</a><br>(31)computer vision center;&nbsp;<a href="http://computervisioncentral.com/cvcnews" rel="external nofollow noreferrer" target="_blank">http://computervisioncentral.com/cvcnews</a></p><p>(32)浙江大学图像技术研究与应用（ITRA）团队：<a href="http://www.dvzju.com/" rel="external nofollow noreferrer" target="_blank">http://www.dvzju.com/</a></p><p>(33)自动识别网：<a href="http://www.autoid-china.com.cn/" rel="external nofollow noreferrer" target="_blank">http://www.autoid-china.com.cn/</a></p><p>(34)清华大学章毓晋教授：<a href="http://www.tsinghua.edu.cn/publish/ee/4157/2010/20101217173552339241557/20101217173552339241557_.html" rel="external nofollow noreferrer" target="_blank">http://www.tsinghua.edu.cn/publish/ee/4157/2010/20101217173552339241557/20101217173552339241557_.html</a></p><p>(35)顶级民用机器人研究小组Porf.Gary领导的Willow Garage:<a href="http://www.willowgarage.com/" rel="external nofollow noreferrer" target="_blank">http://www.willowgarage.com/</a></p><p>(36)上海交通大学图像处理与模式识别研究所：<a href="http://www.pami.sjtu.edu.cn/" rel="external nofollow noreferrer" target="_blank">http://www.pami.sjtu.edu.cn/</a></p><p>(37)上海交通大学计算机视觉实验室刘允才教授：<a href="http://www.visionlab.sjtu.edu.cn/" rel="external nofollow noreferrer" target="_blank">http://www.visionlab.sjtu.edu.cn/</a></p><p>(38)德克萨斯州大学奥斯汀分校助理教授Kristen Grauman ：<a href="http://www.cs.utexas.edu/~grauman/" rel="external nofollow noreferrer" target="_blank">http://www.cs.utexas.edu/~grauman/</a>&nbsp;图像分解，检索</p><p>(39)清华大学电子工程系智能图文信息处理实验室（丁晓青教授）：<a href="http://ocrserv.ee.tsinghua.edu.cn/auto/index.asp" rel="external nofollow noreferrer" target="_blank">http://ocrserv.ee.tsinghua.edu.cn/auto/index.asp</a></p><p>(40)北京大学高文教授：<a href="http://www.jdl.ac.cn/htm-gaowen/" rel="external nofollow noreferrer" target="_blank">http://www.jdl.ac.cn/htm-gaowen/</a></p><p>(41)清华大学艾海舟教授：<a href="http://media.cs.tsinghua.edu.cn/cn/aihz" rel="external nofollow noreferrer" target="_blank">http://media.cs.tsinghua.edu.cn/cn/aihz</a></p><p>(42)中科院生物识别与安全技术研究中心：<a href="http://www.cbsr.ia.ac.cn/china/index%20CH.asp" rel="external nofollow noreferrer" target="_blank">http://www.cbsr.ia.ac.cn/china/index%20CH.asp</a></p><p>(43)瑞士巴塞尔大学 Thomas Vetter教授：<a href="http://informatik.unibas.ch/personen/vetter_t.html" rel="external nofollow noreferrer" target="_blank">http://informatik.unibas.ch/personen/vetter_t.html</a></p><p>(44)<span class="st">俄勒冈州立大学 Rob Hess博士：<a href="http://blogs.oregonstate.edu/hess/" rel="external nofollow noreferrer" target="_blank">http://blogs.oregonstate.edu/hess/</a></span></p><p>(45)深圳大学 于仕祺副教授：<a href="http://yushiqi.cn/" rel="external nofollow noreferrer" target="_blank">http://yushiqi.cn/</a></p><p>(46)西安交通大学人工智能与机器人研究所：<a href="http://www.aiar.xjtu.edu.cn/" rel="external nofollow noreferrer" target="_blank">http://www.aiar.xjtu.edu.cn/</a></p><p>(47)卡内基梅隆大学研究员Robert T. Collins:<a href="http://www.cs.cmu.edu/~rcollins/home.html#Background" rel="external nofollow noreferrer" target="_blank">http://www.cs.cmu.edu/~rcollins/home.html#Background</a></p><p>(48)MIT博士Chris Stauffer:<a href="http://people.csail.mit.edu/stauffer/Home/index.php" rel="external nofollow noreferrer" target="_blank">http://people.csail.mit.edu/stauffer/Home/index.php</a></p><p>(49)美国密歇根州立大学生物识别研究组(Anil K. Jain教授)：<a href="http://www.cse.msu.edu/rgroups/biometrics/" rel="external nofollow noreferrer" target="_blank">http://www.cse.msu.edu/rgroups/biometrics/</a></p><p>(50)美国伊利诺伊州立大学Thomas S. Huang:<a href="http://www.beckman.illinois.edu/directory/t-huang1" rel="external nofollow noreferrer" target="_blank">http://www.beckman.illinois.edu/directory/t-huang1</a></p><p>(51)武汉大学数字摄影测量与计算机视觉研究中心：<a href="http://www.whudpcv.cn/index.asp" rel="external nofollow noreferrer" target="_blank">http://www.whudpcv.cn/index.asp</a></p><p>(52)瑞士巴塞尔大学Sami Romdhani助理研究员：<a href="http://informatik.unibas.ch/personen/romdhani_sami/" rel="external nofollow noreferrer" target="_blank">http://informatik.unibas.ch/personen/romdhani_sami/</a></p><p>(53)CMU大学研究员Yang Wang:<a href="http://www.cs.cmu.edu/~wangy/home.html" rel="external nofollow noreferrer" target="_blank">http://www.cs.cmu.edu/~wangy/home.html</a></p><p>(54)英国曼彻斯特大学Tim Cootes教授：<a href="http://personalpages.manchester.ac.uk/staff/timothy.f.cootes/" rel="external nofollow noreferrer" target="_blank">http://personalpages.manchester.ac.uk/staff/timothy.f.cootes/</a></p><p>(55)美国罗彻斯特大学教授Jiebo Luo:<a href="http://www.cs.rochester.edu/u/jluo/" rel="external nofollow noreferrer" target="_blank">http://www.cs.rochester.edu/u/jluo/</a></p><p>(56)美国普渡大学机器人视觉实验室：<a href="https://engineering.purdue.edu/RVL/Welcome.html" rel="external nofollow noreferrer" target="_blank">https://engineering.purdue.edu/RVL/Welcome.html</a></p><p>(57)美国宾利州立大学感知、运动与认识实验室：<a href="http://vision.cse.psu.edu/home/home.shtml" rel="external nofollow noreferrer" target="_blank">http://vision.cse.psu.edu/home/home.shtml</a></p><p>(58)美国宾夕法尼亚大学GRASP实验室：<a href="https://www.grasp.upenn.edu/" rel="external nofollow noreferrer" target="_blank">https://www.grasp.upenn.edu/</a></p><p>(59)美国内达华大学里诺校区CV实验室：<a href="http://www.cse.unr.edu/CVL/index.php" rel="external nofollow noreferrer" target="_blank">http://www.cse.unr.edu/CVL/index.php</a></p><p>(60)美国密西根大学vision实验室：<a href="http://www.eecs.umich.edu/vision/index.html" rel="external nofollow noreferrer" target="_blank">http://www.eecs.umich.edu/vision/index.html</a></p><p>(61)University of Massachusetts(麻省大学),视觉实验室：<a href="http://vis-www.cs.umass.edu/index.html" rel="external nofollow noreferrer" target="_blank">http://vis-www.cs.umass.edu/index.html</a></p><p>(62)华盛顿大学博士后Iva Kemelmacher:<a href="http://www.cs.washington.edu/homes/kemelmi" rel="external nofollow noreferrer" target="_blank">http://www.cs.washington.edu/homes/kemelmi</a></p><p>(63)以色列魏茨曼科技大学Ronen Basri:<a href="http://www.wisdom.weizmann.ac.il/~ronen/index.html" rel="external nofollow noreferrer" target="_blank">http://www.wisdom.weizmann.ac.il/~ronen/index.html</a></p><p>(64)瑞士ETH-Zurich大学CV实验室：<a href="http://www.vision.ee.ethz.ch/boostingTrackers/index.htm" rel="external nofollow noreferrer" target="_blank">http://www.vision.ee.ethz.ch/boostingTrackers/index.htm</a></p><p>(65)微软CV研究员张正友：<a href="http://research.microsoft.com/en-us/um/people/zhang/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/um/people/zhang/</a></p><p>(66)中科院自动化所医学影像研究室：<a href="http://www.3dmed.net/" rel="external nofollow noreferrer" target="_blank">http://www.3dmed.net/</a></p><p>(67)中科院田捷研究员：<a href="http://www.3dmed.net/tian/" rel="external nofollow noreferrer" target="_blank">http://www.3dmed.net/tian/</a></p><p>(68)微软Redmond研究院研究员Simon Baker:<a href="http://research.microsoft.com/en-us/people/sbaker/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/people/sbaker/</a></p><p>(69)普林斯顿大学教授李凯：<a href="http://www.cs.princeton.edu/~li/" rel="external nofollow noreferrer" target="_blank">http://www.cs.princeton.edu/~li/</a><br>(70)普林斯顿大学博士贾登：<a href="http://www.cs.princeton.edu/~jiadeng/" rel="external nofollow noreferrer" target="_blank">http://www.cs.princeton.edu/~jiadeng/</a><br>(71)牛津大学教授Andrew Zisserman：&nbsp;<a href="http://www.robots.ox.ac.uk/~az/" rel="external nofollow noreferrer" target="_blank">http://www.robots.ox.ac.uk/~az/</a><br>(72)英国leeds大学研究员Mark Everingham:<a href="http://www.comp.leeds.ac.uk/me/" rel="external nofollow noreferrer" target="_blank">http://www.comp.leeds.ac.uk/me/</a><br>(73)英国爱丁堡大学教授Chris William:&nbsp;<a href="http://homepages.inf.ed.ac.uk/ckiw/" rel="external nofollow noreferrer" target="_blank">http://homepages.inf.ed.ac.uk/ckiw/</a><br>(74)微软剑桥研究院研究员John Winn:&nbsp;<a href="http://johnwinn.org/" rel="external nofollow noreferrer" target="_blank">http://johnwinn.org/</a><br>(75)佐治亚理工学院教授Monson H.Hayes：<a href="http://savannah.gatech.edu/people/mhayes/index.html" rel="external nofollow noreferrer" target="_blank">http://savannah.gatech.edu/people/mhayes/index.html</a><br>(76)微软亚洲研究院研究员孙剑：<a href="http://research.microsoft.com/en-us/people/jiansun/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/people/jiansun/</a><br>(77)微软亚洲研究院研究员马毅：<a href="http://research.microsoft.com/en-us/people/mayi/" rel="external nofollow noreferrer" target="_blank">http://research.microsoft.com/en-us/people/mayi/</a><br>(78)英国哥伦比亚大学教授David Lowe:&nbsp;<a href="http://www.cs.ubc.ca/~lowe/" rel="external nofollow noreferrer" target="_blank">http://www.cs.ubc.ca/~lowe/</a><br>(79)英国爱丁堡大学教授Bob Fisher:&nbsp;<a href="http://homepages.inf.ed.ac.uk/rbf/" rel="external nofollow noreferrer" target="_blank">http://homepages.inf.ed.ac.uk/rbf/</a><br>(80)加州大学圣地亚哥分校教授Serge J.Belongie:<a href="http://cseweb.ucsd.edu/~sjb/" rel="external nofollow noreferrer" target="_blank">http://cseweb.ucsd.edu/~sjb/</a><br>(81)威斯康星大学教授Charles R.Dyer:&nbsp;<a href="http://pages.cs.wisc.edu/~dyer/" rel="external nofollow noreferrer" target="_blank">http://pages.cs.wisc.edu/~dyer/</a><br>(82)多伦多大学教授Allan.Jepson:&nbsp;<a href="http://www.cs.toronto.edu/~jepson/" rel="external nofollow noreferrer" target="_blank">http://www.cs.toronto.edu/~jepson/</a><br>(83)伦斯勒理工学院教授Qiang Ji:&nbsp;<a href="http://www.ecse.rpi.edu/~qji/" rel="external nofollow noreferrer" target="_blank">http://www.ecse.rpi.edu/~qji/</a><br>(84)CMU研究员Daniel Huber:&nbsp;<a href="http://www.ri.cmu.edu/person.html?person_id=123" rel="external nofollow noreferrer" target="_blank">http://www.ri.cmu.edu/person.html?person_id=123</a><br>(85)多伦多大学教授：David J.Fleet:&nbsp;<a href="http://www.cs.toronto.edu/~fleet/" rel="external nofollow noreferrer" target="_blank">http://www.cs.toronto.edu/~fleet/</a><br>(86)伦敦大学玛丽女王学院教授Andrea Cavallaro:<a href="http://www.eecs.qmul.ac.uk/~andrea/" rel="external nofollow noreferrer" target="_blank">http://www.eecs.qmul.ac.uk/~andrea/</a><br>(87)多伦多大学教授Kyros Kutulakos:&nbsp;<a href="http://www.cs.toronto.edu/~kyros/" rel="external nofollow noreferrer" target="_blank">http://www.cs.toronto.edu/~kyros/</a><br>(88)杜克大学教授Carlo Tomasi:&nbsp;<a href="http://www.cs.duke.edu/~tomasi/" rel="external nofollow noreferrer" target="_blank">http://www.cs.duke.edu/~tomasi/</a><br>(89)CMU教授Martial Hebert:&nbsp;<a href="http://www.cs.cmu.edu/~hebert/" rel="external nofollow noreferrer" target="_blank">http://www.cs.cmu.edu/~hebert/</a><br>(90)MIT助理教授Antonio Torralba:&nbsp;<a href="http://web.mit.edu/torralba/www/" rel="external nofollow noreferrer" target="_blank">http://web.mit.edu/torralba/www/</a><br>(91)马里兰大学研究员Yasel Yacoob:&nbsp;<a href="http://www.umiacs.umd.edu/users/yaser/" rel="external nofollow noreferrer" target="_blank">http://www.umiacs.umd.edu/users/yaser/</a><br>(92)康奈尔大学教授Ramin Zabih:&nbsp;<a href="http://www.cs.cornell.edu/~rdz/" rel="external nofollow noreferrer" target="_blank">http://www.cs.cornell.edu/~rdz/</a></p><p>(93)CMU博士田渊栋: http://www.cs.cmu.edu/~yuandong/<br>(94)CMU副教授Srinivasa Narasimhan: http://www.cs.cmu.edu/~srinivas/<br>(95)CMU大学ILIM实验室：http://www.cs.cmu.edu/~ILIM/<br>(96)哥伦比亚大学教授Sheer K.Nayar: http://www.cs.columbia.edu/~nayar/<br>(97)三菱电子研究院研究员Fatih Porikli ：http://www.porikli.com/<br>(98)康奈尔大学教授Daniel Huttenlocher：http://www.cs.cornell.edu/~dph/<br>(99)南京大学教授周志华：http://cs.nju.edu.cn/zhouzh/index.htm<br>(100)芝加哥丰田技术研究所助理教授Devi Parikh: http://ttic.uchicago.edu/~dparikh/index.html<br>(101)瑞士联邦理工学院博士后Helmut Grabner:<a href="http://www.vision.ee.ethz.ch/~hegrabne/#Short_CV" rel="external nofollow noreferrer" target="_blank">http://www.vision.ee.ethz.ch/~hegrabne/#Short_CV</a></p><p>(102)香港中文大学教授贾佳亚：<a href="http://www.cse.cuhk.edu.hk/~leojia/index.html" rel="external nofollow noreferrer" target="_blank">http://www.cse.cuhk.edu.hk/~leojia/index.html</a></p><p>(103)南京大学教授吴建鑫：<a href="http://c2inet.sce.ntu.edu.sg/Jianxin/index.html" rel="external nofollow noreferrer" target="_blank">http://c2inet.sce.ntu.edu.sg/Jianxin/index.html</a></p><p>(104)GE研究院研究员李关：<a href="http://www.cs.unc.edu/~lguan/" rel="external nofollow noreferrer" target="_blank">http://www.cs.unc.edu/~lguan/</a></p><p>(105)佐治亚理工学院教授Monson Hayes:<a href="http://savannah.gatech.edu/people/mhayes/" rel="external nofollow noreferrer" target="_blank">http://savannah.gatech.edu/people/mhayes/</a></p><p>(106)图片检索国际竞赛PASCAL VOC(微软剑桥研究院组织):<a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" rel="external nofollow noreferrer" target="_blank">http://pascallin.ecs.soton.ac.uk/challenges/VOC/</a></p><p>(107)机器视觉开源处理库汇总：<a href="http://archive.cnblogs.com/a/2217609/" rel="external nofollow noreferrer" target="_blank">http://archive.cnblogs.com/a/2217609/</a></p><p>(108)布朗大学教授Benjamin Kimia:&nbsp;<a href="http://www.lems.brown.edu/kimia.html" rel="external nofollow noreferrer" target="_blank">http://www.lems.brown.edu/kimia.html</a>&nbsp;</p><p>(109)数据堂-图像处理相关的样本数据：<a href="http://www.datatang.com/data/list/602026/p1" rel="external nofollow noreferrer" target="_blank">http://www.datatang.com/data/list/602026/p1</a></p><p>(110)东软基于CV的汽车辅助驾驶系统：<a href="http://www.neusoft.com/cn/solutions/1047/" rel="external nofollow noreferrer" target="_blank">http://www.neusoft.com/cn/solutions/1047/</a></p><p>(111)马里兰大学教授Rema Chellappa:<a href="http://www.cfar.umd.edu/~rama/" rel="external nofollow noreferrer" target="_blank">http://www.cfar.umd.edu/~rama/</a></p><p>(112)芝加哥丰田研究中心助理教授Devi Parikh：<a href="http://ttic.uchicago.edu/~dparikh/index.html" rel="external nofollow noreferrer" target="_blank">http://ttic.uchicago.edu/~dparikh/index.html</a></p><p>(113)宾夕法尼亚大学助理教授石建波：<a href="http://www.cis.upenn.edu/~jshi/" rel="external nofollow noreferrer" target="_blank">http://www.cis.upenn.edu/~jshi/</a></p><p>(114)比利时鲁汶大学教授Luc Van Gool：<a href="http://www.vision.ee.ethz.ch/members/get_member.cgi?id=1" rel="external nofollow noreferrer" target="_blank">http://www.vision.ee.ethz.ch/members/get_member.cgi?id=1</a>,&nbsp;<a href="http://www.vision.ee.ethz.ch/~vangool/" rel="external nofollow noreferrer" target="_blank">http://www.vision.ee.ethz.ch/~vangool/</a></p><p>(115)行人检测主页：<a href="http://www.pedestrian-detection.com/" rel="external nofollow noreferrer" target="_blank">http://www.pedestrian-detection.com/</a></p><p>(116)法国学习算法与系统实验室Basilio Noris博士：<a href="http://lasa.epfl.ch/people/member.php?SCIPER=129576" rel="external nofollow noreferrer" target="_blank">http://lasa.epfl.ch/people/member.php?SCIPER=129576</a>&nbsp;<a href="http://mldemos.epfl.ch/" rel="external nofollow noreferrer" target="_blank">http://mldemos.epfl.ch/</a></p><p>(117)美国马里兰大学LARRY S.DAVIS教授：<a href="http://www.umiacs.umd.edu/~lsd/" rel="external nofollow noreferrer" target="_blank">http://www.umiacs.umd.edu/~lsd/</a></p><p>(118)计算机视觉论文分类导航：<a href="http://www.visionbib.com/bibliography/contents.html" rel="external nofollow noreferrer" target="_blank">http://www.visionbib.com/bibliography/contents.html</a></p><p>(119)计算机视觉分类信息导航：<a href="http://www.visionbib.com/" rel="external nofollow noreferrer" target="_blank">http://www.visionbib.com/</a></p><p>(120)西班牙马德里理工大学博士Marcos Nieto：<a href="http://marcosnieto.net/" rel="external nofollow noreferrer" target="_blank">http://marcosnieto.net/</a></p><p>(121)香港理工大学副教授张磊：<a href="http://www4.comp.polyu.edu.hk/~cslzhang/" rel="external nofollow noreferrer" target="_blank">http://www4.comp.polyu.edu.hk/~cslzhang/</a></p><p>(122)以色列技术学院教授Michael Elad：<a href="http://www.cs.technion.ac.il/~elad/" rel="external nofollow noreferrer" target="_blank">http://www.cs.technion.ac.il/~elad/</a></p><p>(123)韩国启明大学计算机视觉与模式识别实验室：<a href="http://cvpr.kmu.ac.kr/" rel="external nofollow noreferrer" target="_blank">http://cvpr.kmu.ac.kr/</a></p><p>(124)英国诺丁汉大学Michel Valstar博士：<a href="http://www.cs.nott.ac.uk/~mfv/" rel="external nofollow noreferrer" target="_blank">http://www.cs.nott.ac.uk/~mfv/</a></p><p>(125)卡内基梅隆大学Takeo Kanade教授:<a href="http://www.ri.cmu.edu/people/kanade_takeo.html" rel="external nofollow noreferrer" target="_blank">http://www.ri.cmu.edu/people/kanade_takeo.html</a></p><p>(126)微软学术搜索：<a href="http://libra.msra.cn/" rel="external nofollow noreferrer" target="_blank">http://libra.msra.cn/</a></p><p>(127)比利时天主教鲁汶大学Radu Timofte博士：<a href="http://homes.esat.kuleuven.be/~rtimofte/" rel="external nofollow noreferrer" target="_blank">http://homes.esat.kuleuven.be/~rtimofte/</a>，交通标志检测，定位，3D跟踪</p><p>(128)迪斯尼匹兹堡研究院研究员：Iain Matthews:<a href="http://www.iainm.com/iainm/Home.html" rel="external nofollow noreferrer" target="_blank">http://www.iainm.com/iainm/Home.html</a></p><p><a href="http://www.ri.cmu.edu/person.html?type=publications&amp;person_id=741" rel="external nofollow noreferrer" target="_blank">http://www.ri.cmu.edu/person.html?type=publications&amp;person_id=741</a>&nbsp;AAM,三维重建</p><p>（129）康奈尔大学视觉与图像分析组：http://www.via.cornell.edu/ 医学图像处理</p><p>（130）密西根州立大学生物识别研究组：http://www.cse.msu.edu/biometrics/ 人脸识别、指纹识别、图像检索<br>（131）柏林科技大学计算机视觉与遥感实验室：http://www.cv.tu-berlin.de/menue/computer_vision_remote_sensing/parameter/en/ 图像分析、物体重建、基于图像的表面测量、医学图像处理</p><p>（132）英国布里斯托大学数字多媒体研究组：http://www.cs.bris.ac.uk/Research/Digitalmedia/ 运动检测与跟踪、视频压缩、3D重建、字符定位</p><p>（133）英国萨利大学视觉、语音与信号处理中心： http://www.surrey.ac.uk/cvssp/ &nbsp; 人脸识别、监控、3D、视频检索、<br>（134）北卡莱罗纳大学教堂山分校Marc Pollefeys教授：http://www.cs.unc.edu/~marc/ 基于视频的3D模型生成、相机标定、运动检测与分析、3D重建</p><p>（135）澳大利亚国立大学Richard Hartley教授：http://users.cecs.anu.edu.au/~hartley/ 运动估计、稀疏子空间、跟踪、</p><p>（136）百度技术副总监于凯：http://www.dbs.ifi.lmu.de/~yu_k/ 深度学习，稀疏表示，图像分类</p><p>（137）西安电子科技大学高新波教授：http://web.xidian.edu.cn/xbgao/index.html&nbsp;质量评判、水印、稀疏表示、超分辨率</p><p>（138）加州大学伯克利分校Michael I.Jordan教授：http://www.cs.berkeley.edu/~jordan/ 机器学习</p><p>（139）加州理工行人检测相关资料：http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/</p><p>（140）微软Redmond研究院研究员Piotr Dollar:&nbsp;http://vision.ucsd.edu/~pdollar/ 行人检测、特征提取、</p><p>（141）视觉计算研究论坛：http://www.sigvc.org/bbs/ 中科院视觉计算研究小组的论坛</p><p>（142）美国坦桑尼亚州立大学稀疏学习软件包：http://www.public.asu.edu/~jye02/Software/SLEP/index.htm 稀疏学习</p><p>（143）美国加州大学圣地亚哥分校Jacob Whitehill博士：http://mplab.ucsd.edu/~jake/ 机器学习</p><p>（144）美国布朗大学Michael J.Black教授：http://cs.brown.edu/~black/ &nbsp;人的姿态估计和跟踪</p><p>（145）美国加州大学圣地亚哥分校David Kriegman教授：http://cseweb.ucsd.edu/~kriegman/ 人脸识别</p><p>（146）南加州大学Paul Debevec教授：http://ict.debevec.org/~debevec/ 或&nbsp;http://www.pauldebevec.com/&nbsp;将CV和CG结合研究&nbsp;人脸捕捉重建技术</p><p>（147）伊利诺伊大学D.A.Forsyth教授：http://luthuli.cs.uiuc.edu/~daf/ 三维重建</p><p>（148）英国牛津大学Ian Reid教授：http://www.robots.ox.ac.uk/~ian/&nbsp;跟踪和机器人导航</p><p>（149）CMU大学Alyosha Efros 教授:&nbsp;https://www.cs.cmu.edu/~efros/ 图像纹理合成</p><p>（150）加州大学伯克利分校Jitendra Malik教授：http://www.cs.berkeley.edu/~malik/&nbsp;轮廓检测、图像/视频分割、图形匹配、目标识别</p><p>（151）MIT教授William Freeman：&nbsp;http://people.csail.mit.edu/billf/ 图像纹理合成</p><p>（152）CMU博士Henry Schneiderman：&nbsp;http://www.cs.cmu.edu/~hws/&nbsp;目标检测和识别；</p><p>（153）微软研究员Paul Viola:&nbsp;http://research.microsoft.com/en-us/um/people/viola/ AdaBoost算法</p><p>（154）微软研究员Antonio Criminisi:&nbsp;http://research.microsoft.com/en-us/people/antcrim/ 图像修补，三维重建，目标检测与跟踪；</p><p>（155）魏茨曼科学研究所教授Michal Irani:&nbsp;http://www.wisdom.weizmann.ac.il/~irani/ 超分辨率</p><p>（156）瑞士洛桑理工学院Pascal Fua教授：http://people.epfl.ch/pascal.fua/bio?lang=en 立体视觉，增强现实</p><p>（157）佐治亚理工学院Irfan Essa教授：http://www.ic.gatech.edu/people/irfan-essa 人脸表情识别</p><p>（158）中科院助理教授樊彬：http://www.sigvc.org/bfan/ 特征描述；</p><p>（159）斯坦福大学Sebastian Thrun教授：<a href="http://robots.stanford.edu/index.html" rel="external nofollow noreferrer" target="_blank">http://robots.stanford.edu/index.html</a>&nbsp;机器人；</p><p>（160）多伦多大学Geoffrey E.Hinton教授：<a href="http://www.cs.toronto.edu/~hinton/" rel="external nofollow noreferrer" target="_blank">http://www.cs.toronto.edu/~hinton/</a>&nbsp;深度学习</p><p>（161）凤巢系统架构师张栋博士：<a href="http://weibo.com/machinelearning" rel="external nofollow noreferrer" target="_blank">http://weibo.com/machinelearning</a></p><p>（162）2012年龙星计划机器学习课程：<a href="http://bigeye.au.tsinghua.edu.cn/DragonStar2012/index.html" rel="external nofollow noreferrer" target="_blank">http://bigeye.au.tsinghua.edu.cn/DragonStar2012/index.html</a></p><p>（163）中科院自动化所肖柏华教授：<a href="http://www.compsys.ia.ac.cn/people/xiaobaihua.html" rel="external nofollow noreferrer" target="_blank">http://www.compsys.ia.ac.cn/people/xiaobaihua.html</a>&nbsp;文字识别、人脸识别、质量评判</p><p>（164）图像视频质量评判：<a href="http://live.ece.utexas.edu/research/quality/" rel="external nofollow noreferrer" target="_blank">http://live.ece.utexas.edu/research/quality/</a></p><p>（165）纽约大学Yann LeCun教授<a href="http://yann.lecun.com/" rel="external nofollow noreferrer" target="_blank">http://yann.lecun.com/</a>&nbsp; &nbsp;<a href="http://yann.lecun.com/exdb/mnist/" rel="external nofollow noreferrer" target="_blank">http://yann.lecun.com/exdb/mnist/</a>&nbsp; 手写体数字识别</p><p>（166）二维条码识别开源库zxing：<a href="http://code.google.com/p/zxing/" rel="external nofollow noreferrer" target="_blank">http://code.google.com/p/zxing/</a></p><p>（167）布朗大学Pedro Felzenszwalb教授：<a href="http://cs.brown.edu/~pff/" rel="external nofollow noreferrer" target="_blank">http://cs.brown.edu/~pff/</a>&nbsp;特征提取，Deformable Part Model</p><p>（168）伊利诺伊香槟大学Svetlana Lazebnik教授：<a href="http://www.cs.illinois.edu/homes/slazebni/" rel="external nofollow noreferrer" target="_blank">http://www.cs.illinois.edu/homes/slazebni/</a>&nbsp;特征提取，聚类，图像检索</p><p>（169）荷兰乌德勒支大学图像与多媒体研究中心<a href="http://www.cs.uu.nl/centers/give/multimedia/index.html" rel="external nofollow noreferrer" target="_blank">http://www.cs.uu.nl/centers/give/multimedia/index.html</a>&nbsp;图像、多媒体检索与匹配</p><p>（170）英国格拉斯哥大学信息检索小组：<a href="http://ir.dcs.gla.ac.uk/" rel="external nofollow noreferrer" target="_blank">http://ir.dcs.gla.ac.uk/</a>&nbsp;文本、图像、视频检索</p><p>（171）中科院自动化所孙哲南助理教书：<a href="http://www.cbsr.ia.ac.cn/users/znsun/" rel="external nofollow noreferrer" target="_blank">http://www.cbsr.ia.ac.cn/users/znsun/</a>&nbsp;虹膜识别、掌纹识别、人脸识别</p><p>（172）南京信息工程大学刘青山教授：<a href="http://www.jstuoke.com/web/xky/detail.asp?NewsID=1096" rel="external nofollow noreferrer" target="_blank">http://www.jstuoke.com/web/xky/detail.asp?NewsID=1096</a>&nbsp;人脸图像分析、医学图像分析</p><p>（173）清华大学助理教授冯建江：<a href="http://ivg.au.tsinghua.edu.cn/~jfeng/" rel="external nofollow noreferrer" target="_blank">http://ivg.au.tsinghua.edu.cn/~jfeng/</a>&nbsp;指纹识别</p><p>（174）北航助理教授黄迪：<a href="http://irip.buaa.edu.cn/~dihuang/" rel="external nofollow noreferrer" target="_blank">http://irip.buaa.edu.cn/~dihuang/</a>&nbsp;3D人脸识别</p><p>（175）中山大学助理教授郑伟诗：<a href="http://sist.sysu.edu.cn/~zhwshi/" rel="external nofollow noreferrer" target="_blank">http://sist.sysu.edu.cn/~zhwshi/</a>&nbsp;人脸识别、特征匹配、聚类、检索；</p><p>（176）google瑞士苏黎世的工程师Thomas Deselaers:&nbsp;<a href="http://thomas.deselaers.de/index.html" rel="external nofollow noreferrer" target="_blank">http://thomas.deselaers.de/index.html</a>&nbsp;图像检索</p><p>（177）百度深度学习研究中心博士后余轶南：<a href="http://www.cbsr.ia.ac.cn/users/ynyu/index.htm" rel="external nofollow noreferrer" target="_blank">http://www.cbsr.ia.ac.cn/users/ynyu/index.htm</a>&nbsp;目标检测，图像检索</p><p>（178）威兹曼科技大学超分辨率：<a href="http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html" rel="external nofollow noreferrer" target="_blank">http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html</a></p><p>（179）德克萨斯大学奥斯汀分校Al Bovik教授：<a href="http://live.ece.utexas.edu/people/bovik/" rel="external nofollow noreferrer" target="_blank">http://live.ece.utexas.edu/people/bovik/</a>&nbsp;图像视频质量判别、特征提取</p><p>（180）以色列希伯来大学Yair Weiss教授：<a href="http://www.cs.huji.ac.il/~yweiss/" rel="external nofollow noreferrer" target="_blank">http://www.cs.huji.ac.il/~yweiss/</a>&nbsp;机器学习、超分辨率</p><p>（181）以色列希伯来大学Daniel Zoran博士：<a href="http://www.cs.huji.ac.il/~daniez/" rel="external nofollow noreferrer" target="_blank">http://www.cs.huji.ac.il/~daniez/</a>&nbsp;超分辨率、去噪</p><p>（182）美国加州大学Peyman Milanfar教授：<a href="http://users.soe.ucsc.edu/~milanfar/" rel="external nofollow noreferrer" target="_blank">http://users.soe.ucsc.edu/~milanfar/</a>&nbsp;去噪</p><p>（183）中科院计算所副研究员常虹：<a href="http://www.jdl.ac.cn/user/hchang/index.html" rel="external nofollow noreferrer" target="_blank">http://www.jdl.ac.cn/user/hchang/index.html</a>&nbsp;图像检索、半监督学习、超分辨率</p><p>（184）以色列威茨曼大学Anat Levin教授：<a href="http://www.wisdom.weizmann.ac.il/~levina/" rel="external nofollow noreferrer" target="_blank">http://www.wisdom.weizmann.ac.il/~levina/</a>&nbsp;去噪、去模糊</p><p>（185）以色列威茨曼大学Daniel Glasner博士后：<a href="http://www.wisdom.weizmann.ac.il/~glasner/" rel="external nofollow noreferrer" target="_blank">http://www.wisdom.weizmann.ac.il/~glasner/</a>&nbsp;超分辨率、分割、姿态估计</p><p>（186）密西根大学助理教授Honglak Lee:&nbsp;<a href="http://web.eecs.umich.edu/~honglak/" rel="external nofollow noreferrer" target="_blank">http://web.eecs.umich.edu/~honglak/</a>&nbsp;机器学习、特征提取，去噪、稀疏表示；</p><p>（187）MIT周博磊博士：<a href="http://people.csail.mit.edu/bzhou/" rel="external nofollow noreferrer" target="_blank">http://people.csail.mit.edu/bzhou/</a>&nbsp;聚集分析、运动检测</p><p>（188）美国田纳西大学Li He博士：<a href="http://web.eecs.utk.edu/~lhe4/" rel="external nofollow noreferrer" target="_blank">http://web.eecs.utk.edu/~lhe4/</a>&nbsp;稀疏表示、超分辨率；</p><p>（189）Adobe研究院Jianchao Yang研究员：<a href="http://www.ifp.illinois.edu/~jyang29/" rel="external nofollow noreferrer" target="_blank">http://www.ifp.illinois.edu/~jyang29/</a>&nbsp;稀疏表示，超分辨率、图片检索、去噪、去模糊</p><p>（190）Deep Learning主页：<a href="http://deeplearning.net/" rel="external nofollow noreferrer" target="_blank">http://deeplearning.net/</a>&nbsp;深度学习论文、软件，代码，demo，数据等；</p><p>（191）斯坦福大学Andrew Ng教授：<a href="http://cs.stanford.edu/people/ang/" rel="external nofollow noreferrer" target="_blank">http://cs.stanford.edu/people/ang/</a>&nbsp;深度神经网络，深度学习</p><p>（192）Elefant:&nbsp;<a href="http://elefant.developer.nicta.com.au/" rel="external nofollow noreferrer" target="_blank">http://elefant.developer.nicta.com.au/</a>&nbsp;机器学习开源库</p><p>（193）微软研究员Ce Liu:&nbsp;<a href="http://people.csail.mit.edu/celiu/" rel="external nofollow noreferrer" target="_blank">http://people.csail.mit.edu/celiu/</a>&nbsp;去噪、超分辨率、去模糊、分割</p><p>（194）West Virginia大学助理教授Xin Li:&nbsp;<a href="http://www.csee.wvu.edu/~xinl/" rel="external nofollow noreferrer" target="_blank">http://www.csee.wvu.edu/~xinl/</a>&nbsp;边缘检测、降噪、去模糊</p><p>（195）<a href="http://www.csee.wvu.edu/~xinl/source.html" rel="external nofollow noreferrer" target="_blank">http://www.csee.wvu.edu/~xinl/source.html</a>&nbsp;深度学习、去噪、编码、压缩感知、超分辨率、聚类、分割等相关代码集合</p><p>（196）西班牙格拉纳达大学超分辨率重建项目组：<a href="http://decsai.ugr.es/pi/superresolution/index.html" rel="external nofollow noreferrer" target="_blank">http://decsai.ugr.es/pi/superresolution/index.html</a></p><p>（197）清华大学程明明博士：<a href="http://mmcheng.net/" rel="external nofollow noreferrer" target="_blank">http://mmcheng.net/</a>&nbsp;图像分割、检索</p><p>（198）牛津布鲁克斯大学Philip H.S.Torr教授：<a href="http://cms.brookes.ac.uk/staff/PhilipTorr/" rel="external nofollow noreferrer" target="_blank">http://cms.brookes.ac.uk/staff/PhilipTorr/</a>&nbsp;分割、三维重建</p><p>（199）佐治亚理工学院James M.Rehg教授：<a href="http://www.cc.gatech.edu/~rehg/" rel="external nofollow noreferrer" target="_blank">http://www.cc.gatech.edu/~rehg/</a>&nbsp;分割、行人检测、特征描述、</p><p>（200）大规模图像分类、检测竞赛ILSVRC（Stanford, Google举办）:</p><p>&nbsp;<a href="http://www.image-net.org/challenges/LSVRC/2013/" rel="external nofollow noreferrer" target="_blank">http://www.image-net.org/challenges/LSVRC/2013/</a></p><p>（201）加州大学尔湾分校Deva Ramanan助理教授：<a href="http://www.ics.uci.edu/~dramanan/" rel="external nofollow noreferrer" target="_blank">http://www.ics.uci.edu/~dramanan/</a>&nbsp;目标检测，行人检测，跟踪、稀疏表示</p><p>（202）人脸识别测试图片集：<a href="http://www.mlcv.net/" rel="external nofollow noreferrer" target="_blank">http://www.mlcv.net/</a></p><p>（203）美国西北大学博士Ming Yang:&nbsp;http://www.ece.northwestern.edu/~mya671/ 人脸识别、图像检索；</p><p>（204）美国加州大学伯克利分校博士后Ross B.Girshick：http://www.cs.berkeley.edu/~rbg/ 目标检测（DPM）</p><p>（205）中文语言资源联盟：http://www.chineseldc.org/index.html &nbsp;内有很多语言识别、字符识别的训练，测试库；</p><p>（206）西班牙巴塞罗那大学计算机视觉中心：http://www.cvc.uab.es/adas/site/ 检测、跟踪、3D、行人检测、汽车辅助驾驶</p><p>（207）德国戴姆勒研究所<span>Prof. Dr. Dariu M. Gavrila：http://www.gavrila.net/index.html 跟踪、行人检测、</span></p><p>（208）苏黎世联邦理工学院Andreas Ess博士后：http://www.vision.ee.ethz.ch/~aess/ 行人检测、行为检测、跟踪</p><p>（209）Libqrencode:&nbsp;http://fukuchi.org/works/qrencode/ 基于C语言的QR二维码编码开源库</p><p>（210）江西财经大学袁飞牛教授：http://sit.jxufe.cn/grbk/yfn/index.html# &nbsp;烟雾检测、3D重建、医学图像处理</p><p>（211）耶路撒冷大学Raanan Fattal教师：http://www.cs.huji.ac.il/~raananf/ &nbsp;图像增强、</p><p>（212）耶路撒冷大学Dani Lischnski教授：http://www.cs.huji.ac.il/~danix/ 去模糊、纹理合成、图像增强</p><p>3 代码汇总</p><p>&nbsp;</p><p>一、特征提取Feature Extraction：</p><ul><li><p>SIFT [1] [<a href="http://www.cs.ubc.ca/~lowe/keypoints/siftDemoV4.zip" rel="external nofollow noreferrer" target="_blank">Demo program</a>][<a href="http://blogs.oregonstate.edu/hess/code/sift/" rel="external nofollow noreferrer" target="_blank">SIFT Library</a>] [<a href="http://www.vlfeat.org/" rel="external nofollow noreferrer" target="_blank">VLFeat</a>]</p></li><li><p>PCA-SIFT [2] [<a href="http://www.cs.cmu.edu/~yke/pcasift/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Affine-SIFT [3] [<a href="http://www.ipol.im/pub/algo/my_affine_sift/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>SURF [4] [<a href="http://www.chrisevansdev.com/computer-vision-opensurf.html" rel="external nofollow noreferrer" target="_blank">OpenSURF</a>] [<a href="http://www.maths.lth.se/matematiklth/personal/petter/surfmex.php" rel="external nofollow noreferrer" target="_blank">Matlab Wrapper</a>]</p></li><li><p>Affine Covariant Features [5] [<a href="http://www.robots.ox.ac.uk/~vgg/research/affine/" rel="external nofollow noreferrer" target="_blank">Oxford project</a>]</p></li><li><p>MSER [6] [<a href="http://www.robots.ox.ac.uk/~vgg/research/affine/" rel="external nofollow noreferrer" target="_blank">Oxford project</a>] [<a href="http://www.vlfeat.org/" rel="external nofollow noreferrer" target="_blank">VLFeat</a>]</p></li><li><p>Geometric Blur [7] [<a href="http://www.robots.ox.ac.uk/~vgg/software/MKL/" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Local Self-Similarity Descriptor [8] [<a href="http://www.robots.ox.ac.uk/~vgg/software/SelfSimilarity/" rel="external nofollow noreferrer" target="_blank">Oxford implementation</a>]</p></li><li><p>Global and Efficient Self-Similarity [9] [<a href="http://www.vision.ee.ethz.ch/~calvin/gss/selfsim_release1.0.tgz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Histogram of Oriented Graidents [10] [<a href="http://www.navneetdalal.com/software" rel="external nofollow noreferrer" target="_blank">INRIA Object Localization Toolkit</a>] [<a href="http://www.computing.edu.au/~12482661/hog.html" rel="external nofollow noreferrer" target="_blank">OLT toolkit for Windows</a>]</p></li><li><p>GIST [11] [<a href="http://people.csail.mit.edu/torralba/code/spatialenvelope/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Shape Context [12] [<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/sc_digits.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Color Descriptor [13] [<a href="http://koen.me/research/colordescriptors/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Pyramids of Histograms of Oriented Gradients [<a href="http://www.robots.ox.ac.uk/~vgg/research/caltech/phog/phog.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Space-Time Interest Points (STIP) [14][<a href="http://www.nada.kth.se/cvap/abstracts/cvap284.html" rel="external nofollow noreferrer" target="_blank">Project</a>] [<a href="http://www.irisa.fr/vista/Equipe/People/Laptev/download/stip-1.1-winlinux.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Boundary Preserving Dense Local Regions [15][<a href="http://vision.cs.utexas.edu/projects/bplr/bplr.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Weighted Histogram[<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/whistc.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Histogram-based Interest Points Detectors[<a href="http://www.cs.nthu.edu.tw/~htchen/hipd_cvpr09.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://740-2.cs.nthu.edu.tw/~htchen/hipd/hist_corner.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>An OpenCV - C++ implementation of Local Self Similarity Descriptors [<a href="http://intuitionlogic.com/post/2011/04/11/A-OpenCV-C++-implementation-of-Local-Self-Similarity-Descriptors.aspx" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Fast Sparse Representation with Prototypes[<a href="http://faculty.ucmerced.edu/mhyang/cvpr10_fsr.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Corner Detection [<a href="http://kiwi.cs.dal.ca/~dparks/CornerDetection/index.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>AGAST Corner Detector: faster than FAST and even FAST-ER[<a href="http://www6.in.tum.de/Main/ResearchAgast" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Real-time Facial Feature Detection using Conditional Regression Forests[<a href="http://files.is.tue.mpg.de/jgall/projects/facialfeatures/facialfeatures.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Global and Efficient Self-Similarity for Object Classification and Detection[<a href="http://groups.inf.ed.ac.uk/calvin/gss/selfsim_release1.0.tgz" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li><li><p>WαSH: Weighted α-Shapes for Local Feature Detection[<a href="http://image.ntua.gr/iva/research/wash/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>HOG[<a href="http://soc.fudan.edu.cn/vip/projects/gradproj/wiki/HOG%E4%BB%A3%E7%A0%81" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Online Selection of Discriminative Tracking Features[<a href="http://www.cs.ucla.edu/~roozbehm/cs7495/report.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>二、图像分割Image Segmentation：</p><ul><li><p>Normalized Cut [1] [<a href="http://www.cis.upenn.edu/~jshi/software/" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Gerg Mori’ Superpixel code [2] [<a href="http://www.cs.sfu.ca/~mori/research/superpixels/" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Efficient Graph-based Image Segmentation [3] [<a href="http://people.cs.uchicago.edu/~pff/segment/" rel="external nofollow noreferrer" target="_blank">C++ code</a>] [<a href="http://www.mathworks.com/matlabcentral/fileexchange/25866-efficient-graph-based-image-segmentation" rel="external nofollow noreferrer" target="_blank">Matlab wrapper</a>]</p></li><li><p>Mean-Shift Image Segmentation [4] [<a href="http://coewww.rutgers.edu/riul/research/code/EDISON/index.html" rel="external nofollow noreferrer" target="_blank">EDISON C++ code</a>] [<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/edison_matlab_interface.tar.gz" rel="external nofollow noreferrer" target="_blank">Matlab wrapper</a>]</p></li><li><p>OWT-UCM Hierarchical Segmentation [5] [<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="external nofollow noreferrer" target="_blank">Resources</a>]</p></li><li><p>Turbepixels [6] [<a href="http://www.cs.toronto.edu/~babalex/turbopixels_code.tar.gz" rel="external nofollow noreferrer" target="_blank">Matlab code 32bit</a>] [<a href="http://www.cs.toronto.edu/~babalex/TurboPixels64.rar" rel="external nofollow noreferrer" target="_blank">Matlab code 64bit</a>] [<a href="http://www.cs.toronto.edu/~babalex/superpixels_update.tgz" rel="external nofollow noreferrer" target="_blank">Updated code</a>]</p></li><li><p>Quick-Shift [7] [<a href="http://www.vlfeat.org/overview/quickshift.html" rel="external nofollow noreferrer" target="_blank">VLFeat</a>]</p></li><li><p>SLIC Superpixels [8] [<a href="http://ivrgwww.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Segmentation by Minimum Code Length [9] [<a href="http://perception.csl.uiuc.edu/coding/image_segmentation/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Biased Normalized Cut [10] [<a href="http://www.cs.berkeley.edu/~smaji/projects/biasedNcuts/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Segmentation Tree [11-12] [<a href="http://vision.ai.uiuc.edu/segmentation" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Entropy Rate Superpixel Segmentation [13] [<a href="http://www.umiacs.umd.edu/~mingyliu/src/ers_matlab_wrapper_v0.1.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Fast Approximate Energy Minimization via Graph Cuts[<a href="http://www.csd.uwo.ca/faculty/olga/Papers/pami01_final.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://vision.csd.uwo.ca/code/gco-v3.0.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Efﬁcient Planar Graph Cuts with Applications in Computer Vision[<a href="http://www.csd.uwo.ca/~schmidtf/pdf/schmidt_et_al_cvpr09.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://vision.csd.uwo.ca/code/PlanarCut-v1.0.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Isoperimetric Graph Partitioning for Image Segmentation[<a href="http://www.cns.bu.edu/~lgrady/grady2006isoperimetric.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.cns.bu.edu/~lgrady/grady2006isoperimetric_code.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Random Walks for Image Segmentation[<a href="http://www.cns.bu.edu/~lgrady/grady2006random.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.cns.bu.edu/~lgrady/random_walker_matlab_code.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Blossom V: A new implementation of a minimum cost perfect matching algorithm[<a href="http://pub.ist.ac.at/~vnk/software/blossom5-v2.03.src.tar.gz%20%20http:/pub.ist.ac.at/~vnk/software/blossom5-v2.03.src.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Computer Vision[<a href="http://www.csd.uwo.ca/~yuri/Papers/pami04.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://pub.ist.ac.at/~vnk/software/maxflow-v3.01.src.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Geodesic Star Convexity for Interactive Image Segmentation[<a href="http://www.robots.ox.ac.uk/~vgg/software/iseg/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Contour Detection and Image Segmentation Resources[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" rel="external nofollow noreferrer" target="_blank">Project</a>][<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_source.tgz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Biased Normalized Cuts[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/biasedNcuts/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Max-flow/min-cut[<a href="http://vision.csd.uwo.ca/code/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Chan-Vese Segmentation using Level Set[<a href="http://www.ipol.im/pub/art/2012/g-cv/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>A Toolbox of Level Set Methods[<a href="http://www.cs.ubc.ca/~mitchell/ToolboxLS/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Re-initialization Free Level Set Evolution via Reaction Diffusion[<a href="http://www4.comp.polyu.edu.hk/~cslzhang/RD/RD.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Improved C-V active contour model[<a href="http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.rar" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>A Variational Multiphase Level Set Approach to Simultaneous Segmentation and Bias Correction[<a href="http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICIP10_SVMLS.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/SVMLS_v0.rar" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Level Set Method Research by Chunming Li[<a href="http://www.engr.uconn.edu/~cmli/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>ClassCut for Unsupervised Class Segmentation[<a href="http://groups.inf.ed.ac.uk/calvin/classcut/ClassCut-release_v1.0.zip" rel="external nofollow noreferrer" target="_blank">cod</a>e]</p></li><li><p>SEEDS: Superpixels Extracted via Energy-Driven Sampling&nbsp;<a href="http://www.vision.ee.ethz.ch/~vamichae/seeds/" rel="external nofollow noreferrer" target="_blank">[Project</a>][<a href="http://www.mvdblive.org/seeds/" rel="external nofollow noreferrer" target="_blank">other</a>]</p></li></ul><br><p>三、目标检测Object Detection：</p><ul><li><p>A simple object detector with boosting [<a href="http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>INRIA Object Detection and Localization Toolkit [1] [<a href="http://pascal.inrialpes.fr/soft/olt/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Discriminatively Trained Deformable Part Models [2] [<a href="http://people.cs.uchicago.edu/~pff/latent/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Cascade Object Detection with Deformable Part Models [3] [<a href="http://people.cs.uchicago.edu/~rbg/star-cascade/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Poselet [4] [<a href="http://www.eecs.berkeley.edu/~lbourdev/poselets/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Implicit Shape Model [5] [<a href="http://www.vision.ee.ethz.ch/~bleibe/code/ism.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Viola and Jones’s Face Detection [6] [<a href="http://pr.willowgarage.com/wiki/Face_detection" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Bayesian Modelling of Dyanmic Scenes for Object Detection[<a href="http://vision.eecs.ucf.edu/papers/01512057.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://vision.eecs.ucf.edu/Code/Background.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Hand detection using multiple proposals[<a href="http://www.robots.ox.ac.uk/~vgg/software/hands/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Color Constancy, Intrinsic Images, and Shape Estimation[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/BarronMalikECCV2012.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.cs.berkeley.edu/~barron/BarronMalikECCV2012_code.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Discriminatively trained deformable part models[<a href="http://people.cs.uchicago.edu/~rbg/latent/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Gradient Response Maps for Real-Time Detection of Texture-Less Objects: LineMOD [<a href="http://campar.cs.tum.edu/Main/StefanHinterstoisser" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Image Processing On Line[<a href="http://www.ipol.im/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Robust Optical Flow Estimation[<a href="http://www.ipol.im/pub/pre/21/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Where's Waldo: Matching People in Images of Crowds[<a href="http://homes.cs.washington.edu/~rahul/data/WheresWaldo.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Scalable Multi-class Object Detection[<a href="http://files.is.tue.mpg.de/jgall/projects/houghMC/houghMC.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Class-Specific Hough Forests for Object Detection[<a href="http://files.is.tue.mpg.de/jgall/projects/houghforest/houghforest.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Deformed Lattice Detection In Real-World Images[<a href="http://vision.cse.psu.edu/data/data.shtml" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Discriminatively trained deformable part models[<a href="http://people.cs.uchicago.edu/~rbg/latent/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>四、显著性检测Saliency Detection：</p><ul><li><p>Itti, Koch, and Niebur’ saliency detection [1] [<a href="http://www.saliencytoolbox.net/" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Frequency-tuned salient region detection [2] [<a href="http://ivrgwww.epfl.ch/supplementary_material/RK_CVPR09/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Saliency detection using maximum symmetric surround [3] [<a href="http://ivrg.epfl.ch/supplementary_material/RK_ICIP2010/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Attention via Information Maximization [4] [<a href="http://www.cse.yorku.ca/~neil/AIM.zip" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Context-aware saliency detection [5] [<a href="http://webee.technion.ac.il/labs/cgm/Computer-Graphics-Multimedia/Software/Saliency/Saliency.html" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Graph-based visual saliency [6] [<a href="http://www.klab.caltech.edu/~harel/share/gbvs.php" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Saliency detection: A spectral residual approach. [7] [<a href="http://www.klab.caltech.edu/~xhou/projects/spectralResidual/spectralresidual.html" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Segmenting salient objects from images and videos. [8] [<a href="http://www.cse.oulu.fi/MVG/Downloads/saliency" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Saliency Using Natural statistics. [9] [<a href="http://cseweb.ucsd.edu/~l6zhang/" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Discriminant Saliency for Visual Recognition from Cluttered Scenes. [10] [<a href="http://www.svcl.ucsd.edu/projects/saliency/" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Learning to Predict Where Humans Look [11] [<a href="http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Global Contrast based Salient Region Detection [12] [<a href="http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Bayesian Saliency via Low and Mid Level Cues[<a href="http://ice.dlut.edu.cn/lu/Project/TIP_scm/TIP_scm.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Top-Down Visual Saliency via Joint CRF and Dictionary Learning[<a href="http://faculty.ucmerced.edu/mhyang/papers/cvpr12a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/top-down-saliency.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Saliency Detection: A Spectral Residual Approach[<a href="http://www.klab.caltech.edu/~xhou/projects/dva/dva.html" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li></ul><br><p>五、图像分类、聚类Image Classification, Clustering</p><ul><li><p>Pyramid Match [1] [<a href="http://people.csail.mit.edu/jjl/libpmk/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Spatial Pyramid Matching [2] [<a href="http://www.cs.unc.edu/~lazebnik/research/SpatialPyramid.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Locality-constrained Linear Coding [3] [<a href="http://www.ifp.illinois.edu/~jyang29/LLC.htm" rel="external nofollow noreferrer" target="_blank">Project</a>] [<a href="http://www.ifp.illinois.edu/~jyang29/codes/CVPR10-LLC.rar" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Sparse Coding [4] [<a href="http://www.ifp.illinois.edu/~jyang29/ScSPM.htm" rel="external nofollow noreferrer" target="_blank">Project</a>] [<a href="http://www.ifp.illinois.edu/~jyang29/codes/CVPR09-ScSPM.rar" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Texture Classification [5] [<a href="http://www.robots.ox.ac.uk/~vgg/research/texclass/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Multiple Kernels for Image Classification [6] [<a href="http://www.robots.ox.ac.uk/~vgg/software/MKL/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Feature Combination [7] [<a href="http://www.vision.ee.ethz.ch/~pgehler/projects/iccv09/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>SuperParsing [<a href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/eccv10-jtighe-code.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Large Scale Correlation Clustering Optimization[<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/LargeScaleCC1.0.tar.gz" rel="external nofollow noreferrer" target="_blank">Matlab code</a>]</p></li><li><p>Detecting and Sketching the Common[<a href="http://www.wisdom.weizmann.ac.il/~vision/SketchTheCommon" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Self-Tuning Spectral Clustering[<a href="http://www.vision.caltech.edu/lihi/Demos/SelfTuningClustering.html" rel="external nofollow noreferrer" target="_blank">Project</a>][<a href="http://www.vision.caltech.edu/lihi/Demos/SelfTuning/ZPclustering.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>User Assisted Separation of Reflections from a Single Image Using a Sparsity Prior[<a href="http://www.wisdom.weizmann.ac.il/~levina/papers/assisted-eccv04.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.wisdom.weizmann.ac.il/~levina/papers/reflections.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Filters for Texture Classification[<a href="http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html#download" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Multiple Kernel Learning for Image Classification[<a href="http://www.robots.ox.ac.uk/~vgg/software/MKL/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>SLIC Superpixels[<a href="http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>六、抠图Image Matting</p><ul><li><p>A Closed Form Solution to Natural Image Matting [<a href="http://people.csail.mit.edu/alevin/matting.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Spectral Matting [<a href="http://www.vision.huji.ac.il/SpectralMatting/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Learning-based Matting [<a href="http://www.mathworks.com/matlabcentral/fileexchange/31412" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li></ul><br><p>七、目标跟踪Object Tracking：</p><ul><li><p>A Forest of Sensors - Tracking Adaptive Background Mixture Models [<a href="http://www.ai.mit.edu/projects/vsam/Tracking/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Object Tracking via Partial Least Squares Analysis[<a href="http://faculty.ucmerced.edu/mhyang/papers/tip12_pls_tracking.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/PLS_tracker_tip.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Robust Object Tracking with Online Multiple Instance Learning[<a href="http://faculty.ucmerced.edu/mhyang/papers/pami11b.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Online Visual Tracking with Histograms and Articulating Blocks[<a href="http://www.cise.ufl.edu/~smshahed/tracking.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Incremental Learning for Robust Visual Tracking[<a href="http://www.cs.toronto.edu/~dross/ivt/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Real-time Compressive Tracking[<a href="http://www4.comp.polyu.edu.hk/~cslzhang/CT/CT.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Robust Object Tracking via Sparsity-based Collaborative Model[<a href="http://faculty.ucmerced.edu/mhyang/project/cvpr12_scm.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Visual Tracking via Adaptive Structural Local Sparse Appearance Model[<a href="http://faculty.ucmerced.edu/mhyang/project/cvpr12_jia_project.htm" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Online Discriminative Object Tracking with Local Sparse Representation[<a href="http://faculty.ucmerced.edu/mhyang/papers/wacv12a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/wacv12a_code.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Superpixel Tracking[<a href="http://faculty.ucmerced.edu/mhyang/papers/iccv11a.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Learning Hierarchical Image Representation with Sparsity, Saliency and Locality[<a href="http://faculty.ucmerced.edu/mhyang/papers/bmvc11a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/BMVC11-HSSL-package.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Online Multiple Support Instance Tracking [<a href="http://faculty.ucmerced.edu/mhyang/papers/fg11a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/fg11_omsit.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Visual Tracking with Online Multiple Instance Learning[<a href="http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Object detection and recognition[<a href="http://c2inet.sce.ntu.edu.sg/Jianxin/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Compressive Sensing Resources[<a href="http://dsp.rice.edu/cs" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Robust Real-Time Visual Tracking using Pixel-Wise Posteriors[<a href="http://www.robots.ox.ac.uk/~cbibby/index.shtml" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Tracking-Learning-Detection[<a href="http://info.ee.surrey.ac.uk/Personal/Z.Kalal/" rel="external nofollow noreferrer" target="_blank">Project</a>][<a href="https://github.com/arthurv/OpenTLD" rel="external nofollow noreferrer" target="_blank">OpenTLD/C++ Code</a>]</p></li><li><p>the HandVu：vision-based hand gesture interface[<a href="http://ilab.cs.ucsb.edu/index.php/component/content/article/12/29" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities[<a href="http://files.is.tue.mpg.de/jgall/projects/stochGPLVM/stochGPLVM.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>八、Kinect：</p><ul><li><p>Kinect toolbox[<a href="http://kinecttoolbox.codeplex.com/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>OpenNI[<a href="http://www.openni.org/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>zouxy09 CSDN Blog[<a href="http://blog.csdn.net/zouxy09/article/details/8145688" rel="external nofollow noreferrer" target="_blank">Resource</a>]</p></li><li><p>FingerTracker 手指跟踪[<a href="http://makematics.com/code/FingerTracker/" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li></ul><br><p>九、3D相关：</p><ul><li><p>3D Reconstruction of a Moving Object[<a href="http://www.wisdom.weizmann.ac.il/~ronen/papers/Simakov%20Frolova%20Basri%20-%20Dense%20Shape%20Reconstruction%20Under%20Arbitrary%20Unknown%20Lighting.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>] [<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/SFB_matlab1.0.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Shape From Shading Using Linear Approximation[<a href="http://vision.eecs.ucf.edu/shadsrc.html" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Combining Shape from Shading and Stereo Depth Maps[<a href="http://vision.eecs.ucf.edu/combsrc.html" rel="external nofollow noreferrer" target="_blank">Project</a>][<a href="http://vision.eecs.ucf.edu/projects/ShapeFromShading/combine.tar.Z" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Shape from Shading: A Survey[<a href="http://vision.eecs.ucf.edu/papers/shah/99/ZTCS99.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://vision.eecs.ucf.edu/projects/ShapeFromShading/SFS_Survey_1_00.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>A Spatio-Temporal Descriptor based on 3D Gradients [HOG3D][<a href="http://lear.inrialpes.fr/people/klaeser/research_hog3d" rel="external nofollow noreferrer" target="_blank">Project</a>](<a href="http://lear.inrialpes.fr/people/klaeser/software_3d_video_descriptor" rel="external nofollow noreferrer" target="_blank">Code</a>)</p></li><li><p>Multi-camera Scene Reconstruction via Graph Cuts[<a href="http://www.cs.cornell.edu/~rdz/papers/kz-eccv02-recon.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://pub.ist.ac.at/~vnk/software/match-v3.4.src.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>A Fast Marching Formulation of Perspective Shape from Shading under Frontal Illumination[<a href="http://www.cs.ucf.edu/~vision" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.ee.cityu.edu.hk/~syyuen/Public/SfS/PRL_Perspective_FMM.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Reconstruction:3D Shape, Illumination, Shading, Reflectance, Texture[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Monocular Tracking of 3D Human Motion with a Coordinated Mixture of Factor Analyzers[<a href="http://faculty.ucmerced.edu/mhyang/code/PackagedTrackingCode.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Learning 3-D Scene Structure from a Single Still Image[<a href="http://ai.stanford.edu/~asaxena/reconstruction3d/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十、机器学习算法：</p><ul><li><p>Matlab class for computing Approximate Nearest Nieghbor (ANN) [<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/ann_wrapper_Mar2012.tar.gz" rel="external nofollow noreferrer" target="_blank">Matlab class</a>&nbsp;providing interface to<a href="http://www.cs.umd.edu/~mount/ANN/" rel="external nofollow noreferrer" target="_blank">ANN library</a>]</p></li><li><p>Random Sampling[<a href="http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/weight_sample.tar.gz" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li><li><p>Probabilistic Latent Semantic Analysis [pLSA](<a href="http://www.robots.ox.ac.uk/~vgg/software/pLSA/pLSA_demo.tgz" rel="external nofollow noreferrer" target="_blank">Code</a>)</p></li><li><p>FASTANN and FASTCLUSTER for approximate k-means [AKM](<a href="http://www.robots.ox.ac.uk/~vgg/software/fastann/" rel="external nofollow noreferrer" target="_blank">Project</a>)</p></li><li><p>Fast Intersection / Additive Kernel SVMs[<a href="http://www.cs.berkeley.edu/~smaji/projects/fiksvm/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>SVM[<a href="http://osmot.cs.cornell.edu/svm_light/" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Ensemble learning[<a href="http://c2inet.sce.ntu.edu.sg/Jianxin/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Deep Learning[<a href="http://deeplearning.net/" rel="external nofollow noreferrer" target="_blank">Net</a>]</p></li><li><p>Deep Learning Methods for Vision[<a href="http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Neural Network for Recognition of Handwritten Digits[<a href="http://www.codeproject.com/KB/library/NeuralNetRecognition.aspx" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Training a deep autoencoder or a classifier on MNIST digits[<a href="http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>THE MNIST DATABASE of handwritten digits[<a href="http://yann.lecun.com/exdb/mnist/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Ersatz：deep neural networks in the cloud[<a href="http://www.ersatz1.com/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Deep Learning [<a href="http://www.cs.nyu.edu/~yann/research/deep/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>sparseLM : Sparse Levenberg-Marquardt nonlinear least squares in C/C++[<a href="http://www.ics.forth.gr/~lourakis/sparseLM/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Weka 3: Data Mining Software in Java[<a href="http://www.cs.waikato.ac.nz/ml/weka/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Invited talk "A Tutorial on Deep Learning" by Dr. Kai Yu [余凯](<a href="http://vipl.ict.ac.cn/News/academic-report-tutorial-deep-learning-dr-kai-yu" rel="external nofollow noreferrer" target="_blank">Video</a>)</p></li><li><p>CNN - Convolutional neural network class[<a href="http://www.mathworks.cn/matlabcentral/fileexchange/24291" rel="external nofollow noreferrer" target="_blank">Matlab Tool</a>]</p></li><li><p>Yann LeCun's Publications[<a href="http://yann.lecun.com/exdb/publis/index.html#lecun-98" rel="external nofollow noreferrer" target="_blank">Wedsite</a>]</p></li><li><p>LeNet-5, convolutional neural networks[<a href="http://yann.lecun.com/exdb/lenet/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Training a deep autoencoder or a classifier on MNIST digits[<a href="http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Deep Learning 大牛Geoffrey E. Hinton's HomePage[<a href="http://www.cs.toronto.edu/~hinton/" rel="external nofollow noreferrer" target="_blank">Website</a>]</p></li><li><p>Multiple Instance Logistic Discriminant-based Metric Learning (MildML) and Logistic Discriminant-based Metric Learning [LDML](<a href="http://lear.inrialpes.fr/people/guillaumin/code.php#mildml" rel="external nofollow noreferrer" target="_blank">Code</a>)</p></li><li><p>Sparse coding simulation software[<a href="http://redwood.berkeley.edu/bruno/sparsenet/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Visual Recognition and Machine Learning Summer School[<a href="http://lear.inrialpes.fr/software" rel="external nofollow noreferrer" target="_blank">Software</a>]</p></li></ul><br><p>十一、目标、行为识别Object, Action Recognition：</p><ul><li><p>Action Recognition by Dense Trajectories[<a href="http://lear.inrialpes.fr/people/wang/dense_trajectories" rel="external nofollow noreferrer" target="_blank">Project</a>][<a href="http://lear.inrialpes.fr/people/wang/download/dense_trajectory_release.tar.gz" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Action Recognition Using a Distributed Representation of Pose and Appearance[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/action/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Recognition Using Regions[<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam-cvpr09.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam_cvpr09_v2.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>2D Articulated Human Pose Estimation[<a href="http://www.vision.ee.ethz.ch/~calvin/articulated_human_pose_estimation_code/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Fast Human Pose Estimation Using Appearance and Motion via Multi-Dimensional Boosting Regression[<a href="http://faculty.ucmerced.edu/mhyang/papers/cvpr07a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://www.cise.ufl.edu/~smshahed/cvpr07_fast_human_pose.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Estimating Human Pose from Occluded Images[<a href="http://faculty.ucmerced.edu/mhyang/papers/accv09a.pdf" rel="external nofollow noreferrer" target="_blank">Paper</a>][<a href="http://faculty.ucmerced.edu/mhyang/code/accv09_pose.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Quasi-dense wide baseline matching[<a href="http://www.ee.oulu.fi/~jkannala/quasidense/quasidense.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>ChaLearn Gesture Challenge: Principal motion: PCA-based reconstruction of motion histograms[<a href="http://gesture.chalearn.org/data/sample-code" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Real Time Head Pose Estimation with Random Regression Forests[<a href="http://files.is.tue.mpg.de/jgall/projects/RFhead/RFhead.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>2D Action Recognition Serves 3D Human Pose Estimation[</p></li><li><p>A Hough Transform-Based Voting Framework for Action Recognition[</p></li><li><p>Motion Interchange Patterns for Action Recognition in Unconstrained Videos[</p></li><li><p>2D articulated human pose estimation software[<a href="http://groups.inf.ed.ac.uk/calvin/articulated_human_pose_estimation_code/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Learning and detecting shape models [<a href="http://groups.inf.ed.ac.uk/calvin/release-learn-shapes-v1.3.tgz" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li><li><p>Progressive Search Space Reduction for Human Pose Estimation[<a href="http://www.robots.ox.ac.uk/~vgg/software/UpperBody/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Learning Non-Rigid 3D Shape from 2D Motion[<a href="http://movement.stanford.edu/learning-nr-shape/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十二、图像处理：</p><ul><li><p>Distance Transforms of Sampled Functions[<a href="http://cs.brown.edu/~pff/dt/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>The Computer Vision Homepage[<a href="http://www.cs.cmu.edu/~cil/vision.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Efficient appearance distances between windows[<a href="http://groups.inf.ed.ac.uk/calvin/efficientAppDistances/releaseEfficientAppDistances.zip" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li><li><p>Image Exploration algorithm[<a href="http://groups.inf.ed.ac.uk/calvin/ReleasedCode/image_exploration_v1.1.tgz" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li><li><p>Motion Magnification 运动放大 [<a href="http://people.csail.mit.edu/celiu/motionmag/motionmag.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Bilateral Filtering for Gray and Color Images 双边滤波器 [<a href="http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>A Fast Approximation of the Bilateral Filter using a Signal Processing Approach [</p></li></ul><br><p>十三、一些实用工具：</p><ul><li><p>EGT: a Toolbox for Multiple View Geometry and Visual Servoing[<a href="http://egt.dii.unisi.it/" rel="external nofollow noreferrer" target="_blank">Project</a>] [<a href="http://egt.dii.unisi.it/download/EGT_v1p3.zip" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>a development kit of matlab mex functions for OpenCV library[<a href="http://www.cs.stonybrook.edu/~kyamagu/mexopencv/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Fast Artificial Neural Network Library[<a href="http://leenissen.dk/fann/wp/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十四、人手及指尖检测与识别：</p><ul><li><p>finger-detection-and-gesture-recognition [<a href="http://code.google.com/p/finger-detection-and-gesture-recognition/downloads/list" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li><li><p>Hand and Finger Detection using JavaCV[<a href="http://www.javacodegeeks.com/2012/12/hand-and-finger-detection-using-javacv.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+JavaCodeGeeks+%28Java+Code+Geeks%29" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Hand and fingers detection[<a href="http://forum.openframeworks.cc/index.php?topic=1916.0" rel="external nofollow noreferrer" target="_blank">Code</a>]</p></li></ul><br><p>十五、场景解释：</p><ul><li><p>Nonparametric Scene Parsing via Label Transfer [<a href="http://people.csail.mit.edu/celiu/LabelTransfer/code.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十六、光流Optical flow：</p><ul><li><p>High accuracy optical flow using a theory for warping [<a href="http://perception.inrialpes.fr/~chari/myweb/Software/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Dense Trajectories Video Description [<a href="http://lear.inrialpes.fr/people/wang/dense_trajectories" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>SIFT Flow: Dense Correspondence across Scenes and its Applications[<a href="http://people.csail.mit.edu/celiu/SIFTflow/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>KLT: An Implementation of the Kanade-Lucas-Tomasi Feature Tracker [<a href="http://www.ces.clemson.edu/~stb/klt/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Tracking Cars Using Optical Flow[<a href="http://www.mathworks.cn/cn/help/vision/examples/tracking-cars-using-optical-flow.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Secrets of optical flow estimation and their principles[<a href="http://ps.is.tue.mpg.de/person/black#tabs-code" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>implmentation of the Black and Anandan dense optical flow method[<a href="http://ps.is.tue.mpg.de/person/black#tabs-code" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Optical Flow Computation[<a href="https://www.ceremade.dauphine.fr/~peyre/numerical-tour/tours/multidim_5_opticalflow/#37" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Beyond Pixels: Exploring New Representations and Applications for Motion Analysis[<a href="http://people.csail.mit.edu/celiu/OpticalFlow/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>A Database and Evaluation Methodology for Optical Flow[<a href="http://vision.middlebury.edu/flow/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>optical flow relative[<a href="http://lmb.informatik.uni-freiburg.de/resources/software.php" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Robust Optical Flow Estimation [<a href="http://www.ipol.im/pub/pre/21/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>optical flow[<a href="http://www.jonathanmugan.com/GraphicsProject/OpticalFlow/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十七、图像检索Image Retrieval：</p><ul><li><p>Semi-Supervised Distance Metric Learning for Collaborative Image Retrieval&nbsp;<a href="http://www.ee.columbia.edu/~wliu/CVPR08_ssml.pdf" rel="external nofollow noreferrer" target="_blank">[Paper</a>][<a href="http://www.ee.columbia.edu/~wliu/SSMetric.zip" rel="external nofollow noreferrer" target="_blank">code</a>]</p></li></ul><br><p>十八、马尔科夫随机场Markov Random Fields：</p><ul><li><p>Markov Random Fields for Super-Resolution&nbsp;<a href="http://www.ee.columbia.edu/~wliu/CVPR08_ssml.pdf" rel="external nofollow noreferrer" target="_blank">[</a><a href="http://people.csail.mit.edu/billf/project%20pages/sresCode/Markov%20Random%20Fields%20for%20Super-Resolution.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors [<a href="http://vision.middlebury.edu/MRF/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li></ul><br><p>十九、运动检测Motion detection：</p><ul><li><p>Moving Object Extraction, Using Models or Analysis of Regions&nbsp;<a href="http://www.ee.columbia.edu/~wliu/CVPR08_ssml.pdf" rel="external nofollow noreferrer" target="_blank">[</a><a href="http://www.visionbib.com/bibliography/motion-i763.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Background Subtraction: Experiments and Improvements for ViBe [<a href="http://www2.ulg.ac.be/telecom/publi/publications/mvd/VanDroogenbroeck2012Background/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>A Self-Organizing Approach to Background Subtraction for Visual Surveillance Applications [<a href="http://www.na.icar.cnr.it/~maddalena.l/MODLab/SoftwareSOBS.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>changedetection.net: A new change detection benchmark dataset[<a href="http://www.changedetection.net/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>ViBe - a powerful technique for background detection and subtraction in video sequences[<a href="http://www2.ulg.ac.be/telecom/research/vibe/" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Background Subtraction Program[<a href="http://www.umiacs.umd.edu/~knkim/UMD-BGS/index.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Motion Detection Algorithms[<a href="http://www.codeproject.com/Articles/10248/Motion-Detection-Algorithms" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Stuttgart Artificial Background Subtraction Dataset[<a href="http://www.vis.uni-stuttgart.de/index.php?id=sabs" rel="external nofollow noreferrer" target="_blank">Project</a>]</p></li><li><p>Object Detection, Motion Estimation, and Tracking[<a href="http://www.mathworks.cn/cn/help/vision/motion-analysis-and-tracking.html" rel="external nofollow noreferrer" target="_blank">Project</a>]</p><p>&nbsp;</p><p>Feature Detection and Description</p><p>General Libraries:</p><ul><li><p><a href="http://www.vlfeat.org/" rel="external nofollow noreferrer" target="_blank">VLFeat</a>&nbsp;– Implementation of various feature descriptors (including SIFT, HOG, and LBP) and covariant feature detectors (including DoG, Hessian, Harris Laplace, Hessian Laplace, Multiscale Hessian, Multiscale Harris). Easy-to-use Matlab interface. See&nbsp;<a href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxlY2N2MTJmZWF0dXJlc3xneDo3ZDllMzVhMDA4YzEzNmU2" rel="external nofollow noreferrer" target="_blank">Modern features: Software</a>&nbsp;– Slides providing a demonstration of VLFeat and also links to other software. Check also&nbsp;<a href="https://sites.google.com/site/eccv12features/" rel="external nofollow noreferrer" target="_blank">VLFeat hands-on session training</a></p></li><li><p><a href="http://opencv.org/" rel="external nofollow noreferrer" target="_blank">OpenCV</a>&nbsp;– Various implementations of modern feature detectors and descriptors (SIFT, SURF, FAST, BRIEF, ORB, FREAK, etc.)</p></li></ul><br><p>Fast Keypoint Detectors for Real-time Applications:</p><ul><li><p><a href="http://www.edwardrosten.com/work/fast.html" rel="external nofollow noreferrer" target="_blank">FAST</a>&nbsp;– High-speed corner detector implementation for a wide variety of platforms</p></li><li><p><a href="http://www6.in.tum.de/Main/ResearchAgast" rel="external nofollow noreferrer" target="_blank">AGAST</a>&nbsp;– Even faster than the FAST corner detector. A multi-scale version of this method is used for the BRISK descriptor (ECCV 2010).</p></li></ul><br><p>Binary Descriptors for Real-Time Applications:</p><ul><li><p><a href="http://cvlab.epfl.ch/software/brief/" rel="external nofollow noreferrer" target="_blank">BRIEF</a>&nbsp;– C++ code for a fast and accurate interest point descriptor (not invariant to rotations and scale) (ECCV 2010)</p></li><li><p><a href="http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html" rel="external nofollow noreferrer" target="_blank">ORB</a>&nbsp;– OpenCV implementation of the Oriented-Brief (ORB) descriptor (invariant to rotations, but not scale)</p></li><li><p><a href="http://www.asl.ethz.ch/people/lestefan/personal/BRISK" rel="external nofollow noreferrer" target="_blank">BRISK</a>&nbsp;– Efficient Binary descriptor invariant to rotations and scale. It includes a Matlab mex interface. (ICCV 2011)</p></li><li><p><a href="http://www.ivpe.com/freak.htm" rel="external nofollow noreferrer" target="_blank">FREAK</a>&nbsp;– Faster than BRISK (invariant to rotations and scale) (CVPR 2012)</p></li></ul><br><p>SIFT and SURF Implementations:</p><ul><li><p>SIFT:&nbsp;<a href="http://www.vlfeat.org/" rel="external nofollow noreferrer" target="_blank">VLFeat</a>,&nbsp;<a href="http://docs.opencv.org/modules/nonfree/doc/feature_detection.html" rel="external nofollow noreferrer" target="_blank">OpenCV</a>,&nbsp;<a href="http://www.cs.ubc.ca/~lowe/keypoints/" rel="external nofollow noreferrer" target="_blank">Original code</a>&nbsp;by David Lowe,&nbsp;<a href="http://cs.unc.edu/~ccwu/siftgpu/" rel="external nofollow noreferrer" target="_blank">GPU implementation</a>,&nbsp;<a href="http://robwhess.github.com/opensift/" rel="external nofollow noreferrer" target="_blank">OpenSIFT</a></p></li><li><p>SURF:&nbsp;<a href="http://www.vision.ee.ethz.ch/~surf/" rel="external nofollow noreferrer" target="_blank">Herbert Bay’s code</a>,&nbsp;<a href="http://docs.opencv.org/modules/nonfree/doc/feature_detection.html" rel="external nofollow noreferrer" target="_blank">OpenCV</a>,&nbsp;<a href="http://www.visual-experiments.com/demos/gpusurf/" rel="external nofollow noreferrer" target="_blank">GPU-SURF</a></p></li></ul><br><p>Other Local Feature Detectors and Descriptors:</p><ul><li><p><a href="http://www.robots.ox.ac.uk/~vgg/research/affine/" rel="external nofollow noreferrer" target="_blank">VGG Affine Covariant features</a>&nbsp;– Oxford code for various affine covariant feature detectors and descriptors.</p></li><li><p><a href="http://vision.ia.ac.cn/Students/wzh/publication/liop/index.html" rel="external nofollow noreferrer" target="_blank">LIOP descriptor</a>&nbsp;– Source code for the Local Intensity order Pattern (LIOP) descriptor (ICCV 2011).</p></li><li><p><a href="http://www.cs.cornell.edu/projects/symfeat/" rel="external nofollow noreferrer" target="_blank">Local Symmetry Features</a>&nbsp;– Source code for matching of local symmetry features under large variations in lighting, age, and rendering style (CVPR 2012).</p></li></ul><br><p>Global Image Descriptors:</p><ul><li><p><a href="http://people.csail.mit.edu/torralba/code/spatialenvelope/" rel="external nofollow noreferrer" target="_blank">GIST</a>&nbsp;– Matlab code for the GIST descriptor</p></li><li><p><a href="https://sites.google.com/site/wujx2001/home" rel="external nofollow noreferrer" target="_blank">CENTRIST</a>&nbsp;– Global visual descriptor for scene categorization and object detection (PAMI 2011)</p></li></ul><p>&nbsp;</p><p>Feature Coding and Pooling</p><ul><li><p><a href="http://www.robots.ox.ac.uk/~vgg/software/enceval_toolkit/" rel="external nofollow noreferrer" target="_blank">VGG Feature Encoding Toolkit</a>&nbsp;– Source code for various state-of-the-art feature encoding methods – including Standard hard encoding, Kernel codebook encoding, Locality-constrained linear encoding, and Fisher kernel encoding.</p></li><li><p><a href="http://www.cs.illinois.edu/homes/slazebni/" rel="external nofollow noreferrer" target="_blank">Spatial Pyramid Matching</a>&nbsp;– Source code for feature pooling based on spatial pyramid matching (widely used for image classification)</p></li></ul><p>&nbsp;</p><p>Convolutional Nets and Deep Learning</p><ul><li><p><a href="http://eblearn.sourceforge.net/" rel="external nofollow noreferrer" target="_blank">EBLearn</a>&nbsp;– C++ Library for Energy-Based Learning. It includes several demos and step-by-step instructions to train classifiers based on convolutional neural networks.</p></li><li><p><a href="http://www.torch.ch/" rel="external nofollow noreferrer" target="_blank">Torch7</a>&nbsp;– Provides a matlab-like environment for state-of-the-art machine learning algorithms, including a fast implementation of convolutional neural networks.</p></li><li><p><a href="http://deeplearning.net/software_links/" rel="external nofollow noreferrer" target="_blank">Deep Learning</a>&nbsp;- Various links for deep learning software.</p></li></ul><p>&nbsp;</p><p>Part-Based Models</p><p>&nbsp;</p><ul><li><p><a href="http://people.cs.uchicago.edu/~rbg/latent/" rel="external nofollow noreferrer" target="_blank">Deformable Part-based Detector</a>&nbsp;– Library provided by the authors of the original paper (state-of-the-art in PASCAL VOC detection task)</p></li><li><p><a href="http://vision.mas.ecp.fr/Personnel/iasonas/dpms.html" rel="external nofollow noreferrer" target="_blank">Efficient Deformable Part-Based Detector</a>&nbsp;– Branch-and-Bound implementation for a deformable part-based detector.</p></li><li><p><a href="http://www.idiap.ch/~cdubout/coding.html" rel="external nofollow noreferrer" target="_blank">Accelerated Deformable Part Model</a>&nbsp;– Efficient implementation of a method that achieves the exact same performance of deformable part-based detectors but with significant acceleration (ECCV 2012).</p></li><li><p><a href="http://iselab.cvc.uab.es/CoarseToFine" rel="external nofollow noreferrer" target="_blank">Coarse-to-Fine Deformable Part Model</a>&nbsp;– Fast approach for deformable object detection (CVPR 2011).</p></li><li><p><a href="http://www.eecs.berkeley.edu/~lbourdev/poselets/" rel="external nofollow noreferrer" target="_blank">Poselets</a>&nbsp;– C++ and Matlab versions for object detection based on poselets.</p></li><li><p><a href="http://www.ics.uci.edu/~xzhu/face/" rel="external nofollow noreferrer" target="_blank">Part-based Face Detector and Pose Estimation</a>&nbsp;– Implementation of a unified approach for face detection, pose estimation, and landmark localization (CVPR 2012).</p><p>&nbsp;</p><p>Attributes and Semantic Features</p><ul><li><p><a href="http://ttic.uchicago.edu/~dparikh/relative.html#code" rel="external nofollow noreferrer" target="_blank">Relative Attributes</a>&nbsp;– Modified implementation of RankSVM to train Relative Attributes (ICCV 2011).</p></li><li><p><a href="http://vision.stanford.edu/projects/objectbank/" rel="external nofollow noreferrer" target="_blank">Object Bank</a>&nbsp;– Implementation of object bank semantic features (NIPS 2010). See also&nbsp;<a href="http://www.cse.buffalo.edu/~jcorso/r/actionbank/" rel="external nofollow noreferrer" target="_blank">ActionBank</a></p></li><li><p><a href="http://vlg.cs.dartmouth.edu/projects/vlg_extractor/vlg_extractor/Home.html" rel="external nofollow noreferrer" target="_blank">Classemes, Picodes, and Meta-class features</a>&nbsp;– Software for extracting high-level image descriptors (ECCV 2010, NIPS 2011, CVPR 2012).</p></li></ul><p>Large-Scale Learning</p><ul><li><p><a href="http://ttic.uchicago.edu/~smaji/projects/fiksvm/" rel="external nofollow noreferrer" target="_blank">Additive Kernels</a>&nbsp;– Source code for fast additive kernel SVM classifiers (PAMI 2013).</p></li><li><p><a href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/" rel="external nofollow noreferrer" target="_blank">LIBLINEAR</a>&nbsp;– Library for large-scale linear SVM classification.</p></li><li><p><a href="http://www.vlfeat.org/" rel="external nofollow noreferrer" target="_blank">VLFeat</a>&nbsp;– Implementation for Pegasos SVM and Homogeneous Kernel map.</p></li></ul><p>Fast Indexing and Image Retrieval</p><ul><li><p><a href="http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN" rel="external nofollow noreferrer" target="_blank">FLANN</a>&nbsp;– Library for performing fast approximate nearest neighbor.</p></li><li><p><a href="http://www.cse.ohio-state.edu/~kulis/klsh/klsh.htm" rel="external nofollow noreferrer" target="_blank">Kernelized LSH</a>&nbsp;– Source code for Kernelized Locality-Sensitive Hashing (ICCV 2009).</p></li><li><p><a href="http://www.unc.edu/~yunchao/itq.htm" rel="external nofollow noreferrer" target="_blank">ITQ Binary codes</a>&nbsp;– Code for generation of small binary codes using Iterative Quantization and other baselines such as Locality-Sensitive-Hashing (CVPR 2011).</p></li><li><p><a href="http://lear.inrialpes.fr/src/inria_fisher/" rel="external nofollow noreferrer" target="_blank">INRIA Image Retrieval</a>&nbsp;– Efficient code for state-of-the-art large-scale image retrieval (CVPR 2011).</p></li></ul><p>Object Detection</p><ul><li><p>See&nbsp;<a href="http://rogerioferis.com/VisualRecognitionAndSearch/Resources.html#parts" rel="external nofollow noreferrer" target="_blank">Part-based Models</a>&nbsp;and&nbsp;<a href="http://rogerioferis.com/VisualRecognitionAndSearch/Resources.html#convnets" rel="external nofollow noreferrer" target="_blank">Convolutional Nets</a>&nbsp;above.</p></li><li><p><a href="https://bitbucket.org/rodrigob/doppia" rel="external nofollow noreferrer" target="_blank">Pedestrian Detection at 100fps</a>&nbsp;– Very fast and accurate pedestrian detector (CVPR 2012).</p></li><li><p><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" rel="external nofollow noreferrer" target="_blank">Caltech Pedestrian Detection Benchmark</a>&nbsp;– Excellent resource for pedestrian detection, with various links for state-of-the-art implementations.</p></li><li><p><a href="http://docs.opencv.org/trunk/modules/objdetect/doc/cascade_classification.html?highlight=face%20detection" rel="external nofollow noreferrer" target="_blank">OpenCV</a>&nbsp;– Enhanced implementation of Viola&amp;Jones real-time object detector, with trained models for face detection.</p></li><li><p><a href="https://sites.google.com/site/christophlampert/software" rel="external nofollow noreferrer" target="_blank">Efficient Subwindow Search</a>&nbsp;– Source code for branch-and-bound optimization for efficient object localization (CVPR 2008).</p></li></ul><p>3D Recognition</p><ul><li><p><a href="http://www.pointclouds.org/" rel="external nofollow noreferrer" target="_blank">Point-Cloud Library</a>&nbsp;– Library for 3D image and point cloud processing.</p></li></ul><p>Action Recognition</p><ul><li><p><a href="http://www.cse.buffalo.edu/~jcorso/r/actionbank/" rel="external nofollow noreferrer" target="_blank">ActionBank</a>&nbsp;– Source code for action recognition based on the ActionBank representation (CVPR 2012).</p></li><li><p><a href="http://www.di.ens.fr/~laptev/download.html" rel="external nofollow noreferrer" target="_blank">STIP Features</a>&nbsp;– software for computing space-time interest point descriptors</p></li><li><p><a href="http://ai.stanford.edu/~quocle/" rel="external nofollow noreferrer" target="_blank">Independent Subspace Analysis</a>&nbsp;– Look for Stacked ISA for Videos (CVPR 2011)</p></li><li><p><a href="http://www.cs.rochester.edu/~rmessing/uradl/" rel="external nofollow noreferrer" target="_blank">Velocity Histories of Tracked Keypoints</a>&nbsp;- C++ code for activity recognition using the velocity histories of tracked keypoints (ICCV 2009)</p></li></ul><hr class="l"><p>Datasets</p><p>Attributes</p><ul><li><p><a href="http://attributes.kyb.tuebingen.mpg.de/" rel="external nofollow noreferrer" target="_blank">Animals with Attributes</a>&nbsp;– 30,475 images of 50 animals classes with 6 pre-extracted feature representations for each image.</p></li><li><p><a href="http://vision.cs.uiuc.edu/attributes/" rel="external nofollow noreferrer" target="_blank">aYahoo and aPascal</a>&nbsp;– Attribute annotations for images collected from Yahoo and Pascal VOC 2008.</p></li><li><p><a href="http://www.cs.columbia.edu/CAVE/databases/facetracer/" rel="external nofollow noreferrer" target="_blank">FaceTracer</a>&nbsp;– 15,000 faces annotated with 10 attributes and fiducial points.</p></li><li><p><a href="http://www.cs.columbia.edu/CAVE/databases/pubfig/" rel="external nofollow noreferrer" target="_blank">PubFig</a>&nbsp;– 58,797 face images of 200 people with 73 attribute classifier outputs.</p></li><li><p>[url=http://vis-<a href="http://www.cs.umass.edu/lfw/" rel="external nofollow noreferrer" target="_blank">www.cs.umass.edu/lfw/</a>]LFW[/url]&nbsp;– 13,233 face images of 5,749 people with 73 attribute classifier outputs.</p></li><li><p><a href="http://www.eecs.berkeley.edu/~lbourdev/poselets/" rel="external nofollow noreferrer" target="_blank">Human Attributes</a>&nbsp;– 8,000 people with annotated attributes. Check also this&nbsp;<a href="https://sharma.users.greyc.fr/hatdb/" rel="external nofollow noreferrer" target="_blank">link</a>&nbsp;for another dataset of human attributes.</p></li><li><p><a href="http://cs.brown.edu/~gen/sunattributes.html" rel="external nofollow noreferrer" target="_blank">SUN Attribute Database</a>&nbsp;– Large-scale scene attribute database with a taxonomy of 102 attributes.</p></li><li><p><a href="http://www.image-net.org/download-attributes" rel="external nofollow noreferrer" target="_blank">ImageNet Attributes</a>&nbsp;– Variety of attribute labels for the ImageNet dataset.</p></li><li><p><a href="http://ttic.uchicago.edu/~dparikh/relative.html#data" rel="external nofollow noreferrer" target="_blank">Relative attributes</a>&nbsp;– Data for OSR and a subset of PubFig datasets. Check also this&nbsp;<a href="http://vision.cs.utexas.edu/whittlesearch/" rel="external nofollow noreferrer" target="_blank">link</a>&nbsp;for the WhittleSearch data.</p></li><li><p><a href="http://tamaraberg.com/attributesDataset/index.html" rel="external nofollow noreferrer" target="_blank">Attribute Discovery Dataset</a>&nbsp;– Images of shopping categories associated with textual descriptions.</p></li></ul><p>Fine-grained Visual Categorization</p><ul><li><p><a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" rel="external nofollow noreferrer" target="_blank">Caltech-UCSD Birds Dataset</a>&nbsp;– Hundreds of bird categories with annotated parts and attributes.</p></li><li><p><a href="http://vision.stanford.edu/aditya86/ImageNetDogs/" rel="external nofollow noreferrer" target="_blank">Stanford Dogs Dataset</a>&nbsp;– 20,000 images of 120 breeds of dogs from around the world.</p></li><li><p><a href="http://www.robots.ox.ac.uk/~vgg/data/pets/" rel="external nofollow noreferrer" target="_blank">Oxford-IIIT Pet Dataset</a>&nbsp;– 37 category pet dataset with roughly 200 images for each class. Pixel level trimap segmentation is included.</p></li><li><p><a href="http://www.comp.leeds.ac.uk/scs6jwks/dataset/leedsbutterfly/" rel="external nofollow noreferrer" target="_blank">Leeds Butterfly Dataset</a>&nbsp;– 832 images of 10 species of butterflies.</p></li><li><p><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/" rel="external nofollow noreferrer" target="_blank">Oxford Flower Dataset</a>&nbsp;– Hundreds of flower categories.</p></li></ul><p>Face Detection</p><ul><li><p>[url=http://vis-<a href="http://www.cs.umass.edu/fddb/" rel="external nofollow noreferrer" target="_blank">www.cs.umass.edu/fddb/</a>]FDDB[/url]&nbsp;– UMass face detection dataset and benchmark (5,000+ faces)</p></li><li><p><a href="http://vasc.ri.cmu.edu/idb/html/face/frontal_images/index.html" rel="external nofollow noreferrer" target="_blank">CMU/MIT</a>&nbsp;– Classical face detection dataset.</p></li></ul><p>Face Recognition</p><ul><li><p><a href="http://www.face-rec.org/databases/" rel="external nofollow noreferrer" target="_blank">Face Recognition Homepage</a>&nbsp;– Large collection of face recognition datasets.</p></li><li><p>[url=http://vis-<a href="http://www.cs.umass.edu/lfw/" rel="external nofollow noreferrer" target="_blank">www.cs.umass.edu/lfw/</a>]LFW[/url]&nbsp;– UMass unconstrained face recognition dataset (13,000+ face images).</p></li><li><p><a href="http://www.nist.gov/itl/iad/ig/face.cfm" rel="external nofollow noreferrer" target="_blank">NIST Face Homepage</a>&nbsp;– includes face recognition grand challenge (FRGC), vendor tests (FRVT) and others.</p></li><li><p><a href="http://www.multipie.org/" rel="external nofollow noreferrer" target="_blank">CMU Multi-PIE</a>&nbsp;– contains more than 750,000 images of 337 people, with 15 different views and 19 lighting conditions.</p></li><li><p><a href="http://www.nist.gov/itl/iad/ig/colorferet.cfm" rel="external nofollow noreferrer" target="_blank">FERET</a>&nbsp;– Classical face recognition dataset.</p></li><li><p><a href="http://www.cad.zju.edu.cn/home/dengcai/Data/FaceData.html" rel="external nofollow noreferrer" target="_blank">Deng Cai’s face dataset in Matlab Format</a>&nbsp;– Easy to use if you want play with simple face datasets including Yale, ORL, PIE, and Extended Yale B.</p></li><li><p><a href="http://www.scface.org/" rel="external nofollow noreferrer" target="_blank">SCFace</a>&nbsp;– Low-resolution face dataset captured from surveillance cameras.</p></li></ul><p>Handwritten Digits</p><ul><li><p><a href="http://yann.lecun.com/exdb/mnist/" rel="external nofollow noreferrer" target="_blank">MNIST</a>&nbsp;– large dataset containing a training set of 60,000 examples, and a test set of 10,000 examples.</p></li></ul><p>Pedestrian Detection</p><ul><li><p><a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" rel="external nofollow noreferrer" target="_blank">Caltech Pedestrian Detection Benchmark</a>&nbsp;– 10 hours of video taken from a vehicle,350K bounding boxes for about 2.3K unique pedestrians.</p></li><li><p><a href="http://pascal.inrialpes.fr/data/human/" rel="external nofollow noreferrer" target="_blank">INRIA Person Dataset</a>&nbsp;– Currently one of the most popular pedestrian detection datasets.</p></li><li><p><a href="http://www.vision.ee.ethz.ch/~aess/dataset/" rel="external nofollow noreferrer" target="_blank">ETH Pedestrian Dataset</a>&nbsp;– Urban dataset captured from a stereo rig mounted on a stroller.</p></li><li><p><a href="http://www.d2.mpi-inf.mpg.de/tud-brussels" rel="external nofollow noreferrer" target="_blank">TUD-Brussels Pedestrian Dataset</a>&nbsp;– Dataset with image pairs recorded in an crowded urban setting with an onboard camera.</p></li><li><p><a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" rel="external nofollow noreferrer" target="_blank">PASCAL Human Detection</a>&nbsp;– One of 20 categories in PASCAL VOC detection challenges.</p></li><li><p><a href="http://iris.usc.edu/Vision-Users/OldUsers/bowu/DatasetWebpage/dataset.html" rel="external nofollow noreferrer" target="_blank">USC Pedestrian Dataset</a>&nbsp;– Small dataset captured from surveillance cameras.</p></li></ul><p>Generic Object Recognition</p><ul><li><p><a href="http://www.image-net.org/" rel="external nofollow noreferrer" target="_blank">ImageNet</a>&nbsp;– Currently the largest visual recognition dataset in terms of number of categories and images.</p></li><li><p><a href="http://groups.csail.mit.edu/vision/TinyImages/" rel="external nofollow noreferrer" target="_blank">Tiny Images</a>&nbsp;– 80 million 32x32 low resolution images.</p></li><li><p><a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/" rel="external nofollow noreferrer" target="_blank">Pascal VOC</a>&nbsp;– One of the most influential visual recognition datasets.</p></li><li><p><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/" rel="external nofollow noreferrer" target="_blank">Caltech 101</a>&nbsp;/&nbsp;<a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/" rel="external nofollow noreferrer" target="_blank">Caltech 256</a>&nbsp;– Popular image datasets containing 101 and 256 object categories, respectively.</p></li><li><p><a href="http://new-labelme.csail.mit.edu/Release3.0/index.php" rel="external nofollow noreferrer" target="_blank">MIT LabelMe</a>&nbsp;– Online annotation tool for building computer vision databases.</p></li></ul><p>Scene Recognition</p><ul><li><p><a href="http://groups.csail.mit.edu/vision/SUN/" rel="external nofollow noreferrer" target="_blank">MIT SUN Dataset</a>&nbsp;– MIT scene understanding dataset.</p></li><li><p><a href="http://www-cvr.ai.uiuc.edu/ponce_grp/data/" rel="external nofollow noreferrer" target="_blank">UIUC Fifteen Scene Categories</a>&nbsp;– Dataset of 15 natural scene categories.</p></li></ul><p>Feature Detection and Description</p><ul><li><p><a href="http://www.robots.ox.ac.uk/~vgg/data/data-aff.html" rel="external nofollow noreferrer" target="_blank">VGG Affine Dataset</a>&nbsp;– Widely used dataset for measuring performance of feature detection and description. Check<a href="http://www.vlfeat.org/benchmarks/index.html" rel="external nofollow noreferrer" target="_blank">VLBenchmarks</a>for an evaluation framework.</p></li></ul><p>Action Recognition</p><ul><li><p><a href="http://rogerioferis.com/VisualRecognitionAndSearch/material/LiuFerisSunTutorial.pdf" rel="external nofollow noreferrer" target="_blank">Benchmarking Activity Recognition</a>&nbsp;– CVPR 2012 tutorial covering various datasets for action recognition.</p></li></ul><p>RGBD Recognition</p><ul><li><p><a href="http://www.cs.washington.edu/rgbd-dataset/index.html" rel="external nofollow noreferrer" target="_blank">RGB-D Object Dataset</a>&nbsp;– Dataset containing 300 common household objects</p></li></ul><p>Reference:</p><p>&nbsp;</p><p>[1]:&nbsp;<a href="http://rogerioferis.com/VisualRecognitionAndSearch/Resources.html" rel="external nofollow noreferrer" target="_blank">http://rogerioferis.com/VisualRecognitionAndSearch/Resources.html</a></p><p><br>特征提取</p><ul><li><p>SURF特征:&nbsp;<a href="http://www.vision.ee.ethz.ch/software/index.de.html(%E5%BD%93%E7%84%B6%E8%BF%99%E5%8F%AA%E6%98%AF%E5%85%B6%E4%B8%AD%E4%B9%8B%E4%B8%80" rel="external nofollow noreferrer" target="_blank">http://www.vision.ee.ethz.ch/software/index.de.html</a>(当然这只是其中之一)</p></li><li><p>LBP特征(一种纹理特征)：<a href="http://www.comp.hkbu.edu.hk/~icpr06/tutorials/Pietikainen.html" rel="external nofollow noreferrer" target="_blank">http://www.comp.hkbu.edu.hk/~icpr06/tutorials/Pietikainen.html</a></p></li><li><p>Fast Corner Detection（OpenCV中的Fast算法）:<a href="http://mi.eng.cam.ac.uk/~er258/work/fast.html" rel="external nofollow noreferrer" target="_blank">FAST Corner Detection -- Edward Rosten</a></p></li></ul><p>机器视觉</p><ul><li><p>A simple object detector with boosting(Awarded the Best Short Course Prize at ICCV 2005，So了解adaboost的推荐之作)：<a href="http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html" rel="external nofollow noreferrer" target="_blank">http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html</a></p></li><li><p>Boosting(该网页上有相当全的Boosting的文章和几个Boosting代码，本人推荐)：<a href="http://cbio.mskcc.org/~aarvey/boosting_papers.html" rel="external nofollow noreferrer" target="_blank">http://cbio.mskcc.org/~aarvey/boosting_papers.html</a></p></li><li><p>Adaboost Matlab 工具：<a href="http://graphics.cs.msu.ru/en/science/research/machinelearning/adaboosttoolbox" rel="external nofollow noreferrer" target="_blank">http://graphics.cs.msu.ru/en/science/research/machinelearning/adaboosttoolbox</a></p></li><li><p><a href="http://192.168.1.27/wiki/MultiBoost" rel="external nofollow noreferrer" target="_blank">MultiBoost</a>(不说啥了，多类Adaboost算法的程序)：<a href="http://sourceforge.net/projects/multiboost/" rel="external nofollow noreferrer" target="_blank">http://sourceforge.net/projects/multiboost/</a></p></li><li><p><a href="http://192.168.1.27/wiki/TextonBoost" rel="external nofollow noreferrer" target="_blank">TextonBoost</a>(我们教研室王冠夫师兄的毕设):&nbsp;<a href="http://jamie.shotton.org/work/code.html" rel="external nofollow noreferrer" target="_blank">Jamie Shotton - Code</a></p></li><li><p><a href="http://192.168.1.27/wiki/LibSvm" rel="external nofollow noreferrer" target="_blank">LibSvm</a>的老爹（推荐）:&nbsp;<a href="http://www.csie.ntu.edu.tw/~cjlin/" rel="external nofollow noreferrer" target="_blank">http://www.csie.ntu.edu.tw/~cjlin/</a></p></li><li><p><a href="http://www.inference.phy.cam.ac.uk/hmw26/crf/" rel="external nofollow noreferrer" target="_blank">Conditional Random Fields</a>（CRF论文+Code列表，推荐）</p></li><li><p><a href="http://crfpp.sourceforge.net/" rel="external nofollow noreferrer" target="_blank">CRF++: Yet Another CRF toolkit</a></p></li><li><p><a href="http://www.computervisiononline.com/software/conditional-random-field-crf-toolbox-matlab" rel="external nofollow noreferrer" target="_blank">Conditional Random Field (CRF) Toolbox for Matlab</a></p></li><li><p><a href="http://www.cs.cmu.edu/~jkbradle/TreeCRFs/" rel="external nofollow noreferrer" target="_blank">Tree CRFs</a></p></li><li><p><a href="http://alias-i.com/lingpipe/web/install.html" rel="external nofollow noreferrer" target="_blank">LingPipe: Installation</a></p></li><li><p><a href="http://jedlik.phy.bme.hu/~gerjanos/HMM/node2.html" rel="external nofollow noreferrer" target="_blank">Hidden Markov Models</a>（推荐）</p></li><li><p><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">隐马尔科夫模型</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">(Hidden Markov Models)</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">系列之一</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">&nbsp;- eaglex</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">的专栏 - 博客频道&nbsp;</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">- CSDN.NET</a><a href="http://blog.csdn.net/eaglex/article/details/6376826" rel="external nofollow noreferrer" target="_blank">（推荐）</a></p></li></ul><p>综合代码</p><ul><li><p><a href="http://192.168.1.27/wiki/CvPapers" rel="external nofollow noreferrer" target="_blank">CvPapers</a>(好吧，牛吧网站，里面有ICCV，CVPR，ECCV，SIGGRAPH的论文收录，然后还有一些论文的代码搜集，要求加精！)：<a href="http://www.cvpapers.com/" rel="external nofollow noreferrer" target="_blank">http://www.cvpapers.com/</a></p></li><li><p>Computer Vision Software(里面代码很多，并详细的给出了分类)：<a href="http://peipa.essex.ac.uk/info/software.html" rel="external nofollow noreferrer" target="_blank">http://peipa.essex.ac.uk/info/software.html</a></p></li><li><p>某人的Windows Live（我看里面东东不少就收藏了）：<a href="https://skydrive.live.com/?cid=3b6244088fd5a769#cid=3B6244088FD5A769&amp;id=3B6244088FD5A769!523" rel="external nofollow noreferrer" target="_blank">https://skydrive.live.com/?cid=3b6244088fd5a769#cid=3B6244088FD5A769&amp;id=3B6244088FD5A769!523</a></p></li><li><p>MATLAB and Octave Functions for Computer Vision and Image Processing（这个里面的东西也很全，只是都是用Matlab和Octave开发的）：<a href="http://www.csse.uwa.edu.au/~pk/research/matlabfns/" rel="external nofollow noreferrer" target="_blank">http://www.csse.uwa.edu.au/~pk/research/matlabfns/</a></p></li><li><p>Computer Vision Resources（里面的视觉算法很多，给出了相应的论文和Code，挺好的）：<a href="https://netfiles.uiuc.edu/jbhuang1/www/resources/vision/index.html" rel="external nofollow noreferrer" target="_blank">https://netfiles.uiuc.edu/jbhuang1/www/resources/vision/index.html</a></p></li><li><p>MATLAB Functions for Multiple View Geometry（关于物体多视角计算的库）：<a href="http://www.robots.ox.ac.uk/~vgg/hzbook/code/" rel="external nofollow noreferrer" target="_blank">http://www.robots.ox.ac.uk/~vgg/hzbook/code/</a></p></li><li><p>Evolutive Algorithm based on Naïve Bayes models Estimation（单独列了一个算法的Code）：<a href="http://www.cvc.uab.cat/~xbaro/eanbe/#_Software" rel="external nofollow noreferrer" target="_blank">http://www.cvc.uab.cat/~xbaro/eanbe/#_Software</a></p></li></ul><p>主页代码</p><ul><li><p><a href="http://pablonegri.free.fr/index.html" rel="external nofollow noreferrer" target="_blank">Pablo Negri's Home Page</a></p></li><li><p><a href="http://c2inet.sce.ntu.edu.sg/Jianxin/index.html" rel="external nofollow noreferrer" target="_blank">Jianxin Wu's homepage</a></p></li><li><p><a href="http://www.cs.ubc.ca/~pcarbo/" rel="external nofollow noreferrer" target="_blank">Peter Carbonetto</a></p></li><li><p><a href="http://people.csail.mit.edu/billf/project%20pages/sresCode/Markov%20Random%20Fields%20for%20Super-Resolution.html" rel="external nofollow noreferrer" target="_blank">Markov Random Fields for Super-Resolution</a></p></li><li><p><a href="http://www.wisdom.weizmann.ac.il/~vision/SketchTheCommon/" rel="external nofollow noreferrer" target="_blank">Detecting and Sketching the Common</a></p></li><li><p><a href="http://people.cs.uchicago.edu/~pff/" rel="external nofollow noreferrer" target="_blank">Pedro Felzenszwalb</a></p></li><li><p><a href="http://users.soe.ucsc.edu/~rokaf/interests.html" rel="external nofollow noreferrer" target="_blank">Hae JONG, SEO</a></p></li><li><p><a href="http://www.cise.ufl.edu/class/cap5416fa09/Projects.html" rel="external nofollow noreferrer" target="_blank">CAP 5416 - Computer Vision</a></p></li><li><p><a href="http://www.robots.ox.ac.uk/~gk/PTAM/" rel="external nofollow noreferrer" target="_blank">Parallel Tracking and Mapping for Small AR Workspaces (PTAM)</a></p></li><li><p><a href="http://www.ics.uci.edu/~dramanan/" rel="external nofollow noreferrer" target="_blank">Deva Ramanan - UC Irvine - Computer Vision</a></p></li><li><p><a href="http://www.umiacs.umd.edu/~raghuram/" rel="external nofollow noreferrer" target="_blank">Raghuraman Gopalan</a></p></li><li><p><a href="http://bmi.osu.edu/~hkong/index.htm" rel="external nofollow noreferrer" target="_blank">Hui Kong</a></p></li><li><p><a href="http://jamie.shotton.org/work/index.html" rel="external nofollow noreferrer" target="_blank">Jamie Shotton - Post-Doctoral Researcher in Computer Vision</a></p></li><li><p><a href="http://imagine.enpc.fr/~audibert/index.html" rel="external nofollow noreferrer" target="_blank">Jean-Yves AUDIBERT</a></p></li><li><p><a href="http://www.csd.uwo.ca/~olga/" rel="external nofollow noreferrer" target="_blank">Olga Veksler</a></p></li><li><p><a href="http://users.cecs.anu.edu.au/~sgould/index.html#software" rel="external nofollow noreferrer" target="_blank">Stephen Gould</a></p></li><li><p><a href="http://faculty.ucmerced.edu/mhyang/code.html" rel="external nofollow noreferrer" target="_blank">Publications (Last Update: 09/30/10)</a></p></li><li><p><a href="http://cvlab.epfl.ch/~ali/flowboost.htm" rel="external nofollow noreferrer" target="_blank">Karim Ali - FlowBoost</a></p></li><li><p><a href="http://people.csail.mit.edu/fergus/iccv2005/partsstructure.html" rel="external nofollow noreferrer" target="_blank">A simple parts and structure object detector</a></p></li><li><p><a href="http://cms.brookes.ac.uk/research/visiongroup/code.php" rel="external nofollow noreferrer" target="_blank">Code - Oxford Brookes Vision Group</a></p></li><li><p><a href="http://chasen.org/~taku/index.html.en" rel="external nofollow noreferrer" target="_blank">Taku Kudo</a></p></li></ul><p>行人检测</p><ul><li><p><a href="http://www.computing.edu.au/~12482661/hog.html" rel="external nofollow noreferrer" target="_blank">Histogram of Oriented Gradient (Windows)</a></p></li><li><p><a href="http://www.cs.berkeley.edu/~smaji/projects/ped-detector/" rel="external nofollow noreferrer" target="_blank">INRIA Pedestrian detector</a></p></li><li><p><a href="http://www.eecs.berkeley.edu/~lbourdev/poselets/" rel="external nofollow noreferrer" target="_blank">Poselets</a></p></li><li><p><a href="http://www.liv.ic.unicamp.br/~wschwartz/softwares.html" rel="external nofollow noreferrer" target="_blank">William Robson Schwartz - Softwares</a></p></li><li><p><a href="http://www.vision.ee.ethz.ch/~calvin/calvin_upperbody_detector/" rel="external nofollow noreferrer" target="_blank">calvin upper-body detector v1.02</a></p></li><li><p><a href="http://www.cvg.rdg.ac.uk/software/rpt/index.html" rel="external nofollow noreferrer" target="_blank">RPT@CVG</a></p></li><li><p><a href="http://www.idiap.ch/~odobez/human-detection/index.html" rel="external nofollow noreferrer" target="_blank">Main Page</a></p></li><li><p><a href="http://www.lienhart.de/Source_Code/source_code.html" rel="external nofollow noreferrer" target="_blank">Source Code</a></p></li><li><p><a href="http://www.informatik.uni-freiburg.de/~spinello/people2D.html" rel="external nofollow noreferrer" target="_blank">Dr. Luciano Spinello</a></p></li><li><p><a href="http://bmi.osu.edu/~hkong/Human_Detection.html" rel="external nofollow noreferrer" target="_blank">Pedestrian Detection</a></p></li><li><p><a href="http://www.vision.ee.ethz.ch/~gallju/projects/houghforest/index.html" rel="external nofollow noreferrer" target="_blank">Class-Specific Hough Forests for Object Detection</a></p></li><li><p><a href="http://c2inet.sce.ntu.edu.sg/Jianxin/index.html" rel="external nofollow noreferrer" target="_blank">Jianxin Wu's homepage</a>（就是上面的）</p></li><li><p>Berkeley大学做的Pedestrian Detector，使用交叉核的支持向量机，特征使用HOG金字塔，提供Matlab和C++混编的代码：<a href="http://www.cs.berkeley.edu/~smaji/projects/ped-detector/" rel="external nofollow noreferrer" target="_blank">http://www.cs.berkeley.edu/~smaji/projects/ped-detector/</a></p></li></ul><p>视觉壁障</p><ul><li><p><a href="http://www.cs.cornell.edu/~asaxena/rccar/" rel="external nofollow noreferrer" target="_blank">High Speed Obstacle Avoidance using Monocular Vision and Reinforcement Learning</a></p></li><li><p><a href="http://info.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html" rel="external nofollow noreferrer" target="_blank">TLD</a>(2010年很火的tracking算法)</p></li><li><p><a href="http://www.vision.ee.ethz.ch/boostingTrackers/" rel="external nofollow noreferrer" target="_blank">online boosting trackers</a></p></li><li><p><a href="http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml" rel="external nofollow noreferrer" target="_blank">Boris Babenko</a></p></li><li><p>Optical Flow Algorithm Evaluation (提供了一个动态贝叶斯网络框架，例如递 归信息处理与分析、卡尔曼滤波、粒子滤波、序列蒙特卡罗方法等，C++写的)<a href="http://of-.sourceforge.net/" rel="external nofollow noreferrer" target="_blank">http://of-eval.sourceforge.net/</a></p></li></ul><p>物体检测算法</p><ul><li><p><a href="http://www.irisa.fr/vista/Equipe/People/Laptev/objectdetection.html" rel="external nofollow noreferrer" target="_blank">Object Detection</a></p></li><li><p><a href="http://www.seas.upenn.edu/~limingw/obj_det_accv07/code.html" rel="external nofollow noreferrer" target="_blank">Software for object detection</a></p></li></ul><p>人脸检测</p><ul><li><p><a href="http://www.lienhart.de/Source_Code/source_code.html" rel="external nofollow noreferrer" target="_blank">Source Code</a></p></li><li><p><a href="http://itp.nyu.edu/~mbe230/blogmer/2011/02/10-face-detection-projects/" rel="external nofollow noreferrer" target="_blank">10个人脸检测项目</a></p></li><li><p><a href="http://c2inet.sce.ntu.edu.sg/Jianxin/index.html" rel="external nofollow noreferrer" target="_blank">Jianxin Wu's homepage</a>（又是这货）</p></li></ul><p>ICA独立成分分析</p><ul><li><p><a href="http://cnl.salk.edu/~tony/ica.html" rel="external nofollow noreferrer" target="_blank">An ICA page-papers,code,demo,links (Tony Bell)</a></p></li><li><p><a href="http://research.ics.tkk.fi/ica/fastica/" rel="external nofollow noreferrer" target="_blank">FastICA</a></p></li><li><p><a href="http://kos.informatik.uni-osnabrueck.de/download/3dim2007/paper.html" rel="external nofollow noreferrer" target="_blank">Cached k-d tree search for ICP algorithms</a></p></li></ul><p>滤波算法</p><ul><li><p>卡尔曼滤波：<a href="http://www.cs.unc.edu/~welch/kalman/index.html" rel="external nofollow noreferrer" target="_blank">The Kalman Filter</a>(终极网页)</p></li><li><p>Bayesian Filtering Library:&nbsp;<a href="http://www.orocos.org/bfl" rel="external nofollow noreferrer" target="_blank">The Bayesian Filtering Library</a></p></li></ul><p>路面识别</p><ul><li><p><a href="http://www.multimedia-computing.de/wiki/Source_Code#Dataset_of_logos_in_real-world_images:_FlickrLogos-32" rel="external nofollow noreferrer" target="_blank">Source Code</a></p></li><li><p><a href="http://bmi.osu.edu/~hkong/Road_Detection.html" rel="external nofollow noreferrer" target="_blank">Vanishing point detection for general road detection</a></p></li></ul><p>分割算法</p><ul><li><p>MATLAB Normalized Cuts Segmentation Code：<a href="http://www.cis.upenn.edu/~jshi/software/" rel="external nofollow noreferrer" target="_blank">software</a></p></li><li><p>超像素分割：<a href="http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html" rel="external nofollow noreferrer" target="_blank">SLIC Superpixels</a></p></li></ul></li></ul></li></ul></div></section><section class="References"><span id="References">References</span> <span id="References-content"></span></section><section class="post-footer"><hr id="footerline"><br><section class="author">*Corresponding Author: Yao Qing-sheng &lt;Email: <a href="mailto:350788415@qq.com" rel="external nofollow noreferrer" title="350788415@qq.com">350788415@qq.com</a>&gt; BY-NC-SA .</section><br><ol id="list"><li>Yao Qing-sheng&period;计算机视觉牛人博客和代码汇总&period;FUTURE & CIVILIZATION&period;Natural/Social Philosophy & Infomation Sciences&comma;20210506&period;https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/</li><li>版权声明：本文为「LordYao」的原创文章，遵循 CC 4.0 BY-NC-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接： https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/</li></ol></section><script>jQuery(document).on("copy",function(e){var t=window.getSelection(),n=t.toString().replace(/\n/g,"<br>"),o="<br>---------------------<br>著作权归作者所有。<br>商业转载请联系作者获得授权，非商业转载请注明出处。<br><br>作者："+document.getElementById("author").innerText+"<br>复制时间: "+Date.now()+"<br>原文链接："+document.location.href+"<br>© 版权声明：本文为「"+document.getElementById("author").innerText+"」的原创文章，遵循 CC 4.0 BY-NC-SA 版权协议，转载请附上原文出处链接及本声明。",r=$("<div>",{id:"temp",html:n+o,style:{position:"absolute",left:"-99999px"}});$("body").append(r),t.selectAllChildren(r[0]),window.setTimeout(function(){r.remove()},0)})</script></section><div style="font-size:12px;BORDER-BOTTOM:#bbb 1px solid;BORDER-LEFT:#bbb 1px solid;BACKGROUND:#f6f6f6;MIN-HEIGHT:120px;BORDER-TOP:#bbb 1px solid;BORDER-RIGHT:#bbb 1px solid;MARGIN-TOP:30px;MARGIN-BOTTOM:10px"><div style="MARGIN-TOP:10px;FLOAT:left;MARGIN-LEFT:10px;MARGIN-RIGHT:10px"><img alt="author:Yao Qing-sheng" src="/images/avatar_sx_lite.png" width="100" height="100"></div><div style="LINE-HEIGHT:200%;MARGIN:10px;COLOR:#000">Author: <a href="https://yaoqs.github.io/">Yao Qing-sheng</a> &nbsp;&nbsp;&nbsp;&nbsp; Blog: <a href="https://yaoqs.github.io/">https://yaoqs.github.io/</a>&nbsp;&nbsp;&nbsp;&nbsp; Email: <a href="mailto:350788415@qq.com" rel="external nofollow noopener noreferrer" target="_blank">350788415@qq.com</a><br>Address:Department of Natural/Social Philosophy & Infomation Sciences, CHINA<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/yaoqs#biography">Biography...</a></div></div><style>.article-licensing{position:relative;z-index:0;box-shadow:none;background:#f5f5f5;border-radius:4px;overflow:hidden}.article-licensing p{margin-top:0;margin-bottom:0;font-size:.8em}.article-licensing:after{position:absolute;z-index:-1;right:50px;top:30.9px;content:'\f25e';font-size:200px;font-family:'Font Awesome 5 Brands';opacity:.1}.article-licensing .level-left{flex-wrap:wrap;max-width:100%}.article-licensing .licensing-title{line-height:1.2em;margin-left:10px}.article-licensing .licensing-meta{margin-left:10px}.article-licensing .licensing-meta .icon{vertical-align:bottom}.article-licensing .licensing-meta a{color:inherit}.level{align-items:center;justify-content:space-between}.level code{border-radius:4px}.level img{display:inline-block;vertical-align:top}.level.is-mobile{display:flex}.level.is-mobile .level-left,.level.is-mobile .level-right{display:flex}.level.is-mobile .level-left+.level-right{margin-top:0}.level.is-mobile .level-item:not(:last-child){margin-bottom:0;margin-right:.75rem}.level.is-mobile .level-item:not(.is-narrow){flex-grow:1}@media screen and (min-width:769px),print{.level{display:flex}.level>.level-item:not(.is-narrow){flex-grow:1}}.level-item{align-items:center;display:flex;flex-basis:auto;flex-grow:0;flex-shrink:0;justify-content:center}.level-item .subtitle,.level-item .title{margin-bottom:0}@media screen and (max-width:768px){.level-item:not(:last-child){margin-bottom:.75rem}}.level-left,.level-right{flex-basis:auto;flex-grow:0;flex-shrink:0}.level-left .level-item.is-flexible,.level-right .level-item.is-flexible{flex-grow:1}@media screen and (min-width:769px),print{.level-left .level-item:not(:last-child),.level-right .level-item:not(:last-child){margin-right:.75rem}}.level-left{align-items:center;justify-content:flex-start}@media screen and (max-width:768px){.level-left+.level-right{margin-top:1.5rem}}@media screen and (min-width:769px),print{.level-left{display:flex}}.level-right{align-items:center;justify-content:flex-end}@media screen and (min-width:769px),print{.level-right{display:flex}}</style><div class="article-licensing box"><div class="licensing-title"><a href="https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/">计算机视觉牛人博客和代码汇总</a></div><div class="licensing-title"><p><a href="https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/">https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><p>Author</p><p>Yao Qing-sheng</p></div></div><div class="level-item is-narrow"><div><p>Posted on</p><p>2021-05-06</p></div></div><div class="level-item is-narrow"><div><p>Updated on</p><p>2025-01-14</p></div></div><div class="level-item is-narrow"><div><p>Licensed under</p><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a> <a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a> <a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div><div class="licensing-title"><p>转载或引用本文时请遵守许可协议，注明出处、不得用于商业用途！</p></div></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js" integrity="sha256-fGPu+icKh985TLPhO2v68U7i0CW0dE4kiR06RN4O6jo=" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css" integrity="sha256-0EDwznjUTDEicOuZhOL03fpflUqzhkByvhwol8YGkp4=" crossorigin="anonymous"><div class="social-share share-component"></div><style>.card{background-color:#fff;box-shadow:0 4px 10px rgba(0,0,0,.05),0 0 1px rgba(0,0,0,.1);color:#4a4a4a;max-width:100%;position:relative;transition:opacity .3s ease-out,transform .3s ease-out;opacity:1;transform-origin:center top 0}.card-header{background-color:transparent;align-items:stretch;box-shadow:0 .125em .25em rgba(10,10,10,.1);display:flex}.card-header-title{align-items:center;color:#363636;display:flex;flex-grow:1;font-weight:700;padding:.75rem 1rem}.card-header-title.is-centered{justify-content:center}.card-header-icon{align-items:center;cursor:pointer;display:flex;justify-content:center;padding:.75rem 1rem}.card-image{display:block;position:relative}.card-content{background-color:transparent;padding:1.5em;font-size:1.2em}.buttons.is-centered{justify-content:center;display:flex;font-size:.8em}.card-footer{background-color:transparent;border-top:1px solid #ededed;align-items:stretch;display:flex}.card-footer-item{align-items:center;display:flex;flex-basis:0;flex-grow:1;flex-shrink:0;justify-content:center;padding:.75rem}.card-footer-item:not(:last-child){border-right:1px solid #ededed}.card .media:not(:last-child){margin-bottom:.75rem}.donate{position:relative;padding:10px 10px 10px 10px;margin-left:1em;border-radius:.5em}.donate .qrcode{display:none;position:absolute;z-index:99;bottom:2.5em;line-height:0;overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.05),0 0 1px rgba(0,0,0,.1);border-radius:4px}.donate .qrcode img{max-width:280px}.donate:hover .qrcode{display:block}.donate:first-child:not(:last-child) .qrcode{left:-.75rem}.donate:last-child:not(:first-child) .qrcode{right:-.75rem}.donate[data-type=alipay]{color:#fff;background-color:#00a0e8;border-color:transparent}.donate[data-type=alipay]:active{background-color:#008ecf}.donate[data-type=alipay]:hover{background-color:#0097db}.donate[data-type=alipay]:focus:not(:active){box-shadow:0 0 0 .125em rgba(0,160,232,.25)}.donate[data-type=buymeacoffee]{color:rgba(0,0,0,.7);background-color:#fd0;border-color:transparent}.donate[data-type=buymeacoffee]:active{background-color:#e6c700}.donate[data-type=buymeacoffee]:hover{background-color:#f2d200}.donate[data-type=buymeacoffee]:focus:not(:active){box-shadow:0 0 0 .125em rgba(255,221,0,.25)}.donate[data-type=paypal]{color:rgba(0,0,0,.7);background-color:#feb700;border-color:transparent}.donate[data-type=paypal]:active{background-color:#e5a500}.donate[data-type=paypal]:hover{background-color:#f1ae00}.donate[data-type=paypal]:focus:not(:active){box-shadow:0 0 0 .125em rgba(254,183,0,.25)}.donate[data-type=patreon]{color:#fff;background-color:#ff424d;border-color:transparent}.donate[data-type=patreon]:active{background-color:#ff2835}.donate[data-type=patreon]:hover{background-color:#ff3541}.donate[data-type=patreon]:focus:not(:active){box-shadow:0 0 0 .125em rgba(255,66,77,.25)}.donate[data-type=wechat]{color:#fff;background-color:#1aad19;border-color:transparent}.donate[data-type=wechat]:active{background-color:#179716}.donate[data-type=wechat]:hover{background-color:#18a217}.donate[data-type=wechat]:focus:not(:active){box-shadow:0 0 0 .125em rgba(26,173,25,.25)}.donate[data-type="GitHub Sponsor"]{color:#fff;background-color:#000;border-color:transparent}.donate[data-type="GitHub Sponsor"]:active{background-color:#000}.donate[data-type="GitHub Sponsor"]:hover{background-color:#000}.donate[data-type="GitHub Sponsor"]:focus:not(:active){box-shadow:0 0 0 .125em rgba(0,160,232,.25)}</style><div class="card"><div class="card-content"><p>Like this article? Support the author with</p><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i> </span><span>Alipay</span> <span class="qrcode"><img width="200px" src="/images/支付宝收款码.jpg" alt="Alipay"> </span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i> </span><span>Wechat</span> <span class="qrcode"><img src="/images/微信收款码.png" alt="Wechat"> </span></a><a class="button donate" data-type="paypal"><span class="icon is-small"><i class="fab fa-paypal"></i> </span><span>PayPal</span> <span class="qrcode"><img src="/images/paypal.png" alt="PayPal"> </span></a><a class="button donate" data-type="GitHub Sponsor" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/sponsors/yaoqs"><span class="icon is-small"><i class="fab fa-GitHub"></i> </span><span>GitHub Sponsor</span> </a><a class="button donate" data-type="buymeacoffee" target="_blank" rel="noopener external nofollow noreferrer" href="https://buymeacoffee.com/yaoqs"><span class="icon is-small"><i class="fab fa-buymeacoffee"></i> </span><span>Buy Me a Coffee</span></a></div></div></div></article><div id="qrcode"></div><script>$("#qrcode").qrcode({width:173,height:173,text:"https://yaoqs.github.io/20210506/ji-suan-ji-shi-jue-niu-ren-bo-ke-he-dai-ma-hui-zong/"})</script><div class="pagination"><a class="newer-posts" href="/20210519/cheng-xu-yuan-lian-shou-xiao-xiang-mu/">← 程序员练手小项目 </a><a class="older-posts" href="/20210506/chang-jian-de-c-shu-xue-ji-suan-ku/">常见的C++数学计算库 →</a><br></div><a id="toTop" href="#top" title="回顶部">Top</a></main></div></div><script src="https://cdn.jsdelivr.net/gh/yaoqs/donate-plugin/zanzhu_yaoqs.min.js"></script><script>$(function(){new Rewardtip({tiptext:"谢谢支持/Thanks...",tipimg:{img:"/images/ali.gif",width:"50px",height:"50px"},more:"/Donate",tipshow:"<img src='/images/ali.gif'/>",list:[{name:"微信收款码",qrimg:"/images/微信收款码.png"},{name:"微信打赏码",qrimg:"/images/微信打赏码.png"},{name:"支付宝收款码",qrimg:"/images/支付宝收款码.jpg"},{name:"支付宝红包码",qrimg:"/images/支付宝红包码.jpg"}],link:[{name:"paypal",desc:"paypal.me/LordYao",link:"https://www.paypal.com/cgi-bin/webscr?cmd=_xclick&amp;business=243292490@qq.com&amp;currency_code=USD&amp;amount=1&amp;return=http://yaoqs.github.com/about&amp;item_name=LordYao%27s%20Blog&amp;undefined_quantity=1"}]})})</script><script src="https://cdn.jsdelivr.net/npm/materialize-css@1.0.0/dist/js/materialize.min.js" integrity="sha256-U/cHDMTIHCeMcvehBv1xQ052bPSbJtbuiw4QA9cTKz0=" crossorigin="anonymous"></script><style>#searchIcon{font-size:1.2rem}#searchModal{min-height:500px;width:80%}#searchModal .search-header .title{font-size:1.6rem;color:#333}#searchResult{margin:-15px 0 10px 10px}#searchResult .search-result-list{margin-left:-8px;padding-left:0;color:#666}.search-result-list .search-result-title{font-size:1.4rem;color:#42b983}.search-result-list li{border-bottom:1px solid #e5e5e5;padding:15px 0 5px 0}.search-result-list .search-keyword{margin:0 2px;padding:1px 5px 1px 4px;border-radius:2px;background-color:#f2f2f2;color:#e96900;font-style:normal;white-space:pre-wrap}.modal{display:none;position:fixed;left:0;right:0;background-color:#fafafa;padding:0;max-height:70%;width:55%;margin:auto;overflow-y:auto;border-radius:2px;will-change:top,opacity}.modal:focus{outline:0}@media only screen and (max-width:992px){.modal{width:80%}}.modal h1,.modal h2,.modal h3,.modal h4{margin-top:0}.modal .modal-content{padding:24px}.modal .modal-close{cursor:pointer}.modal .modal-footer{border-radius:0 0 2px 2px;background-color:#fafafa;padding:4px 6px;height:56px;width:100%;text-align:right}.modal .modal-footer .btn,.modal .modal-footer .btn-flat,.modal .modal-footer .btn-large,.modal .modal-footer .btn-small{margin:6px 0}.modal-overlay{position:fixed;z-index:999;top:-25%;left:0;bottom:0;right:0;height:125%;width:100%;background:#000;display:none;will-change:opacity}.modal.modal-fixed-footer{padding:0;height:70%}.modal.modal-fixed-footer .modal-content{position:absolute;height:calc(100% - 56px);max-height:100%;width:100%;overflow-y:auto}.modal.modal-fixed-footer .modal-footer{border-top:1px solid rgba(0,0,0,.1);position:absolute;bottom:0}.modal.bottom-sheet{top:auto;bottom:-100%;margin:0;width:100%;max-height:45%;border-radius:0;will-change:bottom,opacity}</style><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;search</span> <input type="search" id="searchInput" name="s" placeholder="searchTip" class="search-input"></div><div id="searchResult"></div></div></div><script>$(function(){var e,r,a;e="/search.xml",r="searchInput",a="searchResult",$.ajax({url:e,dataType:"xml",success:function(e){var t=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),e=document.getElementById(r),n=document.getElementById(a);e.addEventListener("input",function(){var o='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length<=0||(t.forEach(function(e){var n,t,r,a=!0,l=e.title.trim().toLowerCase(),s=e.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=0===(i=e.url).indexOf("/")?e.url:"/"+i,c=-1,u=-1;""!==l&&""!==s&&h.forEach(function(e,t){n=l.indexOf(e),c=s.indexOf(e),n<0&&c<0?a=!1:(c<0&&(c=0),0===t&&(u=c))}),a&&(o+="<li><a href='"+i+"' class='search-result-title'>"+l+"</a>",i=e.content.trim().replace(/<[^>]+>/g,""),0<=u&&(e=u+80,(e=0===(t=(t=u-20)<0?0:t)?100:e)>i.length&&(e=i.length),r=i.substr(t,e),h.forEach(function(e){var t=new RegExp(e,"gi");r=r.replace(t,'<em class="search-keyword">'+e+"</em>")}),o+='<p class="search-result">'+r+"...</p>"),o+="</li>")}),o+="</ul>",n.innerHTML=o)})}})}),$(".modal").modal()</script><script src="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/js/index.js"></script><script src="/js/hexo-widget-tree.js"></script><div id="widget-tree"><ul><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/">github page </a><span class="tree-list-count">14</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/Termux/">Termux </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220101/termux-config/" title="Termux-config"><i class="post-icon gg-file-document"></i>Termux-config</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/keys/">keys </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220101/keys/" title="keys"><i class="post-icon gg-file-document"></i>keys</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/" title="50种最棒的开源爬虫框架/项目"><i class="post-icon gg-file-document"></i>50种最棒的开源爬虫框架/项目</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/Cesium/">Cesium </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/cesium-sheng-cheng-terrain-di-xing-shu-ju-ctb-fang-shi-ji-bu-zou/" title="Cesium 生成terrain地形数据----CTB方式及步骤"><i class="post-icon gg-file-document"></i>Cesium 生成terrain地形数据----CTB方式及步骤</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E6%9C%AF/">科研学术 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/ei-qi-kan-cha-xun/" title="EI期刊查询"><i class="post-icon gg-file-document"></i>EI期刊查询</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/html/">html </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20191121/html5-xuan-ku-dong-hua-ji-yuan-ma-demo-yan-shi/" title="HTML5炫酷动画及源码DEMO演示"><i class="post-icon gg-file-document"></i>HTML5炫酷动画及源码DEMO演示</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/">技术笔记 </a><span class="tree-list-count">15</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/opencv/">opencv </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/opencv-zai-csharp-zhong-ying-yong-opencvsharp/" title="OpenCV在Csharp中应用OpenCVSharp"><i class="post-icon gg-file-document"></i>OpenCV在Csharp中应用OpenCVSharp</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/OpenGL/">OpenGL </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/opengl-chao-ji-bao-dian-xue-xi-bi-ji-cao-zuo-xiang-su/" title="OpenGL超级宝典学习笔记操作像素"><i class="post-icon gg-file-document"></i>OpenGL超级宝典学习笔记操作像素</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/js/">js </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220615/js-han-shu-zhong-ru-he-shi-yong-ke-xuan-can-shu-bao-gua-ke-xuan-hui-diao-han-shu/" title="js函数中如何使用可选参数（包括可选回调函数）"><i class="post-icon gg-file-document"></i>js函数中如何使用可选参数（包括可选回调函数）</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%A0%91%E8%8E%93%E6%B4%BE/">树莓派 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/chu-chang-zhi-zuo-shu-mei-pai-zui-jian-dan-de-rootfs/" title="初尝制作树莓派最简单的rootfs"><i class="post-icon gg-file-document"></i>初尝制作树莓派最简单的rootfs</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220705/you-xi-kai-fa-zi-yuan-gamedevresource/" title="游戏开发资源GameDevResource"><i class="post-icon gg-file-document"></i>游戏开发资源GameDevResource</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20210430/win10-bitlocker-zhuan-ti/" title="win10-BitLocker专题"><i class="post-icon gg-file-document"></i>win10-BitLocker专题</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220425/mu-biao-gen-zong-suan-fa/" title="目标跟踪算法"><i class="post-icon gg-file-document"></i>目标跟踪算法</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">12</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/javascript-zhuan-ti/" title="JavaScript专题"><i class="post-icon gg-file-document"></i>JavaScript专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/docker-zhuan-ti/" title="Docker专题"><i class="post-icon gg-file-document"></i>Docker专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210401/windowsterminal-zhuan-ti/" title="Windows Terminal专题"><i class="post-icon gg-file-document"></i>Windows Terminal专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210401/wsl2-zhuan-ti/" title="WSL2专题"><i class="post-icon gg-file-document"></i>WSL2专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/xamarin-zhuan-ti/" title="Xamarin专题"><i class="post-icon gg-file-document"></i>Xamarin专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220426/csharp-zhuan-ti/" title="csharp专题"><i class="post-icon gg-file-document"></i>csharp专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210220/c-zhuan-ti/" title="c++专题"><i class="post-icon gg-file-document"></i>c++专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/hexo-zhuan-ti/" title="hexo专题"><i class="post-icon gg-file-document"></i>hexo专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/html-zhuan-ti/" title="html专题"><i class="post-icon gg-file-document"></i>html专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210327/jquery-zhuan-ti/" title="jQuery专题"><i class="post-icon gg-file-document"></i>jQuery专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/ssh-zhuan-ti/" title="ssh专题"><i class="post-icon gg-file-document"></i>ssh专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20250114/cookie-zhuan-ti/" title="cookie专题"><i class="post-icon gg-file-document"></i>cookie专题</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/javascript/">javascript </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220315/javascript-yu-yan-jing-sui-yu-bian-cheng-shi-jian/" title="JavaScript语言精髓与编程实践"><i class="post-icon gg-file-document"></i>JavaScript语言精髓与编程实践</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/iocp/">iocp </a><span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/iocp/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/cai-yong-wan-cheng-duan-kou-iocp-shi-xian-gao-xing-neng-wang-luo-fu-wu-qi-windows-c-ban/" title="采用完成端口（IOCP）实现高性能网络服务器（Windows c++版）"><i class="post-icon gg-file-document"></i>采用完成端口（IOCP）实现高性能网络服务器（Windows c++版）</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/python/">python </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240322/python-wang-ye-pa-chong-wen-ben-chu-li-ke-xue-ji-suan-ji-qi-xue-xi-shu-ju-wa-jue-bing-qi-pu/" title="Python 网页爬虫 & 文本处理 & 科学计算 & 机器学习 & 数据挖掘兵器谱"><i class="post-icon gg-file-document"></i>Python 网页爬虫 & 文本处理 & 科学计算 & 机器学习 & 数据挖掘兵器谱</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/MFC/">MFC </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/MFC/cef/">cef </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/mfc-ji-cheng-cef3-chuang-kou/" title="MFC集成CEF3窗口"><i class="post-icon gg-file-document"></i>MFC集成CEF3窗口</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/threejs/">threejs </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/threejs/Cesium/">Cesium </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/threejs-ji-cheng-di-tu-wa-pian/" title="ThreeJS集成地图瓦片"><i class="post-icon gg-file-document"></i>ThreeJS集成地图瓦片</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/visual-studio/">visual studio </a><span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/visual-studio/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220401/visual-studio-code-zhuan-ti/" title="Visual Studio Code 专题"><i class="post-icon gg-file-document"></i>Visual Studio Code 专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/windows-an-quan-gong-ju-jin-ji/" title="Windows安全工具锦集"><i class="post-icon gg-file-document"></i>Windows安全工具锦集</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%B8%97%E9%80%8F/">渗透 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%B8%97%E9%80%8F/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/kali-zhuan-ti/" title="kali专题"><i class="post-icon gg-file-document"></i>kali专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/">数字信号处理 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220330/shu-zi-xin-hao-chu-li-matlab-zuo-fft-shi-dian-shu-n-zen-me-xuan-qu/" title="【数字信号处理】Matlab做fft时点数N怎么选取"><i class="post-icon gg-file-document"></i>【数字信号处理】Matlab做fft时点数N怎么选取</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E4%BA%8C%E7%BB%B4%E7%A0%81/">二维码 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240806/er-wei-ma-de-sheng-cheng-xi-jie-he-yuan-li/" title="二维码的生成细节和原理"><i class="post-icon gg-file-document"></i>二维码的生成细节和原理</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/nextjs/">nextjs </a><span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-next-js-hexo-chong-gou-wo-de-bo-ke/" title="使用 Next.js + Hexo 重构我的博客"><i class="post-icon gg-file-document"></i>使用 Next.js + Hexo 重构我的博客</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-nextjs-he-tailwindcss-chong-gou-wo-de-bo-ke/" title="使用 NextJS 和 TailwindCSS 重构我的博客"><i class="post-icon gg-file-document"></i>使用 NextJS 和 TailwindCSS 重构我的博客</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-next-js-da-jian-ge-ren-bo-ke/" title="使用 Next.js 搭建个人博客"><i class="post-icon gg-file-document"></i>使用 Next.js 搭建个人博客</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/git/">git </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/git/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220609/git-zhuan-ti/" title="git专题"><i class="post-icon gg-file-document"></i>git专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/pdf/">pdf </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/pdf/wpf/">wpf </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/shi-yong-c-kai-fa-pdf-yue-du-qi-chu-tan-ji-yu-wpf-mei-you-shi-yong-kai-yuan-ku/" title="使用C#开发pdf阅读器初探（基于WPF，没有使用开源库）"><i class="post-icon gg-file-document"></i>使用C#开发pdf阅读器初探（基于WPF，没有使用开源库）</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记 </a><span class="tree-list-count">4</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/gong-chan-dang-xuan-yan/" title="共产党宣言"><i class="post-icon gg-file-document"></i>共产党宣言</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/quan-xue-xun-zi/" title="劝学-荀子"><i class="post-icon gg-file-document"></i>劝学-荀子</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20191203/lun-liu-jia-yao-zhi/" title="论六家要指"><i class="post-icon gg-file-document"></i>论六家要指</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/huang-di-yin-fu-jing/" title="黄帝阴符经"><i class="post-icon gg-file-document"></i>黄帝阴符经</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/">opencv </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/qrcode/">qrcode </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/qrcode/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/ji-yu-opencv-shi-bie-ding-wei-er-wei-ma-c-ban/" title="基于opencv 识别、定位二维码 （c++版）"><i class="post-icon gg-file-document"></i>基于opencv 识别、定位二维码 （c++版）</a></li></ul></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/acm/">acm </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/you-xi-she-ji-zhi-zuo-shi-shi-fou-hui-yong-dao-lei-si-acm-zhong-de-suan-fa-she-ji/" title="游戏设计制作时是否会用到类似 ACM 中的算法设计？"><i class="post-icon gg-file-document"></i>游戏设计制作时是否会用到类似 ACM 中的算法设计？</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/">数字签名证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/Let%E2%80%99s-Encrypt%E8%AF%81%E4%B9%A6/">Let’s Encrypt证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/Let%E2%80%99s-Encrypt%E8%AF%81%E4%B9%A6/SSL%E8%AF%81%E4%B9%A6/">SSL证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/zi-jian-shu-zi-qian-ming-zheng-shu/" title="自建数字签名证书"><i class="post-icon gg-file-document"></i>自建数字签名证书</a></li></ul></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240807/bjarne-stroustrup-s-faq-zhong-wen-ban/" title="Bjarne Stroustrup's FAQ（中文版）"><i class="post-icon gg-file-document"></i>Bjarne Stroustrup's FAQ（中文版）</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/follow/">follow </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/follow/rsshub/">rsshub </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20241213/follow-zhuan-ti/" title="Follow专题"><i class="post-icon gg-file-document"></i>Follow专题</a></li></ul></li></ul></li></ul><div id="widget-tree-button"><i class="gg-chevron-right"></i></div></div></body></html>