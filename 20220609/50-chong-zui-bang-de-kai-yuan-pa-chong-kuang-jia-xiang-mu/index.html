<!DOCTYPE html><html lang="en"><head><link href="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/css/index.css" rel="stylesheet"><link href="/css/hexo-widget-tree.css" rel="stylesheet"><!--[if lt IE 9]>
    <script src="http://cdn.static.runoob.com/libs/html5shiv/3.7/html5shiv.min.js"></script>
<![endif]--><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="shortcut icon" href="favicon-fish.ico"><link rel="alternate" type="application/rss+xml" title="LordYao" href="/atom.xml"><meta name="keywords" content="LordYao,scholar,要庆生,yaoqs,FUTURE &amp; CIVILIZATION，Natural/Social Philosophy &amp; Infomation Sciences"><meta name="description" content="A scholar magazine/journal like blog，FUTURE &amp; CIVILIZATION，Natural/Social Philosophy &amp; Infomation Sciences,A scholar magazine/journal-like blog,要庆生的blog"><script>(()=>{var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)})()</script><title>50种最棒的开源爬虫框架/项目 | LordYao</title><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js" integrity="sha256-3gQJhtmj7YnV1fmtbVcnAV6eI4ws0Tr48bVZCThtCGQ=" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" integrity="sha256-PI8n5gCcz9cQqQXm3PEtDuPG8qx9oFsFctPg0S5zb8g=" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/js/all.min.js"></script><link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/fontawesome.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/future.css"><link rel="stylesheet" href="/css/main.css"><script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/jquery.qrcode@1.0.3/jquery.qrcode.min.js"></script><script src="https://d3js.org/d3.v7.min.js"></script><script src="/js/ax.js"></script><script src="/js/main.js"></script><link rel="canonical" href="https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/"><meta name="generator" content="Hexo 7.3.0"></head><body><aside id="aside"><header><style>div#fork_me_on_github{margin-top:-2em;margin-left:-2em;margin-bottom:-5em}.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><div id="fork_me_on_github"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/" class="github-corner" aria-label="View source on GitHub"><svg width="8em" height="8em" viewBox="0 0 250 250" style="fill:#151515;color:#fff;position:absolute;top:0;border:0;left:0;transform:scale(-1,1)" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></div><a id="avatar" href="/"><img id="avatar_img" src="/images/avatar_sx_lite.png" alt="LordYao"></a><h1><a id="author" href="/">LordYao</a></h1><div id="github-iframe"><iframe src="https://ghbtns.com/github-btn.html?user=yaoqs&type=follow&count=true" scrolling="no" frameborder="0" width="150px" height="20px"></iframe></div><div id="weibo"></div><script src="https://tjs.sjs.sinajs.cn/open/api/js/wb.js"></script><iframe src="https://widget.weibo.com/relationship/followbutton.php?btn=red&amp;style=2&amp;uid=1262655355&amp;width=86&amp;height=24&amp;language=zh_cn" scrolling="no" marginheight="0" width="86" height="24" frameborder="0"></iframe><div id="follow-icons"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://space.bilibili.com/19354848" title="哔哩哔哩/bilibili"><i class="fab fa-twitch fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/yaokingson" title="csdn"><i class="fab fa-blogger fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hub.docker.com/u/lordyao" title="dockerhub"><i class="fab fa-docker fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://gitee.com/yaoqs" title="gitee"><i class="fab fa-git fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://ghbtns.com/github-btn.html?user=yaoqs&type=follow&count=true"><i></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/yaoqs" title="github"><i class="fab fa-github fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://stackexchange.com/users/5986345/francisco" title="StackOverflow"><i class="fab fa-stack-overflow fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="http://twitter.com/Lord_Honor_Yao" title="twitter/推特"><i class="fab fa-twitter fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="http://weibo.com/lordyao" title="weibo/微博"><i class="fab fa-weibo fa-2x"></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://widget.weibo.com/relationship/followbutton.php?btn=red&amp;style=2&amp;uid=1262655355&amp;width=86&amp;height=24&amp;language=zh_cn" title="加关注"><i></i></a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/people/yaoqs" title="知乎"><i class="fab fa-zhihu fa-2x"></i></a> <a id="rss" href="/atom.xml" title="RSS"><i class="fa fa-rss fa-2x"></i></a></div><span id="slogan">Slogan:<ul><li style="display:none">解放思想，发展生产力</li><li style="display:none">为天地立心，<br>为生民立命，<br>为往圣继绝学，<br>为万世开太平。</li><li style="display:none">知行合一</li><li style="display:none">凡事预则立，不预则废</li><li style="display:none">茍日新，日日新，又日新</li><li style="display:none">天之道，利而不害；<br>圣人之道，为而不争</li><li style="display:none">吾尝终日而思矣，不如须臾之所学也。<br>吾尝跂而望矣，不如登高之博见也。<br>君子生非异也，善假于物也。</li><li style="display:none">练得身形似鹤形，千株松下两函经。<br>我来问道无馀说，云在青霄水在瓶。</li><li style="display:none">寇可往，我亦可往</li><li style="display:none">我的思想是全人类的财富</li></ul><script>var sel=$("#slogan > ul > li");function lunbo(){arguments.callee.pre=arguments.callee.pre||0,sel[arguments.callee.pre].style.display="none",arguments.callee.pre=Math.floor(Math.random()*sel.length),sel[arguments.callee.pre].style.display="inline-block",setTimeout(lunbo,3e4)}lunbo()</script></span><span id="donate"><a href="/Donate" title="大吉大利 今晚吃鸡">Donate & Reward</a></span></header><footer id="footer-message">Copyright &copy; 2019 - <span id="year">2021</span> <a href="https://yaoqs.github.io" target="_blank">LordYao</a>. BY-NC-SA . All Rights Reserved.<br>Powered by <a href="http://hexo.io/" rel="external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://pages.github.com/" target="_blank">Github Pages</a>. Theme <a href="https://github.com/yaoqs/hexo-theme-scholar-future" rel="external nofollow noreferrer" target="_blank">scholar-future </a>designed by <a href="https://yaoqs.github.io" target="_blank">LordYao </a>.<script>var year=new Date(Date.now()).getFullYear();document.getElementById("year").innerText=year</script><div id="Statistics"><script>var _hmt=_hmt||[];(()=>{var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?2023f967cb85513ede1b6a3d58177776",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)})()</script>&nbsp;<script>var cnzz_protocol="https:"==document.location.protocol?"https://":"http://";document.write(unescape("%3Cspan id='cnzz_stat_icon_1278269244'%3E%3C/span%3E%3Cscript src='"+cnzz_protocol+"s4.cnzz.com/z_stat.php%3Fid%3D1278269244%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"))</script>&nbsp;<script>var cnzz_protocol="https:"==document.location.protocol?"https://":"http://";document.write(unescape("%3Cspan id='cnzz_stat_icon_1278269244'%3E%3C/span%3E%3Cscript src='"+cnzz_protocol+"s4.cnzz.com/z_stat.php%3Fid%3D1278269244%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"))</script>&nbsp;<script src="https://tajs.qq.com/stats?sId=66496804" charset="UTF-8" async></script>&nbsp; <a target="_blank" rel="noopener external nofollow noreferrer" href="https://info.flagcounter.com/tQfY"><img src="https://s11.flagcounter.com/mini/tQfY/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" alt="Flag Counter" border="0"></a>&nbsp;<script>((e,n,c,s,t,r)=>{e[s]=e[s]||function(){(e[s].c=e[s].c||[]).push(arguments)},e[s].s=!1,t=n.getElementsByTagName(c)[0],(r=n.createElement(c)).src="//s.union.360.cn/332983.js",r.defer=!0,r.async=!0,t.parentNode.insertBefore(r,t)})(window,document,"script","_qha")</script>&nbsp;<script src="//js.users.51.la/21341261.js"></script>&nbsp;<script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js?id=JhwXbvPO5Ijy6W6x&ck=JhwXbvPO5Ijy6W6x"></script><script id="LA-DATA-WIDGET" crossorigin="anonymous" charset="UTF-8" src="https://v6-widget.51.la/v6/JhwXbvPO5Ijy6W6x/quote.js?theme=0&f=12&display=0,0,0,1,0,0,0,1"></script><a target="_blank" title="51la网站统计" href="https://v6.51.la/land/JhwXbvPO5Ijy6W6x" rel="external nofollow noreferrer"><img src="https://sdk.51.la/icon/4-5.png"></a>&nbsp;<script src="https://sdk.51.la/perf/js-sdk-perf.min.js" crossorigin="anonymous"></script><script>(new LingQue.Monitor).init({id:"JhwYVlJAdB7w0kYc",sendSpaPv:!0})</script>&nbsp;<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://busuanzi.ibruce.info/" title="不蒜子">总访问量:<span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></a>. </span>&nbsp;<br><span class="post-count">site total word count:475.6k</span></div></footer></aside><nav class="navbar"><h6><span id="custom_html_list"></span> &middot; <a href="/About">About </a>&middot; <a href="/Lab">Lab </a>&middot; <a href="/Navigator">Navigator </a>&middot; <a href="/Feature">Feature </a>&middot; <a href="/Donate">Donate </a>&middot; <a href="/Game">Game </a>&middot; <a href="/Music">Music </a><a href="#searchModal" class="modal-trigger waves-effect waves-light"><span id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></span></a><div id="repos"><div class="dropdown" onmouseenter='showList("dropdown-a")' onmouseleave='showList("dropdown-a")'><a id="a" href="javascript:void(0)" rel="external nofollow noreferrer" class="dropbtn">&#9776; Repositories Pages</a><div class="dropdown-content" id="dropdown-a"><script>$(async function(){jax("https://api.github.com/users/yaoqs/repos",await function(t){d3.select("body").select("#dropdown-a").selectAll("a").data(t).enter().append("a").attr("target","_blank").style("padding-left","1em").text(t=>"§ "+t.full_name).attr("href",t=>"https://yaoqs.github.io/"+t.name)},function(){$("<div style='color:red;width: 9em;height: 2em;text-align: center;display: table-cell;vertical-align: middle;'>当前无网络</div>").appendTo($("#dropdown-a"))})})</script></div></div>&middot;<div class="dropdown" onmouseenter='showList("dropdown-b")' onmouseleave='showList("dropdown-b")'><a href="/" class="dropbtn">Home</a><div class="dropdown-content" id="dropdown-b"><a href="/"><i class="fas fa-home" aria-hidden="true"></i><span style="text-align:center">&#x0009;首页/Index</span></a> <a href="/tags"><i class="fas fa-tags" aria-hidden="true"></i><span style="text-align:center">&#x0009;标签/Tags</span></a> <a href="/categories"><i class="fas fa-bookmark" aria-hidden="true"></i><span style="text-align:center">&#x0009;归类/Categories</span></a> <a href="/archives"><i class="fas fa-archive" aria-hidden="true"></i><span style="text-align:center">&#x0009;文档/Archives</span></a></div></div></div></h6></nav><div id="journal"><div id="journal-name">FUTURE & CIVILIZATION<br>Natural/Social Philosophy & Infomation Sciences</div><div id="post"><main id="content"><hr id="topline"><div id="DOI">06/09, 2022<br>https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/<br><span class="post-count">post word count: 9.2k words.&nbsp; </span><span class="post-count">post estimate read time: 35 min</span></div><article class="post"><h1 class="post-title">50种最棒的开源爬虫框架/项目</h1><div id="post-author">Yao Qingsheng<br>Department of Natural/Social Philosophy & Infomation Sciences, CHINA</div><section class="post-content article-entry"><section id="Abstract"><hr class="AbstractLine"><span class="Abstract">Abstract</span> <span class="Abstract-content"><div id="toc" class="toc-article"><a class="js-toggle-toc" href="javascript:void(0)" rel="external nofollow noreferrer"></a><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">Python 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Scrapy"><span class="toc-text">1. Scrapy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Cola"><span class="toc-text">2. Cola</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Crawley"><span class="toc-text">3. Crawley</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-MechanicalSoup"><span class="toc-text">4. MechanicalSoup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-PySpider"><span class="toc-text">5. PySpider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Portia"><span class="toc-text">6. Portia</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Beautifulsoup"><span class="toc-text">7. Beautifulsoup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Spidy-%E7%88%AC%E8%99%AB"><span class="toc-text">8. Spidy 爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-Garb"><span class="toc-text">9. Garb</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">Java 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-Apache-Nutch"><span class="toc-text">10. Apache Nutch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-Heritrix"><span class="toc-text">11. Heritrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-ACHE-%E7%88%AC%E8%99%AB"><span class="toc-text">12. ACHE 爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-Crawler4j"><span class="toc-text">13. Crawler4j</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-Gecco"><span class="toc-text">14. Gecco</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-BUbiNG"><span class="toc-text">15. BUbiNG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-Narconex"><span class="toc-text">16. Narconex</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-WebSPHINX"><span class="toc-text">17. WebSPHINX</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-Spiderman"><span class="toc-text">18. Spiderman</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-WebCollector"><span class="toc-text">19. WebCollector :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-Webmagic"><span class="toc-text">20. Webmagic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-StormCrawler"><span class="toc-text">21. StormCrawler</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JavaScript-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">JavaScript 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#22-NodeCrawler"><span class="toc-text">22. NodeCrawler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-Simplecrawler"><span class="toc-text">23. Simplecrawler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-Js-crawler"><span class="toc-text">24. Js-crawler :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-Webster"><span class="toc-text">25. Webster</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26-Node-osmosis"><span class="toc-text">26. Node-osmosis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#27-Supercrawler"><span class="toc-text">27. Supercrawler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#28-Web-scraper-%E7%9A%84-Chrome-%E6%89%A9%E5%B1%95"><span class="toc-text">28. Web scraper 的 Chrome 扩展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#29-Headless-Chrome-%E7%88%AC%E8%99%AB"><span class="toc-text">29. Headless Chrome 爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#30-X-ray"><span class="toc-text">30. X-ray</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#C-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">C 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-Httrack"><span class="toc-text">31. Httrack</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-GNU-Wget"><span class="toc-text">32. GNU Wget</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#C-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB-v2"><span class="toc-text">C++编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#33-gigablast"><span class="toc-text">33. gigablast</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#C-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB-v3"><span class="toc-text">C#编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#34-http-Arachnode-net"><span class="toc-text">34. http:&#x2F;&#x2F;Arachnode.net</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35-Abot"><span class="toc-text">35. Abot</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#36-Hawk"><span class="toc-text">36. Hawk</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#37-SkyScraper"><span class="toc-text">37. SkyScraper</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NET-%E7%BC%96%E5%86%99%E7%9A%84-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">.NET 编写的 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#38-DotnetSpider"><span class="toc-text">38. DotnetSpider</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PHP-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">PHP 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#39-Goutte"><span class="toc-text">39. Goutte</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#40-Dom-crawler"><span class="toc-text">40. Dom-crawler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#41-Pspider"><span class="toc-text">41. Pspider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-Php-spider"><span class="toc-text">42. Php-spider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-Spatie-Crawler"><span class="toc-text">43. Spatie &#x2F; Crawler</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ruby-%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">Ruby 实现的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#44-Mechanize"><span class="toc-text">44. Mechanize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GO-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">GO 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#45-Colly"><span class="toc-text">45. Colly</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#46-Gopa"><span class="toc-text">46. Gopa</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#47-Pholcus"><span class="toc-text">47. Pholcus</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#R-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">R 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#48-Rvest"><span class="toc-text">48. Rvest</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scala-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">Scala 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#49-Sparkler"><span class="toc-text">49. Sparkler</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Perl-%E7%BC%96%E5%86%99%E7%9A%84%E5%BC%80%E6%BA%90-Web-%E7%88%AC%E8%99%AB"><span class="toc-text">Perl 编写的开源 Web 爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#50-Web-scraper"><span class="toc-text">50. Web-scraper</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-text">小结</span></a></li></ol></div></div></span><span class="Abstract">Keywords <span class="keywords-content"><a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a>&nbsp; <a href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>&nbsp;</span></span><hr class="AbstractLine"><span class="Abstract">Citation <span class="keywords-content">Yao Qing-sheng&period;50种最棒的开源爬虫框架/项目&period;FUTURE & CIVILIZATION Natural/Social Philosophy & Infomation Sciences&comma;20220609&period; https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/</span></span><hr class="AbstractLine"></section><section><p>作者：<strong><a href="https://link.zhihu.com/?target=http%3A//www.prowebscraper.com/blog/50-best-open-source-web-crawlers/" rel="external nofollow noreferrer">Prowebscraper 博客</a></strong></p><p>译者：Rays</p><p><strong>摘要：</strong> 说起爬虫框架，你可能会马上脱口而出：「 Scrapy 或者 Pyspider」，甚至你可能认为只有 Python 才能爬虫。其实还有很多好用的开源爬虫框架，也绝不仅仅只有 Python 才能写爬虫，大多数热门语言都可以做。</p><p>总之，开源 Web 爬虫纷繁多样，下面按照所用程语言，罗列五十种最好的开源爬虫框架，每一个各具特长，适用于不同场景和用户需求。下面来一睹为快。</p><p><img src="https://pic1.zhimg.com/v2-f55e5381062a9d4ae47e769e7f8313d8_r.jpg" alt=""></p><h2 id="Python-编写的开源-Web-爬虫"><a class="header-anchor" href="#Python-编写的开源-Web-爬虫">※</a><strong>Python 编写的开源 Web 爬虫</strong></h2><h3 id="1-Scrapy"><a class="header-anchor" href="#1-Scrapy">※</a><strong>1. Scrapy</strong></h3><ul><li><strong>实现语言</strong>：Python</li><li><strong>GitHub Star 数</strong>：28660</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic2.zhimg.com/v2-0b652a141850fd3b89a3fe101f329e95_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>Scrapy 是一种高速的高层 Web 爬取和 Web 采集框架，可用于爬取网站页面，并从页面中抽取结构化数据。</li><li>Scrapy 的用途广泛，适用于从数据挖掘、监控到自动化测试。</li><li>Scrapy 设计上考虑了从网站抽取特定的信息，它支持使用 CSS 选择器和 XPath 表达式，使开发人员可以聚焦于实现数据抽取。</li><li>对于熟悉 Python 的开发人员，只需几分钟就能建立并运行 Scrapy。</li><li>支持运行在 Linux、Mac OS 和 Windows 系统上。</li></ul><p><strong>特性</strong>：</p><ul><li>内置支持从 HTML 和 XML 抽取数据、使用扩展的 CSS 选择器（Selector）和 XPath 表达式等特性。</li><li>支持以多种格式（JSON、CSV、XML）生成输出。</li><li>基于 Twisted 构建。</li><li>稳健的支持，自动检测编码方式。</li><li>快速，功能强大。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//docs.scrapy.org/en/latest/" rel="external nofollow noreferrer">https://docs.scrapy.org/en/latest/</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//scrapy.org/" rel="external nofollow noreferrer">https://scrapy.org/</a></strong></p><h3 id="2-Cola"><a class="header-anchor" href="#2-Cola">※</a><strong>2. Cola</strong></h3><ul><li><strong>实现语言</strong>：Python</li><li><strong>GitHub Star 数</strong>：1274</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Cola 是一种高层分布式爬取框架，实现从网站爬取网页，并从中抽取结构化数据。</li><li>它提供了一种实现目标数据获取的简单且灵活的方式。</li><li>用户只需要编写其中一部分代码，就可在本地和分布式环境下运行。</li></ul><p><strong>特性</strong>：</p><ul><li>高层分布式爬取框架。</li><li>简单且高速。</li><li>灵活。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/chineking/cola" rel="external nofollow noreferrer">https://github.com/chineking/cola</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//pypi.org/project/Cola/" rel="external nofollow noreferrer">https://pypi.org/project/Cola/</a></strong></p><h3 id="3-Crawley"><a class="header-anchor" href="#3-Crawley">※</a><strong>3. Crawley</strong></h3><ul><li><strong>实现语言</strong> Python</li><li><strong>GitHub Star 数</strong>： 144</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Crawley 是一种 Python 爬取和采集框架，意在简化开发人员从 Web 网页抽取数据到数据库等结构化存储中。</li></ul><p><strong>特性</strong>：</p><ul><li>基于 Eventlet 构建的高速 Web 爬虫。</li><li>支持 MySQL、PostgreSQL、Oracle、Sqlite 等关系数据库引擎。</li><li>支持 MongoDB、CouchDB 等 NoSQL 数据库（最新特性！）。</li><li>支持导出数据为 JSON、XML 和 CSV 格式（最新特性！）。</li><li>命令行工具。</li><li>支持开发人员使用自己喜好的工具，例如 XPath 或 Pyquery（一种类似于 JQuery 的 Python 软件库）等。</li><li>支持 Cookie 处理器（Handler）。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//pythonhosted.org/crawley/" rel="external nofollow noreferrer">https://pythonhosted.org/crawley/</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=http%3A//project.crawley-cloud.com/" rel="external nofollow noreferrer">http://project.crawley-cloud.com/</a></strong></p><h3 id="4-MechanicalSoup"><a class="header-anchor" href="#4-MechanicalSoup">※</a><strong>4. MechanicalSoup</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>GitHub Star 数</strong>： 2803</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>MechanicalSoup 是一种设计模拟人类使用 Web 浏览器行为的 Python 软件库，它基于解析软件库 BeautifulSoup 构建。</li><li>如果开发人员需要从单个站点采集数据，或是不需要大量数据采集，那么使用 MechanicalSoup 是一种简单高效的方法。</li><li>MechanicalSoup 自动存储和发送 Cookie、跟踪重定向、支持链接跟随和提交表单。</li></ul><p><strong>特性</strong>：</p><ul><li>轻量级。</li><li>支持 Cookie 处理器。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//mechanicalsoup.readthedocs.io/en/stable/" rel="external nofollow noreferrer">https://mechanicalsoup.readthedocs.io/en/stable/</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//mechanicalsoup.readthedocs.io/" rel="external nofollow noreferrer">https://mechanicalsoup.readthedocs.io/</a></strong></p><h3 id="5-PySpider"><a class="header-anchor" href="#5-PySpider">※</a><strong>5. PySpider</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>GitHub Star 数</strong>： 11803</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>PySpider 是一种 Python 编写的强大 Web 爬虫。</li><li>它支持 JavaScript 网页，并具有分布式架构。</li><li>PySpider 支持将爬取数据存储在用户选定的后台数据库，包括**<a href="https://link.zhihu.com/?target=https%3A//www.mysql.com/" rel="external nofollow noreferrer">MySQL</a>**, <strong><a href="https://link.zhihu.com/?target=https%3A//www.mongodb.org/" rel="external nofollow noreferrer">MongoDB</a></strong>, <strong><a href="https://link.zhihu.com/?target=http%3A//redis.io/" rel="external nofollow noreferrer">Redis</a></strong>, <strong><a href="https://link.zhihu.com/?target=https%3A//www.sqlite.org/" rel="external nofollow noreferrer">SQLite</a></strong>, **<a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/" rel="external nofollow noreferrer">Elasticsearch</a>**等。</li><li>支持开发人员使用 RabbitMQ、Beanstalk 和 Redis 等作为消息队列。</li></ul><p><strong>特性</strong>：</p><ul><li>提供强大 Web 界面，具有脚本编辑器、任务监控、项目管理器和结果查看器。</li><li>支持对重度 Ajax 网站的爬取。</li><li>易于实现适用、快速的爬取。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//docs.pyspider.org/" rel="external nofollow noreferrer">http://docs.pyspider.org/</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/binux/pyspider" rel="external nofollow noreferrer">https://github.com/binux/pyspider</a></strong></p><h3 id="6-Portia"><a class="header-anchor" href="#6-Portia">※</a><strong>6. Portia</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>GitHub Star 数</strong>： 6250</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="243" height="243"></svg>)</p><p><strong>简介</strong>：</p><ul><li>Portia 是由 Scrapinghub 创建的一种可视化爬取工具，它不需要用户具有任何程序开发知识。</li><li>如果用户并非开发人员，最好直接使用 Portia 实现 Web 爬取需求。</li><li>用户无需任何安装就可免费试用 Portia，只需要在 Scrapinghub 注册一个账户，就可使用托管版本。</li><li>即便用户没有编程技能，在 Portia 中创建爬虫并抽取 Web 内容也是非常易于实现的。</li><li>用户无需安装任何程序，因为 Portia 是运行在 Web 页面上的。</li><li>用户可以使用 Portia 的基本点击工具标注需要爬取的数据，然后 Portia 就会根据这些标注理解如何爬取类似页面中的数据。</li><li>一旦检测到需要爬取的页面，Portia 会形成一个用户已创建结构的实例。</li></ul><p><strong>特性</strong>：</p><ul><li>通过记录并回放用户在页面上的操作，实现点击、拖动和等待等动作。</li><li>Portia 可以很好地爬取基于 Ajax 构建的网站（基于 Splash），也适用于爬取 Backbone、Angular 和 Ember 等重度 JavsScript 框架。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//portia.readthedocs.io/en/latest/index.html" rel="external nofollow noreferrer">https://portia.readthedocs.io/en/latest/index.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/scrapinghub/portia" rel="external nofollow noreferrer">https://github.com/scrapinghub/portia</a></strong></p><h3 id="7-Beautifulsoup"><a class="header-anchor" href="#7-Beautifulsoup">※</a><strong>7. Beautifulsoup</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="250" height="298"></svg>)</p><p><strong>简介</strong>：</p><ul><li>Beautiful Soup 一种设计用于实现 Web 爬取等快速数据获取项目的 Python 软件库。</li><li>它在设计上处于 HTML 或 XML 解析器之上，提供用于迭代、搜索和修改解析树等功能的 Python 操作原语。往往能为开发人员节省数小时乃至数天的工作。</li></ul><p><strong>特性</strong>：</p><ul><li>Beautiful Soup 自动将输入文档转换为 Unicode 编码，并将输出文档转换为 UTF-8 编码。</li><li>Beautiful Soup 处于一些广为采用的 Python 解析器（例如，<strong><a href="https://link.zhihu.com/?target=http%3A//lxml.de/" rel="external nofollow noreferrer">lxml</a><strong>和</strong><a href="https://link.zhihu.com/?target=http%3A//code.google.com/p/html5lib/" rel="external nofollow noreferrer">html5lib</a></strong>）之上，支持用户尝试使用多种不同的解析策略，并在速度和灵活性上做出权衡。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="external nofollow noreferrer">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.crummy.com/software/BeautifulSoup/" rel="external nofollow noreferrer">https://www.crummy.com/software/BeautifulSoup/</a></strong></p><h3 id="8-Spidy-爬虫"><a class="header-anchor" href="#8-Spidy-爬虫">※</a><strong>8. Spidy 爬虫</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>GitHub Star 数</strong>： 152</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic2.zhimg.com/v2-73a97fabe948e67aba729d3190840aa9_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>Spidy 是一种从命令行运行的 Web 爬虫。易于使用。用户只需提供 Web 网页的 URL 链接，Spidy 就可以开始爬取！Spidy 无疑是一种整体爬取 Web 的简单有效的方式。</li><li>Spidy 使用 Python 请求查询 Web 页面，并使用 lxml 抽取页面中的所有链接。非常简单！</li></ul><p><strong>特性</strong>：</p><ul><li>错误处理。</li><li>跨平台兼容性。</li><li>频繁时间戳日志。</li><li>可移植性。</li><li>用户友好的日志。</li><li>保存 Web 页面。</li><li>支持文件压缩。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/rivermont/spidy" rel="external nofollow noreferrer">https://github.com/rivermont/spidy</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//project.crawley-cloud.com/" rel="external nofollow noreferrer">http://project.crawley-cloud.com/</a></strong></p><h3 id="9-Garb"><a class="header-anchor" href="#9-Garb">※</a><strong>9. Garb</strong></h3><ul><li><strong>实现语言</strong>： Python</li><li><strong>GitHub Star 数</strong>： 1627</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Grab 是一种用于构建爬虫的 Python 框架。</li><li>使用 Grab 可构建出各种复杂度的 Web 爬虫，从只有五行代码的脚本，到可处理百万量级 Web 页面的复杂异步爬虫。</li><li>Grab 提供了执行网络请求、处理接收内容的 API。例如，实现与 HTML 文档的 DOM 树进行交互。</li></ul><p><strong>特性</strong>：</p><ul><li>支持 HTTP 和 SOCKS 代理，可使用也可不使用认证。</li><li>自动字符集检测。</li><li>强大的 API，支持使用 XPath 查询从 HTML 文档的 DOM 树中抽取数据。</li><li>自动 Cookie（或会话）支持。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//grablib.org/en/latest/" rel="external nofollow noreferrer">https://grablib.org/en/latest/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/lorien/grab" rel="external nofollow noreferrer">https://github.com/lorien/grab</a></strong></p><h2 id="Java-编写的开源-Web-爬虫"><a class="header-anchor" href="#Java-编写的开源-Web-爬虫">※</a><strong>Java 编写的开源 Web 爬虫</strong></h2><h3 id="10-Apache-Nutch"><a class="header-anchor" href="#10-Apache-Nutch">※</a><strong>10. Apache Nutch</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 1743</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic1.zhimg.com/v2-3554a536f366655fc1cfb54ce52ce32c_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>Apache Nutch 是一种高度可扩展、可伸缩的开源 Web 爬虫软件项目。</li><li>如果要列出最好的开源 Web 爬虫列表，Apache Nutch 无疑金榜题名。</li><li>作为一种用于数据挖掘的高度可扩展、可伸缩的开源代码 Web 数据抽取软件项目，Apache Nutch 得到了广泛的使用。</li><li>Nutch 支持单机运行，但是在 Hadoop 集群上运行可最大化地发挥其强大能力。</li><li>全球范围内很多数据分析人员和科研人员、应用开发人员和 Web 文本挖掘工程师都在使用 Apache Nutch。</li><li>Apache Nutch 是一种 Java 编写的跨平台解决方案。</li></ul><p><strong>特性</strong>：</p><ul><li>默认情况下，爬取数据和分析数据是独立的过程。</li><li>广泛支持多种文档格式，包括纯文本、HTML/XHTML+XML、XML、PDF、ZIP 等。</li><li>使用 XPath 和命名空间实现映射。</li><li>通过 Hadoop 支持分布式文件系统。</li><li>链接图形式的数据库。</li><li>支持 NTLM 认证。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//wiki.apache.org/nutch/" rel="external nofollow noreferrer">https://wiki.apache.org/nutch/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//nutch.apache.org/" rel="external nofollow noreferrer">http://nutch.apache.org/</a></strong></p><h3 id="11-Heritrix"><a class="header-anchor" href="#11-Heritrix">※</a><strong>11. Heritrix</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 1236</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>在使用 Java 编写的免费开源 Web 爬虫中，Heritrix 是其中一种得到广泛使用的工具。事实上，它是一种可扩展、Web 规模、存档质量（archival-quality）的 Web 爬取项目。</li><li>Heritrix 是一种扩展能力和性能很好的解决方案，支持用户即刻爬取并归档一组网站。此外，它在设计上考虑了 robots.txt 禁止规则和 META 机器人标签。</li><li>Heritrix 可运行在 Linux/Unix 和 Windows 系统上。</li></ul><p><strong>特性</strong>：</p><ul><li>HTTP 认证。</li><li>NTLM 认证。</li><li>链接抽取中的 XSL 转换。</li><li>独立于搜索引擎。</li><li>是一种成熟并稳定的平台。</li><li>高度可配置。</li><li>支持在任一机器上运行。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/internetarchive/heritrix3/wiki/Heritrix%25203.0%2520and%25203.1%2520User%2520Guide" rel="external nofollow noreferrer">https://github.com/internetarchive/heritrix3/wiki/Heritrix%203.0%20and%203.1%20User%20Guide</a></strong></p><p>– <strong>官方站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/internetarchive/heritrix3b" rel="external nofollow noreferrer">https://github.com/internetarchive/heritrix3b</a></strong></p><h3 id="12-ACHE-爬虫"><a class="header-anchor" href="#12-ACHE-爬虫">※</a><strong>12. ACHE 爬虫</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 154</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="231" height="120"></svg>)</p><p><strong>简介</strong>：</p><ul><li>ACHE 是一种专用于特定用途的 Web 爬虫。</li><li>ACHE 爬取满足特定标准的 Web 页面。例如，属于特定领域并包含用户指定模式的页面。</li><li>不同于通用爬虫，ACHE 使用页面分类器遴选特定领域中的相关和无关页面。</li><li>页面分类器可以是基本的正则表达式（例如，匹配所有包含给定单词的页面），也可以基于机器学习的分类模型。ACHE 也可以自动学习如何对链接做优先处理，实现高效地定位相关内容，避免检索无关的页面内容。</li></ul><p><strong>特性</strong>：</p><ul><li>对固定网站列表的正常爬取。</li><li>通过自动链接优先处理，发现并爬取新的相关网站。</li><li>可配置不同类型的页面分类器（例如，机器学习、正则表达式等）。</li><li>持续重新爬取站点，实现页面更新的发现。</li><li>使用 ElasticSearch 对爬取页面做索引。</li><li>实时搜索爬取页面的 Web 接口。</li><li>用于监控爬虫的 REST API 和基于 Web 的用户接口。</li><li>使用 TOR 代理爬取隐含服务。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//ache.readthedocs.io/en/latest/" rel="external nofollow noreferrer">http://ache.readthedocs.io/en/latest/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/ViDA-NYU/ache" rel="external nofollow noreferrer">https://github.com/ViDA-NYU/ache</a></strong></p><h3 id="13-Crawler4j"><a class="header-anchor" href="#13-Crawler4j">※</a><strong>13. Crawler4j</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 3039</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>crawler4j 是一种 Java 编写的开源 Web 爬虫，提供了爬取 Web 网站的基本接口。</li><li>开发人员可以使用 crawler4j 在数分钟内建立一个多线程 Web 爬虫。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/yasserg/crawler4j" rel="external nofollow noreferrer">https://github.com/yasserg/crawler4j</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/yasserg/crawler4j" rel="external nofollow noreferrer">https://github.com/yasserg/crawler4j</a></strong></p><h3 id="14-Gecco"><a class="header-anchor" href="#14-Gecco">※</a><strong>14. Gecco</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 1245</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Gecco 是一种使用 Java 开发的轻量级 Web 爬虫，易于使用。</li><li>Gecco 集成了 jsoup、httpclient、fastjson、spring、htmlunit、redission 等优秀框架。用户只需要配置一系列 jQuery 风格选择器，就能很快地建立一个爬虫。</li><li>Gecco 框架具有优秀的扩展能力。框架基于一些开放式和封闭式设计原则，对改进封闭，对扩展开放。</li></ul><p><strong>特性</strong>：</p><ul><li>易于使用，使用 jQuery 风格选择器抽取元素。</li><li>支持页面中的异步 Ajax 请求。</li><li>支持页面 JavaScript 变量抽取。</li><li>使用 Redis 实现分布式爬取（参见 gecco-redis 文档）。</li><li>支持使用 Spring 开发业务逻辑（参见 gecco-spring 文档）。</li><li>支持 htmlunit 扩展（参见 gecco-htmlunit 文档）。</li><li>支持多种扩展机制。</li><li>支持下载 UserAgent 的随机选择。</li><li>支持下载代理服务器的随机选取。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/xtuhcy/gecco" rel="external nofollow noreferrer">https://github.com/xtuhcy/gecco</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/xtuhcy/gecco" rel="external nofollow noreferrer">https://github.com/xtuhcy/gecco</a></strong></p><h3 id="15-BUbiNG"><a class="header-anchor" href="#15-BUbiNG">※</a><strong>15. BUbiNG</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>：24</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>BUbiNG 令人惊喜，它可称为下一代的开源 Web 爬虫。BUbiNG 是一种 Java 开发的完全分布式爬虫（无需中央协调），每秒可爬取数千个网页，并支持采集大规模数据集。</li><li>BUbiNG 的分布式是基于高速协议实现的，因此可以获得非常高的通量。</li><li>BUbiNG 提供对海量数据的大规模爬取。它完全可配置、易于扩展，并可集成垃圾信息检测。</li></ul><p><strong>特性</strong>：</p><ul><li>高度并行。</li><li>完全分布式。</li><li>使用 JAI4J。JAI4J 是一种基于 JGroups 实现的瘦功能层，实现任务指派。</li><li>（当前）使用剥离网页的指纹，检测近似的重复内容。</li><li>快速。</li><li>大规模爬取。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//law.di.unimi.it/software/bubing-docs/index.html" rel="external nofollow noreferrer">http://law.di.unimi.it/software/bubing-docs/index.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//law.di.unimi.it/software.php%23bubing" rel="external nofollow noreferrer">http://law.di.unimi.it/software.php#bubing</a></strong></p><h3 id="16-Narconex"><a class="header-anchor" href="#16-Narconex">※</a><strong>16. Narconex</strong></h3><ul><li><strong>实现语言</strong>：Java</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic4.zhimg.com/v2-47ae5be7edc6c681a379c405899abc2f_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>对于寻求可满足企业级需求的开源 Web 爬虫的用户而言，Narconex 是一种很好的工具。</li><li>Norconex 支持用户爬取任何 Web 内容。用户可以独立运行这种全功能数据采集器，或是将其集成在自己的应用中。</li><li>支持所有操作系统。可在具有一般容量的单体服务器上爬取数百万信息。此外，Narconex 提供多种内容和元数据操作特性，还可以抽取页面中特定的图像。</li></ul><p><strong>特性</strong>：</p><ul><li>多线程。</li><li>支持按各种计划任务，抽取不同时间段的数据。</li><li>从 HTML、Word、PDF 等多种文件格式中抽取文本内容。</li><li>抽取文档相关的元数据。</li><li>支持抽取使用用 JavaScript 渲染的页面。</li><li>检测语言。</li><li>支持翻译。</li><li>可配置爬取速度。</li><li>可检测发生修改或已被删除的文档。</li><li>支持使用外部命令分析或操作文档。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.norconex.com/collectors/collector-http/getting-started" rel="external nofollow noreferrer">http://www.norconex.com/collectors/collector-http/getting-started</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.norconex.com/collectors/collector-http/" rel="external nofollow noreferrer">http://www.norconex.com/collectors/collector-http/</a></strong></p><h3 id="17-WebSPHINX"><a class="header-anchor" href="#17-WebSPHINX">※</a><strong>17. WebSPHINX</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li>当前尚不提供官方支持。</li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="296" height="225"></svg>)</p><p><strong>简介</strong>：</p><ul><li>WebSphinix 是一种非常易于使用的可定制 Web 爬虫。它设计用于高级 Web 用户和 Java 编程人员，支持他们自动爬取小部分 Web。</li><li>WebSphinix 数据抽取解决方案也提供了一种全面的 Java 类库和交互式软件开发环境。WebSphinix 包括两部分：爬虫基准测试（Crawler Workbench），WebSPHINX 类库。</li><li>爬虫基准测试提供了很好的用户图形接口，支持用户配置并控制定制的 Web 爬虫。</li><li>WebSPHINX 类库为使用 Java 编写 Web 爬虫提供支持。</li><li>WebSphinix 支持运行在 Windows、Linux、Mac 和 Android IOS 上。</li></ul><p><strong>特性</strong>：</p><ul><li>以图的方式可视化 Web 页面采集。</li><li>将多个页面组合为单个文档，以供查看和打印。</li><li>支持抽取所有满足设定模式的文本。</li><li>支持 HTML 解析。</li><li>支持 robot.txt 禁止标准。</li><li>通用 HTML 转换。</li><li>多线程 Web 页面检索。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.cs.cmu.edu/~rcm/websphinx/doc/index.html" rel="external nofollow noreferrer">https://www.cs.cmu.edu/~rcm/websphinx/doc/index.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.cs.cmu.edu/~rcm/websphinx/%23about" rel="external nofollow noreferrer">https://www.cs.cmu.edu/~rcm/websphinx/#about</a></strong></p><h3 id="18-Spiderman"><a class="header-anchor" href="#18-Spiderman">※</a><strong>18. Spiderman</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 2400</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Spiderman 是一种 Java 开源 Web 数据抽取工具。它采集特定的 Web 页面，并从中抽取有用数据。</li><li>Spiderman 主要使用 XPath 和正则表达式等技术抽取实际数据。</li></ul><p><strong>特性</strong>：</p><ul><li>更高的性能。</li><li>持久化集合状态。</li><li>分布式。</li><li>支持 JavaScript。</li><li>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//gitee.com/l-weiwei/spiderman" rel="external nofollow noreferrer">https://gitee.com/l-weiwei/spiderman</a></strong></li></ul><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//gitee.com/l-weiwei/spiderman" rel="external nofollow noreferrer">https://gitee.com/l-weiwei/spiderman</a></strong></p><h3 id="19-WebCollector"><a class="header-anchor" href="#19-WebCollector">※</a><strong>19. WebCollector :</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 1986</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>WebCollector 是一种基于 Java 的开源 Web 爬虫框架。</li><li>它为实现 Web 爬取功能提供了一下基本的接口。用户可以使用它在五分钟内建立起一个多线程爬虫。</li></ul><p><strong>特性</strong>：</p><ul><li>快速。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/CrawlScript/WebCollector" rel="external nofollow noreferrer">https://github.com/CrawlScript/WebCollector</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/CrawlScript/WebCollector" rel="external nofollow noreferrer">https://github.com/CrawlScript/WebCollector</a></strong></p><h3 id="20-Webmagic"><a class="header-anchor" href="#20-Webmagic">※</a><strong>20. Webmagic</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>： 6891</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic3.zhimg.com/v2-c0b0e6efba453137639551e5d11a1542_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>WebMagic 是一种可扩展的爬虫框架。</li><li>WebMagic 涵盖了爬虫的整个生命周期，包括下载、URL 管理、内容抽取和持久化。</li><li>可用于简化一些特定爬虫的开发。</li></ul><p><strong>特性</strong>：</p><ul><li>高度灵活的简单内核。</li><li>提供实现 HTML 抽取的简单 API。</li><li>使用 POJO 标注定制爬虫，无需配置。</li><li>支持多线程和分布式。</li><li>易于集成。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//webmagic.io/docs/en/" rel="external nofollow noreferrer">http://webmagic.io/docs/en/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/code4craft/webmagic" rel="external nofollow noreferrer">https://github.com/code4craft/webmagic</a></strong></p><h3 id="21-StormCrawler"><a class="header-anchor" href="#21-StormCrawler">※</a><strong>21. StormCrawler</strong></h3><ul><li><strong>实现语言</strong>： Java</li><li><strong>GitHub Star 数</strong>：437</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic4.zhimg.com/v2-4f40d9113c161884a19fd41756e93507_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>StormCrawler 是一种基于 Apache Storm 构架分布式 Web 爬虫的开源 SDK。</li><li>StormCrawler 为开发人员构建爬虫提供了软件库和一系列资源。</li><li>StormCrawler 完全适用于以数据流提供需获取和解析的 URL 的情况，也非常适用于大规模递归性爬取，尤其是需要低延迟的情况。</li></ul><p><strong>特性</strong>：</p><ul><li>可扩展。</li><li>有弹性。</li><li>低延迟。</li><li>易于扩展。</li><li>运行良好且高效。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//stormcrawler.net/docs/api/" rel="external nofollow noreferrer">http://stormcrawler.net/docs/api/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//stormcrawler.net/" rel="external nofollow noreferrer">http://stormcrawler.net/</a></strong></p><h2 id="JavaScript-编写的开源-Web-爬虫"><a class="header-anchor" href="#JavaScript-编写的开源-Web-爬虫">※</a><strong>JavaScript 编写的开源 Web 爬虫</strong></h2><h3 id="22-NodeCrawler"><a class="header-anchor" href="#22-NodeCrawler">※</a><strong>22. NodeCrawler</strong></h3><ul><li><strong>实现语言</strong>： JavaScript</li><li><strong>GitHub Star 数</strong>： 3999</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic3.zhimg.com/v2-ddebe1bae52d5b0f56687f79d6bcfbf2_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>NodeCrawler 是一种广为使用的 Web 爬虫，它基于 NodeJS 实现，具有非常快的爬取速度。</li><li>Nodecrawler 非常适用于偏爱使用 JavaScript 编程或者致力于 JavaScript 项目的开发人员。其安装也非常简单。</li><li>JSDOM 和 Cheerio（用于 HTML 解析）实现服务器端渲染。其中，JSDOM 更为稳定。</li></ul><p><strong>特性</strong>：</p><ul><li>使用 Cheerio（默认）或 JSDOM 实现服务端 DOM 和自动 jQuery 插入。</li><li>可配置池子规模和重试次数。</li><li>控制爬取率限制。</li><li>请求的优先队列。</li><li>支持 forceUTF8 模式，使得爬虫可以检测并转换字符集。</li><li>与 4.x 乃至更新版本兼容。</li></ul><p>– <strong>官方文档</strong>：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/bda-research/node-crawler" rel="external nofollow noreferrer">https://github.com/bda-research/node-crawler</a></strong></p><p>– <strong>官方网站</strong>：<strong><a href="https://link.zhihu.com/?target=http%3A//nodecrawler.org/" rel="external nofollow noreferrer">http://nodecrawler.org/</a></strong></p><h3 id="23-Simplecrawler"><a class="header-anchor" href="#23-Simplecrawler">※</a><strong>23. Simplecrawler</strong></h3><ul><li><strong>实现语言</strong>： JavaScript</li><li><strong>GitHub Star 数</strong>：1764</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Simplecrawler 设计提供基本的、灵活且稳定的网站爬取 API。</li><li>Simplecrawler 在实现上考虑了针对特大型 Web 站点的归档、分析和搜索。它可爬取上百万页面，并毫无问题地向磁盘写入数十 GB 数据。</li></ul><p><strong>特性</strong>：</p><ul><li>提供了用于自动检测链接资源的一些简单逻辑，用户可自行替换和添加。</li><li>自动请求任何 robots.txt 禁止规则。</li><li>具有灵活的队列系统，可在磁盘上冻结和解冻。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/simplecrawler/simplecrawler" rel="external nofollow noreferrer">https://github.com/simplecrawler/simplecrawler</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.npmjs.com/package/simplecrawler" rel="external nofollow noreferrer">https://www.npmjs.com/package/simplecrawler</a></strong></p><h3 id="24-Js-crawler"><a class="header-anchor" href="#24-Js-crawler">※</a><strong>24. Js-crawler :</strong></h3><ul><li><strong>实现语言</strong>： JavaScript</li><li><strong>GitHub Star 数</strong>： 167</li><li><strong>官方支持链接)</strong></li></ul><p><strong>简介</strong>：</p><ul><li>使用 NodeJS 实现的 Web 爬虫，支持 HTTP 和 HTTPS</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/antivanov/js-crawler" rel="external nofollow noreferrer">https://github.com/antivanov/js-crawler</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/antivanov/js-crawler" rel="external nofollow noreferrer">https://github.com/antivanov/js-crawler</a></strong></p><h3 id="25-Webster"><a class="header-anchor" href="#25-Webster">※</a><strong>25. Webster</strong></h3><ul><li><strong>实现语言</strong>： JavaScript</li><li><strong>GitHub Star 数</strong>： 201</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Webster 是一种使用 NodeJS 编写的可靠 Web 爬取和采集框架，用于爬取 Web 站点并从页面中抽取结构化数据。</li><li>与其他爬取框架的不同之处在于，Webster 可以抓取浏览器客户端的 JavaScript 和 Ajax 请求呈现的内容。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//webster.zhuyingda.com/" rel="external nofollow noreferrer">http://webster.zhuyingda.com/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/zhuyingda/webster" rel="external nofollow noreferrer">https://github.com/zhuyingda/webster</a></strong></p><h3 id="26-Node-osmosis"><a class="header-anchor" href="#26-Node-osmosis">※</a><strong>26. Node-osmosis</strong></h3><ul><li><strong>实现语言</strong>：JavaScript</li><li><strong>GitHub Star 数</strong>： 3630</li><li>**<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/rchipka/node-osmosis/issues" rel="external nofollow noreferrer">官方支持链接</a></strong></li></ul><p><strong>简介</strong>：</p><p>* 一种使用 NodeJS 实现的 HTML/XML 解析器和 Web 爬虫。</p><p><strong>特性</strong>：</p><ul><li>使用原生 libxml 的 C 绑定。</li><li>干净的 Promise 类接口。</li><li>支持 CSS 3.0 和 XPath 1.0 选择器的混合。</li><li><strong><a href="https://link.zhihu.com/?target=https%3A//github.com/jquery/sizzle/wiki%23other-selectors-and-conventions" rel="external nofollow noreferrer">Sizzle 选择器</a></strong>、<strong><a href="https://link.zhihu.com/?target=http%3A//mootools.net/core/docs/1.6.0/Slick/Slick" rel="external nofollow noreferrer">Slick 选择器</a><strong>以及</strong><a href="https://link.zhihu.com/?target=https%3A//github.com/rchipka/node-osmosis/blob/master/docs/Selectors.md" rel="external nofollow noreferrer">更多</a></strong>。</li><li>不具有像 jQuery、cheerio 或 jsdom 那样的大型依赖。</li><li>构成深度和复杂的数据结构。</li><li>HTML 解析器特性：</li><li>快速解析；</li><li>高速搜索；</li><li>内存占用小。</li><li>HTML DOM 特性：</li><li>加载和搜索 ajax 内容；</li><li>DOM 交互和事件；</li><li>执行嵌入和远程脚本；</li><li>在 DOM 中执行代码。</li><li>HTTP 请求特性：</li><li>日志记录 URL，重定向和错误；</li><li>Cookie 的 jar 包，以及自定义 Cookie/头部/用户代理；</li><li>登录/表单提交、会话 Cookie，基本的认证；</li><li>单代理、多代理，处理代理失败情况；</li><li>限制重试和重定向。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//rchipka.github.io/node-osmosis/global.html" rel="external nofollow noreferrer">https://rchipka.github.io/node-osmosis/global.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.npmjs.com/package/osmosis" rel="external nofollow noreferrer">https://www.npmjs.com/package/osmosis</a></strong></p><h3 id="27-Supercrawler"><a class="header-anchor" href="#27-Supercrawler">※</a><strong>27. Supercrawler</strong></h3><ul><li><strong>实现语言</strong>：JavaScript</li><li><strong>GitHub Star 数</strong>： 4341</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Supercrawler 是一种使用 NodeJS 实现的 Web 爬虫，在设计上支持高度可配置和易用性。</li><li>一旦成功爬取一个网页（可以是图像、文本文档或其他任何文件），Supercrawler 将会触发用户自定义的内容类型（content-type）处理器，处理页面解析、保存数据以及其它一些用户定义的功能。</li></ul><p><strong>特性</strong>：</p><ul><li>链接检测：Supercrawler 会解析所爬取的 HTML 文档，识别其中链接并添加到队列中。</li><li>机器人解析：在爬取前 Supercrawler 会请求 robots.txt 并检查其中的禁止规则。它也可识别站点地图。</li><li>站点地图解析：Supercrawler 可以从 XML 站点地图文件中读取链接，并将链接添加到队列中。</li><li>并发限制：Supercrawler 可限制在任一时间发出的请求数。</li><li>速率限制：Supercrawler 可添加请求的时延，以免对服务器产生轰炸。</li><li>指数补偿（Exponential backoff）重试：Supercrawler 将依此在一小时、两小时、四小时乃至更多时间后重试请求。要使用该特性，爬取队列必须使用数据库或 Redis 作为后端。</li><li>主机名均衡：Supercrawler 可在不同主机名间平均分割请求量。要使用该特性，爬取队列必须以 Redis 为后端。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/brendonboshell/supercrawler" rel="external nofollow noreferrer">https://github.com/brendonboshell/supercrawler</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/brendonboshell/supercrawler" rel="external nofollow noreferrer">https://github.com/brendonboshell/supercrawler</a></strong></p><h3 id="28-Web-scraper-的-Chrome-扩展"><a class="header-anchor" href="#28-Web-scraper-的-Chrome-扩展">※</a><strong>28. Web scraper 的 Chrome 扩展</strong></h3><ul><li><strong>实现语言</strong>：JavaScript</li><li><strong>GitHub Star 数</strong>： 775</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Web Scraper 是一种 Chrome 浏览器扩展，构建用于从 Web 页面抽取数据。</li><li>用户可以使用该扩展创建计划（站点地图），定义如何遍历一个 Web 网站，以及如何从中抽取数据。</li><li>Web Scraper 使用站点地图相应地遍历网站，并从中抽取数据。</li><li>支持以 CSV 格式导出所抽取的数据。</li></ul><p><strong>特性</strong>：</p><ul><li>抽取多个页面。</li><li>站点地图和抽取的数据存储在浏览器的本地存储，也可存储在 CouchDB 中。</li><li>多种数据类型选取。</li><li>支持从动态网页（JavaScript+AJAX）抽取数据。</li><li>浏览抽取的数据。</li><li>以 CSV 格式导出抽取的数据。</li><li>导入、导出站点地图。</li><li>只依赖于 Chrome 浏览器。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.webscraper.io/documentation" rel="external nofollow noreferrer">https://www.webscraper.io/documentation</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.webscraper.io/" rel="external nofollow noreferrer">https://www.webscraper.io</a></strong></p><h3 id="29-Headless-Chrome-爬虫"><a class="header-anchor" href="#29-Headless-Chrome-爬虫">※</a><strong>29. Headless Chrome 爬虫</strong></h3><ul><li><strong>实现语言</strong>：JavaScript</li><li><strong>GitHub Star 数</strong>： 3256</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic2.zhimg.com/v2-59980cb14aeb8114d240a806a8a5caf5_r.jpg" alt=""></p><p><strong>简介</strong>：</p><ul><li>使用基本 HTML 文件请求的爬虫，通常速度很快。但这样的爬虫往往会抽取到空白内容，尤其是在爬取使用 AngularJS、React 和 Vue.js 等现代前端框架构建的网站时。</li></ul><p><strong>特性</strong>：</p><ul><li>分布式爬取。</li><li>可配置并发、延迟和重试。</li><li>支持深度优先搜索和广度优先搜索算法。</li><li>支持插拔缓存存储，例如 Redis。</li><li>支持导出 CSV 和 JSON。</li><li>在达到最大请求时暂停爬取，并可在任一时刻恢复。</li><li>自动插入用于抽取的 jQuery。</li><li>保存屏幕截图，用于证实爬取过程。</li><li>模拟设备和用户代理。</li><li>具有优先队列，可提高爬取效率。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/yujiosaka/headless-chrome-crawler/blob/master/docs/API.md" rel="external nofollow noreferrer">https://github.com/yujiosaka/headless-chrome-crawler/blob/master/docs/API.md</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/yujiosaka/headless-chrome-crawler" rel="external nofollow noreferrer">https://github.com/yujiosaka/headless-chrome-crawler</a></strong></p><h3 id="30-X-ray"><a class="header-anchor" href="#30-X-ray">※</a><strong>30. X-ray</strong></h3><ul><li><strong>实现语言</strong>：JavaScript</li><li><strong>GitHub Star 数</strong>： 4464</li><li><strong>官方支持链接</strong></li></ul><p><img src="https://pic3.zhimg.com/v2-898fd51a134e7ea31554fca0ff89bfda_r.jpg" alt=""></p><p><strong>特性</strong>：</p><ul><li>模式灵活：支持字符串、数组、对象以及嵌套对象结构。模式并非绑定于所抽取的页面结构，支持用户获取选定结构中的数据。</li><li>可组合（Composable）：API 是完全可组合的，赋予用户抽取每个页面的极大灵活性。</li><li>分页支持：爬取页面在 Web 站点上的所有分页。X-ray 还支持请求延迟和分页限制，并支持将爬取页面导入到单个文件中。这样一旦单个页面产生错误，用户不会失去所有已爬取的数据。</li><li>爬虫支持：从一个页面开始，轻易跳转另一个页面。页面跳转是可预测的，按深度优先爬取所有页面。</li><li>负责任的爬取：X-ray 支持并发、限制、延迟、超时和限制，实现负责任地爬取任何页面。</li><li>可插拔驱动：可按用户需求置换不同的爬虫。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/matthewmueller/x-ray" rel="external nofollow noreferrer">https://github.com/matthewmueller/x-ray</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.npmjs.com/package/x-ray-scraper" rel="external nofollow noreferrer">https://www.npmjs.com/package/x-ray-scraper</a></strong></p><h2 id="C-编写的开源-Web-爬虫"><a class="header-anchor" href="#C-编写的开源-Web-爬虫">※</a><strong>C 编写的开源 Web 爬虫</strong></h2><h3 id="31-Httrack"><a class="header-anchor" href="#31-Httrack">※</a><strong>31. Httrack</strong></h3><ul><li><strong>实现语言</strong>：C</li><li><strong>GitHub Star 数</strong>： 747</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="383" height="33"></svg>)</p><p><strong>简介</strong>：</p><ul><li>HTTracks 是一项免费（GPL、Libre/自由软件）且易于使用的离线浏览器功能。</li><li>支持用户将 Web 站点下载到本地目录，递归构建全部目录，以及获取 HTML、图像和其它文件到本地计算机。</li><li>HTTrack 会维持原站点的相对链接结构。用户可以用浏览器打开本地的“镜像”页面，并逐个链接浏览，与在线浏览无异。</li><li>HTTrack 也支持对已有镜像站点的更新，以及从中断点恢复下载。</li><li>HTTrack 高度可配置，并提供帮助文档。</li></ul><p><strong>特性</strong>：</p><ul><li>多语言窗口，提供对 Linux/UNIX 的接口。</li><li>镜像单个站点，或是一并镜像多个站点。</li><li>支持按文件类型、链接位置、结构深度、文件大小过滤，接受或拒绝站点或文件名。</li><li>支持代理，可最大化速度，并可选认证。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.httrack.com/html/index.html" rel="external nofollow noreferrer">http://www.httrack.com/html/index.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.httrack.com/" rel="external nofollow noreferrer">http://www.httrack.com/</a></strong></p><h3 id="32-GNU-Wget"><a class="header-anchor" href="#32-GNU-Wget">※</a><strong>32. GNU Wget</strong></h3><ul><li><strong>实现语言</strong>：C</li><li><strong>GitHub Star 数</strong>： 22</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="139" height="136"></svg>)</p><p><strong>简介</strong>：</p><ul><li>GNU Wget 是一种免费软件包，它使用 HTTP、HTTPS、FTP、FTPS 等广为使用的互联网协议检索文件。</li><li>Wget 是一种非交互式命令行工具，易于从脚本、Cron 任务、不具有 X 窗口支持的终端等处调用。</li></ul><p><strong>特性</strong>：</p><ul><li>使用 REST 和 RANGE 支持从中断处恢复下载。</li><li>基于 NLS 的消息文件，可使用多种语言。</li><li>可运行于大多数类 UNIX 操作系统上，也支持 Windows.</li><li>支持 HTTP 代理。</li><li>支持 HTTP Cookie。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.gnu.org/software/wget/manual/" rel="external nofollow noreferrer">https://www.gnu.org/software/wget/manual/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//www.gnu.org/software/wget/" rel="external nofollow noreferrer">https://www.gnu.org/software/wget/</a></strong></p><h2 id="C-编写的开源-Web-爬虫-v2"><a class="header-anchor" href="#C-编写的开源-Web-爬虫-v2">※</a><strong>C++编写的开源 Web 爬虫</strong></h2><h3 id="33-gigablast"><a class="header-anchor" href="#33-gigablast">※</a><strong>33. gigablast</strong></h3><ul><li><strong>实现语言</strong>：C++</li><li><strong>GitHub Star 数</strong>： 912</li><li>**<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/gigablast/open-source-search-engine/issues" rel="external nofollow noreferrer">官方支持链接</a></strong></li></ul><p><strong>简介</strong>：</p><ul><li>Gigablast 是一种开源的 Web 和企业搜索引擎，也是一种爬虫。</li><li>Gigablast 是自身维护数十亿页面检索索引的数家美国搜索引擎之一。</li></ul><p><strong>特性</strong>：</p><ul><li>大规模。</li><li>高性能。</li><li>实时信息检索技术。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.gigablast.com/api.html" rel="external nofollow noreferrer">http://www.gigablast.com/api.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//www.gigablast.com/" rel="external nofollow noreferrer">http://www.gigablast.com/</a></strong></p><h2 id="C-编写的开源-Web-爬虫-v3"><a class="header-anchor" href="#C-编写的开源-Web-爬虫-v3">※</a><strong>C#编写的开源 Web 爬虫</strong></h2><h3 id="34-http-Arachnode-net"><a class="header-anchor" href="#34-http-Arachnode-net">※</a><strong>34. <a href="https://link.zhihu.com/?target=http%3A//Arachnode.net" rel="external nofollow noreferrer">http://Arachnode.net</a></strong></h3><ul><li><strong>实现语言</strong>：C#</li><li><strong>GitHub Star 数</strong>： 9</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//Arachnode.net" rel="external nofollow noreferrer">http://Arachnode.net</a> 适用于寻求开源 Web 爬虫的 C#开发人员。</li><li><a href="https://link.zhihu.com/?target=http%3A//Arachnode.net" rel="external nofollow noreferrer">http://Arachnode.net</a> 软件类库从因特网下载内容、对内容做索引，并对过程做定制。</li><li>用户可使用该工具做个人内容聚合，也可用于将下载的内容抽取、采集和解析为多个表单。</li><li><a href="https://link.zhihu.com/?target=http%3A//Arachnode.net" rel="external nofollow noreferrer">http://Arachnode.net</a> 索引所发现的内容，并存储在 <a href="https://link.zhihu.com/?target=http%3A//Lucene.NET" rel="external nofollow noreferrer">http://Lucene.NET</a> 索引中。</li><li><a href="https://link.zhihu.com/?target=http%3A//Arachnode.net" rel="external nofollow noreferrer">http://Arachnode.net</a> 非常适用于文本挖掘，也适用于学习高级爬取技术。</li></ul><p><strong>特性</strong>：</p><ul><li>可配置规则和行为。</li><li>集成 <a href="https://link.zhihu.com/?target=http%3A//Lucene.NET" rel="external nofollow noreferrer">http://Lucene.NET</a>。</li><li>支持 SQL Server 和全文本索引。</li><li>支持对.DOC/.PDF/.PPT/.XLS 等文件类型的索引。</li><li>支持将 HTML 转化为 XML 和 XHTML。</li><li>支持全部 JavaScript/AJAX 功能。</li><li>支持多线程和节流(Throttling)。</li><li>行为适当（Respectful）的爬取。</li><li>分析服务。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//documentation.arachnode.net/index.html" rel="external nofollow noreferrer">https://documentation.arachnode.net/index.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//arachnode.net/" rel="external nofollow noreferrer">http://arachnode.net/</a></strong></p><h3 id="35-Abot"><a class="header-anchor" href="#35-Abot">※</a><strong>35. Abot</strong></h3><ul><li><strong>实现语言</strong>：C#</li><li><strong>GitHub Star 数</strong>： 1392</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Abot 是一种 C#实现的开源 Web 爬虫，主要侧重于速度和灵活性。</li><li>Abot 在实现中考虑了底层技术细节，包括多线程、HTTP 请求、调度、链接解析等。</li><li>用户只需注册事件，就可以处理分页数据。</li><li>支持用户插入自己的核心接口实现，实现对整个爬取过程的完全控制。</li></ul><p><strong>特性</strong>：</p><ul><li>高速！</li><li>易于定制（可插拔架构，支持用户定义爬取内容和方式）。</li><li>经过大量的单元测试（高代码覆盖率）。</li><li>非常轻量级（并非过度工程化）。</li><li>无过程之外的依赖，例如对数据库、所安装服务等的依赖。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/sjdirect/abot" rel="external nofollow noreferrer">https://github.com/sjdirect/abot</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/sjdirect/abot" rel="external nofollow noreferrer">https://github.com/sjdirect/abot</a></strong></p><h3 id="36-Hawk"><a class="header-anchor" href="#36-Hawk">※</a><strong>36. Hawk</strong></h3><ul><li><strong>实现语言</strong>：C#</li><li><strong>GitHub Star 数</strong>： 1875</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>HAWK 无需用户做任何编程，提供图形可视化数据获取和清理工具，并以 GPL 协议开源。</li></ul><p><strong>特性</strong>：</p><ul><li>无需编程，即可实现对 Web 内容的智能分析。</li><li>所见即所得（WYSIWYG），可视化拉拽，支持对数据转换和过滤等的快速处理。</li><li>支持从多种数据库和文件中导入和导出。</li><li>任务可保存并可重用。</li><li>尤其适用于爬取和数据清理，但其功能并不仅局限于此。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/ferventdesert/Hawk" rel="external nofollow noreferrer">https://github.com/ferventdesert/Hawk</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//ferventdesert.github.io/Hawk/" rel="external nofollow noreferrer">https://ferventdesert.github.io/Hawk/</a></strong></p><h3 id="37-SkyScraper"><a class="header-anchor" href="#37-SkyScraper">※</a><strong>37. SkyScraper</strong></h3><ul><li><strong>实现语言</strong>：C#</li><li><strong>GitHub Star 数</strong>： 39</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>一种异步 Web 获取和爬虫，使用了 async/await 和响应式扩展。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/JonCanning/SkyScraper" rel="external nofollow noreferrer">https://github.com/JonCanning/SkyScraper</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/JonCanning/SkyScraper" rel="external nofollow noreferrer">https://github.com/JonCanning/SkyScraper</a></strong></p><h2 id="NET-编写的-Web-爬虫"><a class="header-anchor" href="#NET-编写的-Web-爬虫">※</a><strong>.NET 编写的 Web 爬虫</strong></h2><h3 id="38-DotnetSpider"><a class="header-anchor" href="#38-DotnetSpider">※</a><strong>38. DotnetSpider</strong></h3><ul><li><strong>实现语言</strong>：.NET</li><li><strong>GitHub Star 数</strong>： 1382</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>DotnetSpider <a target="_blank" rel="noopener external nofollow noreferrer" href="http://xn--4gq59a111cewn2of.NET">是一种使用.NET</a> Standard 实现的 Web 爬取软件库，类似于 WebMagic 和 Scrapy。</li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://xn--4gq6mt54aiwkvhs2lg935b.NET">它是一种适用于.NET</a> 的轻量级、高效和高速的高层 Web 爬取和获取框架。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/dotnetcore/DotnetSpider/wiki" rel="external nofollow noreferrer">https://github.com/dotnetcore/DotnetSpider/wiki</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/dotnetcore/DotnetSpider" rel="external nofollow noreferrer">https://github.com/dotnetcore/DotnetSpider</a></strong></p><h2 id="PHP-编写的开源-Web-爬虫"><a class="header-anchor" href="#PHP-编写的开源-Web-爬虫">※</a><strong>PHP 编写的开源 Web 爬虫</strong></h2><h3 id="39-Goutte"><a class="header-anchor" href="#39-Goutte">※</a><strong>39. Goutte</strong></h3><ul><li><strong>实现语言</strong>：PHP</li><li><strong>GitHub Star 数</strong>： 6574</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Goutte 是一种 PHP 实现的屏幕抓取和 Web 爬取软件库。</li><li>Goutte 为爬取 Web 站点和从 HTML/XML 响应中抽取数据提供了很好的 API。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//goutte.readthedocs.io/en/latest/" rel="external nofollow noreferrer">https://goutte.readthedocs.io/en/latest/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/FriendsOfPHP/Goutte" rel="external nofollow noreferrer">https://github.com/FriendsOfPHP/Goutte</a></strong></p><h3 id="40-Dom-crawler"><a class="header-anchor" href="#40-Dom-crawler">※</a><strong>40. Dom-crawler</strong></h3><ul><li><strong>实现语言</strong>：PHP</li><li><strong>GitHub Star 数</strong>： 1340</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>DomCrawler 组件简化了对 HTML 和 XML 文档的 DOM 浏览。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//symfony.com/doc/current/components/dom_crawler.html" rel="external nofollow noreferrer">https://symfony.com/doc/current/components/dom_crawler.html</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/symfony/dom-crawler" rel="external nofollow noreferrer">https://github.com/symfony/dom-crawler</a></strong></p><h3 id="41-Pspider"><a class="header-anchor" href="#41-Pspider">※</a><strong>41. Pspider</strong></h3><ul><li><strong>实现语言</strong>：PHP</li><li><strong>GitHub Star 数</strong>： 249</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Pspider 是最近完全使用 PHP 实现的一种并行爬取框架，它基于 hightman/httpclient 组件。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/hightman/pspider" rel="external nofollow noreferrer">https://github.com/hightman/pspider</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/hightman/pspider" rel="external nofollow noreferrer">https://github.com/hightman/pspider</a></strong></p><h3 id="42-Php-spider"><a class="header-anchor" href="#42-Php-spider">※</a><strong>42. Php-spider</strong></h3><ul><li><strong>实现语言</strong>：PHP</li><li><strong>GitHub Star 数</strong>： 1023</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>一种可配置、可扩展的 Web 爬虫。</li></ul><p><strong>特性</strong>：</p><ul><li>可限制爬取深度、队列大小和最大下载数。</li><li>支持基于 XPath、CSS 选择器或普通（Plain old）PHP 添加自定义的 URI 发现逻辑。</li><li>提供了一系列有用的 URI 过滤器，例如域限制等。</li><li>收集爬取统计信息，用于形成报告。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/mvdbos/php-spider" rel="external nofollow noreferrer">https://github.com/mvdbos/php-spider</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/mvdbos/php-spider" rel="external nofollow noreferrer">https://github.com/mvdbos/php-spider</a></strong></p><h3 id="43-Spatie-Crawler"><a class="header-anchor" href="#43-Spatie-Crawler">※</a><strong>43. Spatie / Crawler</strong></h3><ul><li><strong>实现语言</strong>：PHP</li><li><strong>GitHub Star 数</strong>： 740</li><li>**<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/spatie/crawler/issues" rel="external nofollow noreferrer">官方支持链接</a></strong></li></ul><p><strong>简介</strong>：</p><ul><li>该软件包提供了从 Web 站点爬取链接的类。在实现的底层机制上，使用了 GuzzleHttp/Promise 并发爬取多个 URL。</li><li>该爬虫支持执行 JavaScript，可以爬取使用 JavaScript 渲染的站点。从实现的底层机制看，该特性使用了 Chrome 和 Puppeteer。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/spatie/crawler" rel="external nofollow noreferrer">https://github.com/spatie/crawler</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/spatie/crawler" rel="external nofollow noreferrer">https://github.com/spatie/crawler</a></strong></p><h2 id="Ruby-实现的开源-Web-爬虫"><a class="header-anchor" href="#Ruby-实现的开源-Web-爬虫">※</a><strong>Ruby 实现的开源 Web 爬虫</strong></h2><h3 id="44-Mechanize"><a class="header-anchor" href="#44-Mechanize">※</a><strong>44. Mechanize</strong></h3><ul><li><strong>实现语言</strong>：Ruby</li><li><strong>GitHub Star 数</strong>： 3728</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Mechanize 软件库用于实现于 Web 站点的自动交互。</li><li>Mechanize 自动按重定向存储并发送 Cookie。可以根据链接提交表单，支持填写和提交表单域。</li><li>Mechanize 也可跟踪用户访问过站点的历史记录。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//docs.seattlerb.org/mechanize/" rel="external nofollow noreferrer">http://docs.seattlerb.org/mechanize/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/sparklemotion/mechanize" rel="external nofollow noreferrer">https://github.com/sparklemotion/mechanize</a></strong></p><h2 id="GO-编写的开源-Web-爬虫"><a class="header-anchor" href="#GO-编写的开源-Web-爬虫">※</a><strong>GO 编写的开源 Web 爬虫</strong></h2><h3 id="45-Colly"><a class="header-anchor" href="#45-Colly">※</a><strong>45. Colly</strong></h3><ul><li><strong>实现语言</strong>：Go</li><li><strong>GitHub Star 数</strong>： 5439</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="381" height="199"></svg>)</p><p><strong>简介</strong>：</p><ul><li>为 Go 爱好者提供了一种快速且适用的爬取框架。</li><li>Colly 提供了非常清晰的接口，可用于编写任何类型的爬虫和数据获取工具。</li><li>Colly 使得用户可以轻易地从站点抽取结构化数据。这些数据适用于大范围的应用，例如数据挖掘、数据处理和归档。</li></ul><p><strong>特性</strong>：</p><ul><li>清晰的 API。</li><li>高速（支持单核每秒处理一千次以上的请求）。</li><li>按域管理请求延迟和最大并发。</li><li>自动 Cookie 和会话管理。</li><li>同步/异步/并行爬取。</li><li>支持缓存。</li><li>对非 unicode 响应的自动编码。</li><li>支持 robots.txt 禁止规则。</li><li>分布式爬取。</li><li>可通过环境变量配置。</li><li>支持扩展。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//go-colly.org/docs/" rel="external nofollow noreferrer">http://go-colly.org/docs/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//go-colly.org/" rel="external nofollow noreferrer">http://go-colly.org/</a></strong></p><h3 id="46-Gopa"><a class="header-anchor" href="#46-Gopa">※</a><strong>46. Gopa</strong></h3><ul><li><strong>实现语言</strong>：Go</li><li><strong>GitHub Star 数</strong>： 169</li><li><strong>官方支持链接</strong></li></ul><p><strong>特性</strong>：</p><ul><li>轻量级，低资源占用，小于 100MB 的内存需求。</li><li>易于部署，无需任何运行时和依赖关系。</li><li>易于使用，不需要用户具有任何编程和脚本技能，提供开箱即可用特性。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/infinitbyte/gopa" rel="external nofollow noreferrer">https://github.com/infinitbyte/gopa</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/infinitbyte/gopa" rel="external nofollow noreferrer">https://github.com/infinitbyte/gopa</a></strong></p><h3 id="47-Pholcus"><a class="header-anchor" href="#47-Pholcus">※</a><strong>47. Pholcus</strong></h3><ul><li><strong>实现语言</strong>：Go</li><li><strong>GitHub Star 数</strong>： 4341</li><li><strong>官方支持链接</strong></li></ul><p>![](data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="92" height="92"></svg>)</p><p><strong>简介</strong>：</p><ul><li>Pholcus 是一种完全使用 Go 语言实现的高并发性、重量级爬虫软件。</li><li>它针对因特网数据采集，为只具有基本 Go 或 JavaScript 编程基础的用户提供了一种只需要关注自定义功能的特性。</li><li>规则简单灵活，并发批处理任务，提供丰富的输出方式，包括 MySQL、MongoDB、Kafka、CSV、Exvel 等。</li><li>用户共享了大量的演示。此外，Pholcus 支持两种水平和垂直爬取模式，支持模拟登陆、暂停任务、取消任务等一系列高级特性。</li></ul><p><strong>特性</strong>：</p><ul><li>一种强大的爬取工具。</li><li>支持三种运行模式：单机、服务器和客户。</li><li>提供三种操作接口：Web、GUI 和命令行。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//pholcus.gitbooks.io/docs/" rel="external nofollow noreferrer">https://pholcus.gitbooks.io/docs/</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/henrylee2cn/pholcus" rel="external nofollow noreferrer">https://github.com/henrylee2cn/pholcus</a></strong></p><h2 id="R-编写的开源-Web-爬虫"><a class="header-anchor" href="#R-编写的开源-Web-爬虫">※</a><strong>R 编写的开源 Web 爬虫</strong></h2><h3 id="48-Rvest"><a class="header-anchor" href="#48-Rvest">※</a><strong>48. Rvest</strong></h3><ul><li><strong>实现语言</strong>：R</li><li><strong>GitHub Star 数</strong>： 969</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Rvest 为用户从 Web 页面抽取信息提供帮助。它在设计上使用了 magrittr 软件包，易于表达通用 Web 抽取。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//cran.r-project.org/web/packages/rvest/rvest.pdf" rel="external nofollow noreferrer">https://cran.r-project.org/web/packages/rvest/rvest.pdf</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/hadley/rvest" rel="external nofollow noreferrer">https://github.com/hadley/rvest</a></strong></p><h2 id="Scala-编写的开源-Web-爬虫"><a class="header-anchor" href="#Scala-编写的开源-Web-爬虫">※</a><strong>Scala 编写的开源 Web 爬虫</strong></h2><h3 id="49-Sparkler"><a class="header-anchor" href="#49-Sparkler">※</a><strong>49. Sparkler</strong></h3><ul><li><strong>实现语言</strong>： Scala</li><li><strong>GitHub Star 数</strong>： 198</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Web 爬虫是一种机器人程序，它从 Web 网站采集资源，用于构建搜索引擎、知识库等应用。</li><li>Sparkler（“Spark-Crawler”的缩写）是一种新型的 Web 爬虫，它通过整合 Spark、Kafka、Lucene/Solr、Tika、pf4j 等多种 Apache 项目，使用了分布式计算和信息检索领域的最新进展。</li></ul><p><strong>特性</strong>：</p><ul><li>提供更高的性能，具有更好的容错。</li><li>支持复杂和近实时分析。</li><li>实时输出数据流。</li><li>可扩展的插件框架。</li><li>通用解析器。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//irds.usc.edu/sparkler/dev/development-environment-setup.html%23contributing-source" rel="external nofollow noreferrer">http://irds.usc.edu/sparkler/dev/development-environment-setup.html#contributing-source</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=http%3A//irds.usc.edu/sparkler/" rel="external nofollow noreferrer">http://irds.usc.edu/sparkler/</a></strong></p><h2 id="Perl-编写的开源-Web-爬虫"><a class="header-anchor" href="#Perl-编写的开源-Web-爬虫">※</a><strong>Perl 编写的开源 Web 爬虫</strong></h2><h3 id="50-Web-scraper"><a class="header-anchor" href="#50-Web-scraper">※</a><strong>50. Web-scraper</strong></h3><ul><li><strong>实现语言</strong>：Perl</li><li><strong>GitHub Star 数</strong>： 91</li><li><strong>官方支持链接</strong></li></ul><p><strong>简介</strong>：</p><ul><li>Web Scraper 是一种使用 HTML、CSS 选择器或 XPath 表达式的 Web 采集工具集。</li></ul><p>– <strong>官方文档</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/miyagawa/web-scraper" rel="external nofollow noreferrer">https://github.com/miyagawa/web-scraper</a></strong></p><p>– <strong>官方网站</strong>： <strong><a href="https://link.zhihu.com/?target=https%3A//github.com/miyagawa/web-scraper" rel="external nofollow noreferrer">https://github.com/miyagawa/web-scraper</a></strong></p><h2 id="小结"><a class="header-anchor" href="#小结">※</a><strong>小结</strong></h2><p>以上罗列了 50 个不同编程语言下的不错爬虫框架/项目，感兴趣可以用用看。</p><p><strong>英文原文：</strong> <strong><a href="https://link.zhihu.com/?target=http%3A//www.prowebscraper.com/blog/50-best-open-source-web-crawlers/" rel="external nofollow noreferrer">http://www.prowebscraper.com/blog/50-best-open-source-web-crawlers/</a></strong></p><p>本文转自 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/64305013">https://zhuanlan.zhihu.com/p/64305013</a>，如有侵权，请联系删除。</p></section><section class="References"><span id="References">References</span> <span id="References-content"></span></section><section class="post-footer"><hr id="footerline"><br><section class="author">*Corresponding Author: Yao Qing-sheng &lt;Email: <a href="mailto:350788415@qq.com" rel="external nofollow noreferrer" title="350788415@qq.com">350788415@qq.com</a>&gt; BY-NC-SA .</section><br><ol id="list"><li>Yao Qing-sheng&period;50种最棒的开源爬虫框架/项目&period;FUTURE & CIVILIZATION&period;Natural/Social Philosophy & Infomation Sciences&comma;20220609&period;https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/</li><li>版权声明：本文为「LordYao」的原创文章，遵循 CC 4.0 BY-NC-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接： https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/</li></ol></section><script>jQuery(document).on("copy",function(e){var t=window.getSelection(),n=t.toString().replace(/\n/g,"<br>"),o="<br>---------------------<br>著作权归作者所有。<br>商业转载请联系作者获得授权，非商业转载请注明出处。<br><br>作者："+document.getElementById("author").innerText+"<br>复制时间: "+Date.now()+"<br>原文链接："+document.location.href+"<br>© 版权声明：本文为「"+document.getElementById("author").innerText+"」的原创文章，遵循 CC 4.0 BY-NC-SA 版权协议，转载请附上原文出处链接及本声明。",r=$("<div>",{id:"temp",html:n+o,style:{position:"absolute",left:"-99999px"}});$("body").append(r),t.selectAllChildren(r[0]),window.setTimeout(function(){r.remove()},0)})</script></section><div style="font-size:12px;BORDER-BOTTOM:#bbb 1px solid;BORDER-LEFT:#bbb 1px solid;BACKGROUND:#f6f6f6;MIN-HEIGHT:120px;BORDER-TOP:#bbb 1px solid;BORDER-RIGHT:#bbb 1px solid;MARGIN-TOP:30px;MARGIN-BOTTOM:10px"><div style="MARGIN-TOP:10px;FLOAT:left;MARGIN-LEFT:10px;MARGIN-RIGHT:10px"><img alt="author:Yao Qing-sheng" src="/images/avatar_sx_lite.png" width="100" height="100"></div><div style="LINE-HEIGHT:200%;MARGIN:10px;COLOR:#000">Author: <a href="https://yaoqs.github.io/">Yao Qing-sheng</a> &nbsp;&nbsp;&nbsp;&nbsp; Blog: <a href="https://yaoqs.github.io/">https://yaoqs.github.io/</a>&nbsp;&nbsp;&nbsp;&nbsp; Email: <a href="mailto:350788415@qq.com" rel="external nofollow noopener noreferrer" target="_blank">350788415@qq.com</a><br>Address:Department of Natural/Social Philosophy & Infomation Sciences, CHINA<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/yaoqs#biography">Biography...</a></div></div><style>.article-licensing{position:relative;z-index:0;box-shadow:none;background:#f5f5f5;border-radius:4px;overflow:hidden}.article-licensing p{margin-top:0;margin-bottom:0;font-size:.8em}.article-licensing:after{position:absolute;z-index:-1;right:50px;top:30.9px;content:'\f25e';font-size:200px;font-family:'Font Awesome 5 Brands';opacity:.1}.article-licensing .level-left{flex-wrap:wrap;max-width:100%}.article-licensing .licensing-title{line-height:1.2em;margin-left:10px}.article-licensing .licensing-meta{margin-left:10px}.article-licensing .licensing-meta .icon{vertical-align:bottom}.article-licensing .licensing-meta a{color:inherit}.level{align-items:center;justify-content:space-between}.level code{border-radius:4px}.level img{display:inline-block;vertical-align:top}.level.is-mobile{display:flex}.level.is-mobile .level-left,.level.is-mobile .level-right{display:flex}.level.is-mobile .level-left+.level-right{margin-top:0}.level.is-mobile .level-item:not(:last-child){margin-bottom:0;margin-right:.75rem}.level.is-mobile .level-item:not(.is-narrow){flex-grow:1}@media screen and (min-width:769px),print{.level{display:flex}.level>.level-item:not(.is-narrow){flex-grow:1}}.level-item{align-items:center;display:flex;flex-basis:auto;flex-grow:0;flex-shrink:0;justify-content:center}.level-item .subtitle,.level-item .title{margin-bottom:0}@media screen and (max-width:768px){.level-item:not(:last-child){margin-bottom:.75rem}}.level-left,.level-right{flex-basis:auto;flex-grow:0;flex-shrink:0}.level-left .level-item.is-flexible,.level-right .level-item.is-flexible{flex-grow:1}@media screen and (min-width:769px),print{.level-left .level-item:not(:last-child),.level-right .level-item:not(:last-child){margin-right:.75rem}}.level-left{align-items:center;justify-content:flex-start}@media screen and (max-width:768px){.level-left+.level-right{margin-top:1.5rem}}@media screen and (min-width:769px),print{.level-left{display:flex}}.level-right{align-items:center;justify-content:flex-end}@media screen and (min-width:769px),print{.level-right{display:flex}}</style><div class="article-licensing box"><div class="licensing-title"><a href="https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/">50种最棒的开源爬虫框架/项目</a></div><div class="licensing-title"><p><a href="https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/">https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><p>Author</p><p>Yao Qing-sheng</p></div></div><div class="level-item is-narrow"><div><p>Posted on</p><p>2022-06-09</p></div></div><div class="level-item is-narrow"><div><p>Updated on</p><p>2025-01-14</p></div></div><div class="level-item is-narrow"><div><p>Licensed under</p><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a> <a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a> <a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div><div class="licensing-title"><p>转载或引用本文时请遵守许可协议，注明出处、不得用于商业用途！</p></div></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js" integrity="sha256-fGPu+icKh985TLPhO2v68U7i0CW0dE4kiR06RN4O6jo=" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css" integrity="sha256-0EDwznjUTDEicOuZhOL03fpflUqzhkByvhwol8YGkp4=" crossorigin="anonymous"><div class="social-share share-component"></div><style>.card{background-color:#fff;box-shadow:0 4px 10px rgba(0,0,0,.05),0 0 1px rgba(0,0,0,.1);color:#4a4a4a;max-width:100%;position:relative;transition:opacity .3s ease-out,transform .3s ease-out;opacity:1;transform-origin:center top 0}.card-header{background-color:transparent;align-items:stretch;box-shadow:0 .125em .25em rgba(10,10,10,.1);display:flex}.card-header-title{align-items:center;color:#363636;display:flex;flex-grow:1;font-weight:700;padding:.75rem 1rem}.card-header-title.is-centered{justify-content:center}.card-header-icon{align-items:center;cursor:pointer;display:flex;justify-content:center;padding:.75rem 1rem}.card-image{display:block;position:relative}.card-content{background-color:transparent;padding:1.5em;font-size:1.2em}.buttons.is-centered{justify-content:center;display:flex;font-size:.8em}.card-footer{background-color:transparent;border-top:1px solid #ededed;align-items:stretch;display:flex}.card-footer-item{align-items:center;display:flex;flex-basis:0;flex-grow:1;flex-shrink:0;justify-content:center;padding:.75rem}.card-footer-item:not(:last-child){border-right:1px solid #ededed}.card .media:not(:last-child){margin-bottom:.75rem}.donate{position:relative;padding:10px 10px 10px 10px;margin-left:1em;border-radius:.5em}.donate .qrcode{display:none;position:absolute;z-index:99;bottom:2.5em;line-height:0;overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.05),0 0 1px rgba(0,0,0,.1);border-radius:4px}.donate .qrcode img{max-width:280px}.donate:hover .qrcode{display:block}.donate:first-child:not(:last-child) .qrcode{left:-.75rem}.donate:last-child:not(:first-child) .qrcode{right:-.75rem}.donate[data-type=alipay]{color:#fff;background-color:#00a0e8;border-color:transparent}.donate[data-type=alipay]:active{background-color:#008ecf}.donate[data-type=alipay]:hover{background-color:#0097db}.donate[data-type=alipay]:focus:not(:active){box-shadow:0 0 0 .125em rgba(0,160,232,.25)}.donate[data-type=buymeacoffee]{color:rgba(0,0,0,.7);background-color:#fd0;border-color:transparent}.donate[data-type=buymeacoffee]:active{background-color:#e6c700}.donate[data-type=buymeacoffee]:hover{background-color:#f2d200}.donate[data-type=buymeacoffee]:focus:not(:active){box-shadow:0 0 0 .125em rgba(255,221,0,.25)}.donate[data-type=paypal]{color:rgba(0,0,0,.7);background-color:#feb700;border-color:transparent}.donate[data-type=paypal]:active{background-color:#e5a500}.donate[data-type=paypal]:hover{background-color:#f1ae00}.donate[data-type=paypal]:focus:not(:active){box-shadow:0 0 0 .125em rgba(254,183,0,.25)}.donate[data-type=patreon]{color:#fff;background-color:#ff424d;border-color:transparent}.donate[data-type=patreon]:active{background-color:#ff2835}.donate[data-type=patreon]:hover{background-color:#ff3541}.donate[data-type=patreon]:focus:not(:active){box-shadow:0 0 0 .125em rgba(255,66,77,.25)}.donate[data-type=wechat]{color:#fff;background-color:#1aad19;border-color:transparent}.donate[data-type=wechat]:active{background-color:#179716}.donate[data-type=wechat]:hover{background-color:#18a217}.donate[data-type=wechat]:focus:not(:active){box-shadow:0 0 0 .125em rgba(26,173,25,.25)}.donate[data-type="GitHub Sponsor"]{color:#fff;background-color:#000;border-color:transparent}.donate[data-type="GitHub Sponsor"]:active{background-color:#000}.donate[data-type="GitHub Sponsor"]:hover{background-color:#000}.donate[data-type="GitHub Sponsor"]:focus:not(:active){box-shadow:0 0 0 .125em rgba(0,160,232,.25)}</style><div class="card"><div class="card-content"><p>Like this article? Support the author with</p><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i> </span><span>Alipay</span> <span class="qrcode"><img width="200px" src="/images/支付宝收款码.jpg" alt="Alipay"> </span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i> </span><span>Wechat</span> <span class="qrcode"><img src="/images/微信收款码.png" alt="Wechat"> </span></a><a class="button donate" data-type="paypal"><span class="icon is-small"><i class="fab fa-paypal"></i> </span><span>PayPal</span> <span class="qrcode"><img src="/images/paypal.png" alt="PayPal"> </span></a><a class="button donate" data-type="GitHub Sponsor" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/sponsors/yaoqs"><span class="icon is-small"><i class="fab fa-GitHub"></i> </span><span>GitHub Sponsor</span> </a><a class="button donate" data-type="buymeacoffee" target="_blank" rel="noopener external nofollow noreferrer" href="https://buymeacoffee.com/yaoqs"><span class="icon is-small"><i class="fab fa-buymeacoffee"></i> </span><span>Buy Me a Coffee</span></a></div></div></div></article><div id="qrcode"></div><script>$("#qrcode").qrcode({width:173,height:173,text:"https://yaoqs.github.io/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/"})</script><div class="pagination"><a class="newer-posts" href="/20220613/ru-he-zhi-zuo-tou-ming-bei-jing-de-opengl-xuan-ran-shang-xia-wen/">← 如何制作透明背景的OpenGL渲染上下文？ </a><a class="older-posts" href="/20220609/git-zhuan-ti/">git专题 →</a><br></div><a id="toTop" href="#top" title="回顶部">Top</a></main></div></div><script src="https://cdn.jsdelivr.net/gh/yaoqs/donate-plugin/zanzhu_yaoqs.min.js"></script><script>$(function(){new Rewardtip({tiptext:"谢谢支持/Thanks...",tipimg:{img:"/images/ali.gif",width:"50px",height:"50px"},more:"/Donate",tipshow:"<img src='/images/ali.gif'/>",list:[{name:"微信收款码",qrimg:"/images/微信收款码.png"},{name:"微信打赏码",qrimg:"/images/微信打赏码.png"},{name:"支付宝收款码",qrimg:"/images/支付宝收款码.jpg"},{name:"支付宝红包码",qrimg:"/images/支付宝红包码.jpg"}],link:[{name:"paypal",desc:"paypal.me/LordYao",link:"https://www.paypal.com/cgi-bin/webscr?cmd=_xclick&amp;business=243292490@qq.com&amp;currency_code=USD&amp;amount=1&amp;return=http://yaoqs.github.com/about&amp;item_name=LordYao%27s%20Blog&amp;undefined_quantity=1"}]})})</script><script src="https://cdn.jsdelivr.net/npm/materialize-css@1.0.0/dist/js/materialize.min.js" integrity="sha256-U/cHDMTIHCeMcvehBv1xQ052bPSbJtbuiw4QA9cTKz0=" crossorigin="anonymous"></script><style>#searchIcon{font-size:1.2rem}#searchModal{min-height:500px;width:80%}#searchModal .search-header .title{font-size:1.6rem;color:#333}#searchResult{margin:-15px 0 10px 10px}#searchResult .search-result-list{margin-left:-8px;padding-left:0;color:#666}.search-result-list .search-result-title{font-size:1.4rem;color:#42b983}.search-result-list li{border-bottom:1px solid #e5e5e5;padding:15px 0 5px 0}.search-result-list .search-keyword{margin:0 2px;padding:1px 5px 1px 4px;border-radius:2px;background-color:#f2f2f2;color:#e96900;font-style:normal;white-space:pre-wrap}.modal{display:none;position:fixed;left:0;right:0;background-color:#fafafa;padding:0;max-height:70%;width:55%;margin:auto;overflow-y:auto;border-radius:2px;will-change:top,opacity}.modal:focus{outline:0}@media only screen and (max-width:992px){.modal{width:80%}}.modal h1,.modal h2,.modal h3,.modal h4{margin-top:0}.modal .modal-content{padding:24px}.modal .modal-close{cursor:pointer}.modal .modal-footer{border-radius:0 0 2px 2px;background-color:#fafafa;padding:4px 6px;height:56px;width:100%;text-align:right}.modal .modal-footer .btn,.modal .modal-footer .btn-flat,.modal .modal-footer .btn-large,.modal .modal-footer .btn-small{margin:6px 0}.modal-overlay{position:fixed;z-index:999;top:-25%;left:0;bottom:0;right:0;height:125%;width:100%;background:#000;display:none;will-change:opacity}.modal.modal-fixed-footer{padding:0;height:70%}.modal.modal-fixed-footer .modal-content{position:absolute;height:calc(100% - 56px);max-height:100%;width:100%;overflow-y:auto}.modal.modal-fixed-footer .modal-footer{border-top:1px solid rgba(0,0,0,.1);position:absolute;bottom:0}.modal.bottom-sheet{top:auto;bottom:-100%;margin:0;width:100%;max-height:45%;border-radius:0;will-change:bottom,opacity}</style><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;search</span> <input type="search" id="searchInput" name="s" placeholder="searchTip" class="search-input"></div><div id="searchResult"></div></div></div><script>$(function(){var e,r,a;e="/search.xml",r="searchInput",a="searchResult",$.ajax({url:e,dataType:"xml",success:function(e){var t=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),e=document.getElementById(r),n=document.getElementById(a);e.addEventListener("input",function(){var o='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length<=0||(t.forEach(function(e){var n,t,r,a=!0,l=e.title.trim().toLowerCase(),s=e.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=0===(i=e.url).indexOf("/")?e.url:"/"+i,c=-1,u=-1;""!==l&&""!==s&&h.forEach(function(e,t){n=l.indexOf(e),c=s.indexOf(e),n<0&&c<0?a=!1:(c<0&&(c=0),0===t&&(u=c))}),a&&(o+="<li><a href='"+i+"' class='search-result-title'>"+l+"</a>",i=e.content.trim().replace(/<[^>]+>/g,""),0<=u&&(e=u+80,(e=0===(t=(t=u-20)<0?0:t)?100:e)>i.length&&(e=i.length),r=i.substr(t,e),h.forEach(function(e){var t=new RegExp(e,"gi");r=r.replace(t,'<em class="search-keyword">'+e+"</em>")}),o+='<p class="search-result">'+r+"...</p>"),o+="</li>")}),o+="</ul>",n.innerHTML=o)})}})}),$(".modal").modal()</script><script src="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/js/index.js"></script><script src="/js/hexo-widget-tree.js"></script><div id="widget-tree"><ul><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/">github page </a><span class="tree-list-count">14</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/Termux/">Termux </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220101/termux-config/" title="Termux-config"><i class="post-icon gg-file-document"></i>Termux-config</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/github-page/keys/">keys </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220101/keys/" title="keys"><i class="post-icon gg-file-document"></i>keys</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220609/50-chong-zui-bang-de-kai-yuan-pa-chong-kuang-jia-xiang-mu/" title="50种最棒的开源爬虫框架/项目"><i class="post-icon gg-file-document"></i>50种最棒的开源爬虫框架/项目</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/Cesium/">Cesium </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/cesium-sheng-cheng-terrain-di-xing-shu-ju-ctb-fang-shi-ji-bu-zou/" title="Cesium 生成terrain地形数据----CTB方式及步骤"><i class="post-icon gg-file-document"></i>Cesium 生成terrain地形数据----CTB方式及步骤</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E6%9C%AF/">科研学术 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/ei-qi-kan-cha-xun/" title="EI期刊查询"><i class="post-icon gg-file-document"></i>EI期刊查询</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/html/">html </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20191121/html5-xuan-ku-dong-hua-ji-yuan-ma-demo-yan-shi/" title="HTML5炫酷动画及源码DEMO演示"><i class="post-icon gg-file-document"></i>HTML5炫酷动画及源码DEMO演示</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/">技术笔记 </a><span class="tree-list-count">15</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/opencv/">opencv </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/opencv-zai-csharp-zhong-ying-yong-opencvsharp/" title="OpenCV在Csharp中应用OpenCVSharp"><i class="post-icon gg-file-document"></i>OpenCV在Csharp中应用OpenCVSharp</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/OpenGL/">OpenGL </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/opengl-chao-ji-bao-dian-xue-xi-bi-ji-cao-zuo-xiang-su/" title="OpenGL超级宝典学习笔记操作像素"><i class="post-icon gg-file-document"></i>OpenGL超级宝典学习笔记操作像素</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/js/">js </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220615/js-han-shu-zhong-ru-he-shi-yong-ke-xuan-can-shu-bao-gua-ke-xuan-hui-diao-han-shu/" title="js函数中如何使用可选参数（包括可选回调函数）"><i class="post-icon gg-file-document"></i>js函数中如何使用可选参数（包括可选回调函数）</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%A0%91%E8%8E%93%E6%B4%BE/">树莓派 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/chu-chang-zhi-zuo-shu-mei-pai-zui-jian-dan-de-rootfs/" title="初尝制作树莓派最简单的rootfs"><i class="post-icon gg-file-document"></i>初尝制作树莓派最简单的rootfs</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220705/you-xi-kai-fa-zi-yuan-gamedevresource/" title="游戏开发资源GameDevResource"><i class="post-icon gg-file-document"></i>游戏开发资源GameDevResource</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20210430/win10-bitlocker-zhuan-ti/" title="win10-BitLocker专题"><i class="post-icon gg-file-document"></i>win10-BitLocker专题</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220425/mu-biao-gen-zong-suan-fa/" title="目标跟踪算法"><i class="post-icon gg-file-document"></i>目标跟踪算法</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">12</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/javascript-zhuan-ti/" title="JavaScript专题"><i class="post-icon gg-file-document"></i>JavaScript专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/docker-zhuan-ti/" title="Docker专题"><i class="post-icon gg-file-document"></i>Docker专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210401/windowsterminal-zhuan-ti/" title="Windows Terminal专题"><i class="post-icon gg-file-document"></i>Windows Terminal专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210401/wsl2-zhuan-ti/" title="WSL2专题"><i class="post-icon gg-file-document"></i>WSL2专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/xamarin-zhuan-ti/" title="Xamarin专题"><i class="post-icon gg-file-document"></i>Xamarin专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220426/csharp-zhuan-ti/" title="csharp专题"><i class="post-icon gg-file-document"></i>csharp专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210220/c-zhuan-ti/" title="c++专题"><i class="post-icon gg-file-document"></i>c++专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/hexo-zhuan-ti/" title="hexo专题"><i class="post-icon gg-file-document"></i>hexo专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220424/html-zhuan-ti/" title="html专题"><i class="post-icon gg-file-document"></i>html专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210327/jquery-zhuan-ti/" title="jQuery专题"><i class="post-icon gg-file-document"></i>jQuery专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20210411/ssh-zhuan-ti/" title="ssh专题"><i class="post-icon gg-file-document"></i>ssh专题</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20250114/cookie-zhuan-ti/" title="cookie专题"><i class="post-icon gg-file-document"></i>cookie专题</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/javascript/">javascript </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220315/javascript-yu-yan-jing-sui-yu-bian-cheng-shi-jian/" title="JavaScript语言精髓与编程实践"><i class="post-icon gg-file-document"></i>JavaScript语言精髓与编程实践</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/iocp/">iocp </a><span class="tree-list-count">2</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/iocp/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/cai-yong-wan-cheng-duan-kou-iocp-shi-xian-gao-xing-neng-wang-luo-fu-wu-qi-windows-c-ban/" title="采用完成端口（IOCP）实现高性能网络服务器（Windows c++版）"><i class="post-icon gg-file-document"></i>采用完成端口（IOCP）实现高性能网络服务器（Windows c++版）</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/python/">python </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240322/python-wang-ye-pa-chong-wen-ben-chu-li-ke-xue-ji-suan-ji-qi-xue-xi-shu-ju-wa-jue-bing-qi-pu/" title="Python 网页爬虫 & 文本处理 & 科学计算 & 机器学习 & 数据挖掘兵器谱"><i class="post-icon gg-file-document"></i>Python 网页爬虫 & 文本处理 & 科学计算 & 机器学习 & 数据挖掘兵器谱</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/MFC/">MFC </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/MFC/cef/">cef </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/mfc-ji-cheng-cef3-chuang-kou/" title="MFC集成CEF3窗口"><i class="post-icon gg-file-document"></i>MFC集成CEF3窗口</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/threejs/">threejs </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/threejs/Cesium/">Cesium </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/threejs-ji-cheng-di-tu-wa-pian/" title="ThreeJS集成地图瓦片"><i class="post-icon gg-file-document"></i>ThreeJS集成地图瓦片</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/visual-studio/">visual studio </a><span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/visual-studio/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220401/visual-studio-code-zhuan-ti/" title="Visual Studio Code 专题"><i class="post-icon gg-file-document"></i>Visual Studio Code 专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/windows-an-quan-gong-ju-jin-ji/" title="Windows安全工具锦集"><i class="post-icon gg-file-document"></i>Windows安全工具锦集</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%B8%97%E9%80%8F/">渗透 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%B8%97%E9%80%8F/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220628/kali-zhuan-ti/" title="kali专题"><i class="post-icon gg-file-document"></i>kali专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/">数字信号处理 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220330/shu-zi-xin-hao-chu-li-matlab-zuo-fft-shi-dian-shu-n-zen-me-xuan-qu/" title="【数字信号处理】Matlab做fft时点数N怎么选取"><i class="post-icon gg-file-document"></i>【数字信号处理】Matlab做fft时点数N怎么选取</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E4%BA%8C%E7%BB%B4%E7%A0%81/">二维码 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240806/er-wei-ma-de-sheng-cheng-xi-jie-he-yuan-li/" title="二维码的生成细节和原理"><i class="post-icon gg-file-document"></i>二维码的生成细节和原理</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/nextjs/">nextjs </a><span class="tree-list-count">3</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-next-js-hexo-chong-gou-wo-de-bo-ke/" title="使用 Next.js + Hexo 重构我的博客"><i class="post-icon gg-file-document"></i>使用 Next.js + Hexo 重构我的博客</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-nextjs-he-tailwindcss-chong-gou-wo-de-bo-ke/" title="使用 NextJS 和 TailwindCSS 重构我的博客"><i class="post-icon gg-file-document"></i>使用 NextJS 和 TailwindCSS 重构我的博客</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20240711/shi-yong-next-js-da-jian-ge-ren-bo-ke/" title="使用 Next.js 搭建个人博客"><i class="post-icon gg-file-document"></i>使用 Next.js 搭建个人博客</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/git/">git </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/git/%E4%B8%93%E9%A2%98/">专题 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220609/git-zhuan-ti/" title="git专题"><i class="post-icon gg-file-document"></i>git专题</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/pdf/">pdf </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/pdf/wpf/">wpf </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/shi-yong-c-kai-fa-pdf-yue-du-qi-chu-tan-ji-yu-wpf-mei-you-shi-yong-kai-yuan-ku/" title="使用C#开发pdf阅读器初探（基于WPF，没有使用开源库）"><i class="post-icon gg-file-document"></i>使用C#开发pdf阅读器初探（基于WPF，没有使用开源库）</a></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记 </a><span class="tree-list-count">4</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/gong-chan-dang-xuan-yan/" title="共产党宣言"><i class="post-icon gg-file-document"></i>共产党宣言</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/quan-xue-xun-zi/" title="劝学-荀子"><i class="post-icon gg-file-document"></i>劝学-荀子</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20191203/lun-liu-jia-yao-zhi/" title="论六家要指"><i class="post-icon gg-file-document"></i>论六家要指</a></li><li class="tree-list-item"><a class="tree-list-post-link" href="/20220613/huang-di-yin-fu-jing/" title="黄帝阴符经"><i class="post-icon gg-file-document"></i>黄帝阴符经</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/">opencv </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/qrcode/">qrcode </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/opencv/qrcode/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/ji-yu-opencv-shi-bie-ding-wei-er-wei-ma-c-ban/" title="基于opencv 识别、定位二维码 （c++版）"><i class="post-icon gg-file-document"></i>基于opencv 识别、定位二维码 （c++版）</a></li></ul></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/acm/">acm </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/you-xi-she-ji-zhi-zuo-shi-shi-fou-hui-yong-dao-lei-si-acm-zhong-de-suan-fa-she-ji/" title="游戏设计制作时是否会用到类似 ACM 中的算法设计？"><i class="post-icon gg-file-document"></i>游戏设计制作时是否会用到类似 ACM 中的算法设计？</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/">数字签名证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/Let%E2%80%99s-Encrypt%E8%AF%81%E4%B9%A6/">Let’s Encrypt证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/Let%E2%80%99s-Encrypt%E8%AF%81%E4%B9%A6/SSL%E8%AF%81%E4%B9%A6/">SSL证书 </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240808/zi-jian-shu-zi-qian-ming-zheng-shu/" title="自建数字签名证书"><i class="post-icon gg-file-document"></i>自建数字签名证书</a></li></ul></li></ul></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/c/">c++ </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20240807/bjarne-stroustrup-s-faq-zhong-wen-ban/" title="Bjarne Stroustrup's FAQ（中文版）"><i class="post-icon gg-file-document"></i>Bjarne Stroustrup's FAQ（中文版）</a></li></ul></li><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/follow/">follow </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-post-icon gg-folder-add"></i> <a class="tree-list-link" href="/categories/follow/rsshub/">rsshub </a><span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><a class="tree-list-post-link" href="/20241213/follow-zhuan-ti/" title="Follow专题"><i class="post-icon gg-file-document"></i>Follow专题</a></li></ul></li></ul></li></ul><div id="widget-tree-button"><i class="gg-chevron-right"></i></div></div></body></html>